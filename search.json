[{"path":"index.html","id":"about","chapter":"About","heading":"About","text":"sample book written Markdown. can use anything Pandoc’s Markdown supports, e.g., math equation \\(^2 + b^2 = c^2\\).bookdown package can installed CRAN Github:Remember Rmd file contains one one chapter, chapter defined first-level heading #.compile example PDF, need XeLaTeX. recommended install TinyTeX (includes XeLaTeX): https://yihui.name/tinytex/.","code":"\ninstall.packages(\"bookdown\")\n# or the development version\n# devtools::install_github(\"rstudio/bookdown\")"},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"","code":""},{"path":"basic.html","id":"basic","chapter":"2 R語言基礎","heading":"2 R語言基礎","text":"本章節將介紹如何使用RStudio來執行R語言的指令。並簡單介紹R語言的基礎操作，並介紹vector與data.frame兩個基礎資料型態。","code":""},{"path":"basic.html","id":"使用rstudio","chapter":"2 R語言基礎","heading":"2.1 使用RStudio","text":"Using Cmd+Enter (Ctrl+Enter Window) excute line cursor located.Using Cmd+Enter (Ctrl+Enter Window) excute line cursor located.Using Cmd(Ctrl)+Shift+Enter run code cellUsing Cmd(Ctrl)+Shift+Enter run code cellUsing mouse select multiple lines, Cmd(Ctrl)+Shift+c comment/uncomment multiple lines.Using mouse select multiple lines, Cmd(Ctrl)+Shift+c comment/uncomment multiple lines.","code":"\na <- c(1, 2, 3, 4, 5)\nb <- 4\na*b## [1]  4  8 12 16 20"},{"path":"basic.html","id":"插入新的程式區","chapter":"2 R語言基礎","heading":"2.1.1 插入新的程式區","text":"Using Cmd(Ctrl)+Option(Alt)+insert new cell","code":""},{"path":"basic.html","id":"安裝與載入套件","chapter":"2 R語言基礎","heading":"2.1.2 安裝與載入套件","text":"套件的使用分為安裝(install.packages(\"pkg_name\"))和載入（library(pkg_name)）兩個動作。通常安裝好R的時候就已經安裝好基本base套件。當執行R時便會將base套件預載入程式的執行環境中。非常多的R使用者會編寫第三方套件，並且將這些套件開放給群眾使用。通常這些套件已經被上載到R cran提供下載。而R cran上的套件我們可以使用install.packages(\"package_name\")來自動安裝到我們的電腦中。Practice 1. 嘗試安裝下列函式庫（套件）。","code":""},{"path":"basic.html","id":"載入所安裝的第三方套件","chapter":"2 R語言基礎","heading":"2.1.3 載入所安裝的第三方套件","text":"這些第三方套件被安裝好後，還需要被加載到程式的執行環境中才可以使用。因此要用library(package_name)將其載入。","code":"\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr)"},{"path":"basic.html","id":"註解","chapter":"2 R語言基礎","heading":"2.1.4 註解","text":"下列程式碼中開頭有#符號者為註解，程式在執行時會自動忽略前面有#符號的程式碼。","code":"\n# a <- c(1, 2, 3, 4, 5)\n# b <- 4\n# a*b"},{"path":"basic.html","id":"第一次資料嘗試","chapter":"2 R語言基礎","heading":"2.2 第一次資料嘗試","text":"","code":""},{"path":"basic.html","id":"載入dcard頁面資料","chapter":"2 R語言基礎","heading":"2.2.1 載入dcard頁面資料","text":"先不要去管以下程式碼如fromJSON(content(GET(url), \"text\"))是什麼意思，先著重在語言的形式。通常一個函式會寫為func_name()，所以上述其實是三個函式由內而外一層套一層，從最內層開始往外做。這其實很「make-sense」，因為如果你有一個數學式(1 + (3-3)/2)/8，也是會從最裡面那層做出來。","code":"\nlibrary(jsonlite)\nlibrary(httr)\nurl <- \"https://www.dcard.tw/_api/forums/relationship/posts?popular=true\"\nres <- fromJSON(content(GET(url), \"text\"))\n# View(res)\n\ndplyr::glimpse(res)## Rows: 30\n## Columns: 53\n## $ id                      <int> 235931948, 238786114, 238791140, 238789541, 23…\n## $ title                   <chr> \"#公告 關於感情板的微西斯內容\", \"去年...我在精…\n## $ excerpt                 <chr> \"各位卡友們好，小天使近期收到許多關於感情板西…\n## $ anonymousSchool         <lgl> FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE,…\n## $ anonymousDepartment     <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n## $ pinned                  <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n## $ forumId                 <chr> \"42851318-b9e2-4a75-8a05-9fe180becefe\", \"42851…\n## $ replyId                 <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n## $ createdAt               <chr> \"2021-05-07T06:11:32.413Z\", \"2022-05-03T13:43:…\n## $ updatedAt               <chr> \"2021-05-07T18:00:24.726Z\", \"2022-05-03T13:43:…\n## $ commentCount            <int> 34, 62, 95, 96, 71, 144, 231, 40, 37, 42, 30, …\n## $ likeCount               <int> 321, 835, 324, 251, 228, 218, 176, 173, 95, 80…\n## $ withNickname            <lgl> TRUE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, FA…\n## $ tags                    <list> \"HIDE_THUMBNAIL\", <>, <>, <>, <>, \"HIDE_THUMB…\n## $ topics                  <list> <>, <\"精神病院\", \"老婆\", \"遇到\", \"愛情\">, <\"…\n## $ meta                    <df[,3]> <data.frame[26 x 3]>\n## $ forumName               <chr> \"感情\", \"感情\", \"感情\", \"感情\", \"感情\", \"感…\n## $ forumAlias              <chr> \"relationship\", \"relationship\", \"relationship\"…\n## $ nsfw                    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ gender                  <chr> \"D\", \"M\", \"F\", \"M\", \"F\", \"F\", \"F\", \"F\", \"F\", \"…\n## $ school                  <chr> \"客服小天使\", \"璟兒\", \"艾瑪\", \"Atticus\", NA, N…\n## $ department              <chr> \"dcard_support_1\", \"wowbeach978\", \"emma0109\", …\n## $ replyTitle              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n## $ mediaMeta               <list> [<data.frame[0 x 0]>], [<data.frame[2 x 10]>],…\n## $ reactions               <list> [<data.frame[4 x 2]>], [<data.frame[3 x 2]>],…\n## $ hidden                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n## $ customStyle             <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n## $ isSuspiciousAccount     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ isModerator             <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ layout                  <chr> \"classic\", \"classic\", \"classic\", \"classic\", \"c…\n## $ pinnedType              <chr> \"dcard\", NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n## $ pinnedPriority          <dbl> 1.620368e+12, NA, NA, NA, NA, NA, NA, NA, NA, …\n## $ spoilerAlert            <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ categories              <list> \"公告\", <NULL>, <NULL>, <NULL>, <NULL>, <NULL>…\n## $ isSelectedPost          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n## $ unsafe                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ totalCommentCount       <int> 34, 168, 177, 201, 80, 245, 330, 105, 82, 67, …\n## $ withImages              <lgl> FALSE, TRUE, TRUE, TRUE, FALSE, FALSE, TRUE, F…\n## $ withVideos              <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n## $ media                   <list> [<data.frame[0 x 0]>], [<data.frame[1 x 1]>], …\n## $ reportReasonText        <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"…\n## $ supportedReactions      <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n## $ excerptComments         <list> [], [], [], [], [], [], [], [], [], [], [], []…\n## $ edited                  <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n## $ collectionCount         <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n## $ postAvatar              <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n## $ activityAvatar          <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n## $ verifiedBadge           <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n## $ memberType              <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"…\n## $ enableNestedComment     <lgl> NA, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n## $ enablePrivateMessage    <lgl> NA, NA, FALSE, NA, FALSE, NA, NA, NA, NA, NA, …\n## $ leaderboardCategoryId   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n## $ leaderboardCategoryName <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\nhead(res) %>% select(id, title, excerpt) %>% kbl() %>% kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\"))"},{"path":"basic.html","id":"讀取台北住宅竊盜點位資料","chapter":"2 R語言基礎","heading":"2.2.2 讀取台北住宅竊盜點位資料","text":"Go data.taipeiMake query “住宅竊盜”Open “住宅竊盜點位資訊”Click “API”Copy API address assign url","code":""},{"path":"basic.html","id":"讀取先行下載的csv檔","chapter":"2 R語言基礎","heading":"2.2.3 讀取先行下載的csv檔","text":"","code":"\ndf <- read.csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\")\nhead(df)"},{"path":"basic.html","id":"直接從網路載入內政部開放資料","chapter":"2 R語言基礎","heading":"2.2.4 直接從網路載入內政部開放資料","text":"","code":"\nlibrary(httr)\nlibrary(jsonlite)\nurl <- \"https://www.ris.gov.tw/rs-opendata/api/v1/datastore/ODRP024/107?page=1\"\nfirst_page <- fromJSON(content(GET(url), \"text\"))\nhead(first_page$responseData)"},{"path":"basic.html","id":"獲取ubike即時資料","chapter":"2 R語言基礎","heading":"2.2.5 獲取ubike即時資料","text":"https://taipeicity.github.io/traffic_realtime/","code":"\nurl <- \"https://tcgbusfs.blob.core.windows.net/blobyoubike/YouBikeTP.json\"\nubike.list <- fromJSON(content(GET(url),\"text\", encoding = \"utf-8\"))\nubike.v <- unlist(ubike.list$retVal)\nubike.m <- matrix(ubike.v, byrow = T, ncol = 14)\nubike.df <- as.data.frame(ubike.m)\nnames(ubike.df) <- names(ubike.list$retVal$`0001`)\nhead(ubike.df)"},{"path":"vectors.html","id":"vectors","chapter":"3 Vectors","heading":"3 Vectors","text":"","code":""},{"path":"vectors.html","id":"r-syntax","chapter":"3 Vectors","heading":"3.1 R Syntax","text":"","code":""},{"path":"vectors.html","id":"assignment","chapter":"3 Vectors","heading":"3.1.1 Assignment","text":"<- 將右邊的算式或數值指派給左邊的變數。右邊如果是numeric，那左邊的變數就是numeric variable；右邊如果是character，左邊的變數就是character variable。在幾乎所有程式語言中，單等號=指的是assignment，把右方的算式、值或物件指給左方的變數。而比較兩者相不相等，則用雙等號==，例如1==3-2。","code":"\na <- 1\nb <- c(1, 2, 3, 4)\nc <- c(\"1\", \"2\", \"3\", \"4\")\nd <- c(b, a)\ne <- \"abcd\""},{"path":"vectors.html","id":"comments-註解","chapter":"3 Vectors","heading":"3.1.2 comments 註解","text":"註解：在程式碼區塊若前面有#字號後面跟著空白的話，那代表那行被標示為註解，程式執行時會自動跳過註解不執行。快速鍵：當游標在某一行程式碼時打cmd(ctrl)-shift-c，就可以產生註解。","code":"\n# df <- data.frame(a = c(1, 2, 3), b = c(3, 4, 5))"},{"path":"vectors.html","id":"basic-operations","chapter":"3 Vectors","heading":"3.2 Basic operations","text":"各縣市平均每月薪資所得各縣市人口數","code":""},{"path":"vectors.html","id":"creating","chapter":"3 Vectors","heading":"3.2.1 Creating","text":"在程式碼中，只要是文字必用成對的雙引號或單引號包含其中，以區隔「變數」和「數字」。例如如果看到沒有雙引號的「英文字母」必定是變數名稱，或函式名稱。如果看到有雙引號的數字，那也是文字。","code":"\nincome <- c(70100, 51300, 51100, 48400, 47600, 43000)\ncounty <- c(\"台北\", \"新北\", \"桃園\", \"高雄\", \"台中\", \"台南\")\npopulation <- c(2.6, 3.9, 2.2, 2.7, 2.8, 1.8)\narea <- c(271.8, 2052.5, 1221, 2951.9, 2214.9, 2191.7)\nincome## [1] 70100 51300 51100 48400 47600 43000\ncounty[c(5, 3, 1)]## [1] \"台中\" \"桃園\" \"台北\"\ncounty <- county[c(5, 3, 1)]\ncounty## [1] \"台中\" \"桃園\" \"台北\"\narea## [1]  271.8 2052.5 1221.0 2951.9 2214.9 2191.7\npopulation## [1] 2.6 3.9 2.2 2.7 2.8 1.8"},{"path":"vectors.html","id":"creating-a-sequence","chapter":"3 Vectors","heading":"3.2.1.1 Creating a sequence","text":"","code":"\na <- seq(11, 99, 11)\na## [1] 11 22 33 44 55 66 77 88 99\nb <- 11:20\nb##  [1] 11 12 13 14 15 16 17 18 19 20"},{"path":"vectors.html","id":"creating-sequences-by-distribution","chapter":"3 Vectors","heading":"3.2.1.2 Creating sequences by distribution","text":"","code":"\nx <- runif(10000000, 1, 10) # uniform dist, n=1000\nplot(density(x))\nx <- rnorm(1000, 1, 10) # uniform dist, n=1000\nplot(density(x))\nx <- rnorm(10000000, 1, 10) # normal dist, n=1000\nplot(density(x))"},{"path":"vectors.html","id":"viewing","chapter":"3 Vectors","heading":"3.2.2 Viewing","text":"","code":"\ncounty## [1] \"台中\" \"桃園\" \"台北\"\nincome## [1] 70100 51300 51100 48400 47600 43000\nhead(county)## [1] \"台中\" \"桃園\" \"台北\"\ntail(county)## [1] \"台中\" \"桃園\" \"台北\"\nlength(county)## [1] 3\nmode(county)## [1] \"character\"\nclass(county)## [1] \"character\"\n# View(county)\nlength(county)## [1] 3\nlength(income)## [1] 6"},{"path":"vectors.html","id":"subsetting-filtering","chapter":"3 Vectors","heading":"3.2.3 Subsetting, filtering","text":"important know neglect first n last n elements. example, [1:(length()-2)] neglect last two elements. Thinking need parentheses length()-2 .","code":"\ncounty## [1] \"台中\" \"桃園\" \"台北\"\ncounty[c(5, 3, 1)] # how about country[c(1, 3, 5)]## [1] NA     \"台北\" \"台中\"\ncounty[3:6] # is it equal to country[c(3, 4, 5, 6)]## [1] \"台北\" NA     NA     NA\na <- 11:19\na[3:length(a)]## [1] 13 14 15 16 17 18 19\na[length(a):3]## [1] 19 18 17 16 15 14 13"},{"path":"vectors.html","id":"deleting","chapter":"3 Vectors","heading":"3.2.4 Deleting","text":"Without assignment, deletion won’t change original vectorsCorrect deleting operations assignment replace original vector","code":"\nb <- 11:20\nb[-(3:5)]## [1] 11 12 16 17 18 19 20\nb[-c(1, 3, 5)]## [1] 12 14 16 17 18 19 20\nb##  [1] 11 12 13 14 15 16 17 18 19 20\nb <- b[-(3:5)]\nb## [1] 11 12 16 17 18 19 20\na <- seq(11, 99, 11)\na <- a[-c(1, 3, 5)]\na## [1] 22 44 66 77 88 99"},{"path":"vectors.html","id":"concatinating","chapter":"3 Vectors","heading":"3.2.5 Concatinating","text":"Concatinating quite useful web crawling crawl article links page page. may sure number page need crawl. need append entire new vector old vector. concatinating. (“Appending” often means adding one new element end data.)","code":"\na <- 1:10\na <- c(a, 11)\na##  [1]  1  2  3  4  5  6  7  8  9 10 11\nb## [1] 11 12 16 17 18 19 20\na <- c(a, b)\na##  [1]  1  2  3  4  5  6  7  8  9 10 11 11 12 16 17 18 19 20\na <- c(a, a, b)\na##  [1]  1  2  3  4  5  6  7  8  9 10 11 11 12 16 17 18 19 20  1  2  3  4  5  6  7\n## [26]  8  9 10 11 11 12 16 17 18 19 20 11 12 16 17 18 19 20"},{"path":"vectors.html","id":"calculating-with-vectors","chapter":"3 Vectors","heading":"3.3 Calculating with vectors","text":"","code":""},{"path":"vectors.html","id":"arithmetic-operations","chapter":"3 Vectors","heading":"3.3.1 Arithmetic operations","text":"","code":"\na <- 11:19\na + 3## [1] 14 15 16 17 18 19 20 21 22\na / 2## [1] 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5\na %% 2## [1] 1 0 1 0 1 0 1 0 1\na %/% 2## [1] 5 6 6 7 7 8 8 9 9\na %% 2== 0## [1] FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE\nwhich(a %% 2== 0)## [1] 2 4 6 8\na[which(a%% 2 == 0)]## [1] 12 14 16 18\na[c(2, 4, 6, 8)]## [1] 12 14 16 18\na %% 2 != 0## [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE\na[a%% 2 == 0]## [1] 12 14 16 18\na[a%%2 != 0]## [1] 11 13 15 17 19\na <- a %% 2     # modular arithmetic, get the reminder\na <- a %/% 2    # Quotient"},{"path":"vectors.html","id":"logic-comparisons","chapter":"3 Vectors","heading":"3.3.2 Logic comparisons","text":"","code":"\na %% 2 == 0     # deteting odd/even number## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\na %% 2 != 0## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\na[a%%2==0]## [1] 0 0 0 0 0 0 0 0 0\na > b## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nincome > mean(income)## [1]  TRUE FALSE FALSE FALSE FALSE FALSE\nTRUE == T       # == equal to,## [1] TRUE\nTRUE != F       # != Not equal to## [1] TRUE\nany(a>11) # is there any element larger than 1## [1] FALSE\nall(a>11) # are all elements larger than 1## [1] FALSE"},{"path":"vectors.html","id":"subsetting-by-logic-comparisons","chapter":"3 Vectors","heading":"3.3.3 Subsetting by logic comparisons","text":"two methods filter data vectors, index vector logical vector equal length.","code":"\na <- seq(11, 55, 11)\na[c(T, F, T, F, T)]## [1] 11 33 55\na[a%%2==1]## [1] 11 33 55\na%%2## [1] 1 0 1 0 1\na%%2==1## [1]  TRUE FALSE  TRUE FALSE  TRUE\na <- c(\"你好\",\"你好棒棒\",\"你好棒\",\"你真的好棒\")\na[nchar(a)>3]## [1] \"你好棒棒\"   \"你真的好棒\"\n# which will return \"index-of\"\na <- seq(11, 55, 11)\na[which(a%%2==1)]## [1] 11 33 55\nwhich(a%%2==1)## [1] 1 3 5"},{"path":"vectors.html","id":"sorting-and-ordering","chapter":"3 Vectors","heading":"3.3.4 Sorting and ordering","text":"sort(x)的結果必須用<-覆蓋原本的x，此時的x才算被排序的結果。sort(x)的結果必須用<-覆蓋原本的x，此時的x才算被排序的結果。order(x)函式會傳回x數值由小到大的索引。這個例子的結果是5, 4, 3, 6, 1, 2，也就是5位置的那個數最小、4那個位置的數次小、接下來3, 6, 1, 2。order(x)函式會傳回x數值由小到大的索引。這個例子的結果是5, 4, 3, 6, 1, 2，也就是5位置的那個數最小、4那個位置的數次小、接下來3, 6, 1, 2。x[order(x)]把order(x)結果（也就是c(5, 4, 3, 6, 1, 2)）傳給原本的x便會使得原本的x重新排序。通常order()的用途是，我們可以將兩個等長的variables例如var1和var2，依據var2來重新排序var1，例如var1[order(var2)]。x[order(x)]把order(x)結果（也就是c(5, 4, 3, 6, 1, 2)）傳給原本的x便會使得原本的x重新排序。通常order()的用途是，我們可以將兩個等長的variables例如var1和var2，依據var2來重新排序var1，例如var1[order(var2)]。","code":"\nx <- c(33, 55, 22, 13, 4, 24)\nmode(x)## [1] \"numeric\"\nclass(x)## [1] \"numeric\"\nsort(x)## [1]  4 13 22 24 33 55\n# x <- sort(x) # assign to replace original x\norder(x) ## [1] 5 4 3 6 1 2\nx[order(x)]## [1]  4 13 22 24 33 55\nx[c(5, 4, 3, 6, 1, 2)]## [1]  4 13 22 24 33 55"},{"path":"vectors.html","id":"built-in-math-functions","chapter":"3 Vectors","heading":"3.3.5 Built-in math functions","text":"\nlog computes logarithms, default natural logarithms,\nlog10 computes common (.e., base 10) logarithms, \nlog2 computes binary (.e., base 2) logarithms.\ngeneral form log(x, base) computes logarithms base\nbase.\n\nlog1p(x) computes log(1+x) accurately also \n|x| << 1.\n\nexp computes exponential function.\n\nexpm1(x) computes exp(x) - 1 accurately also \n|x| << 1.\n\nnumeric complex vector.\n\npositive complex number: base respect \nlogarithms computed. Defaults e=exp(1).\n\nexcept logb generic functions: methods can defined\nindividually via Math\ngroup generic.\n\nlog10 log2 convenience wrappers, logs\nbases 10 2 (whether computed via log wrappers)\ncomputed efficiently accurately supported OS.\nMethods can set individually (otherwise methods \nlog used).\n\nlogb wrapper log compatibility S. \n(S3 S4) methods set log dispatched.\nset S4 methods logb .\n\nexcept log primitive functions.\n\nvector length x containing transformed\nvalues. log(0) gives -Inf, log(x) \nnegative values x NaN. exp(-Inf) 0.\n\ncomplex inputs log functions, value complex number\nimaginary part range [-pi, pi]: \nend range used might platform-specific.\n\nexp, expm1, log, log10, log2 \nlog1p S4 generic members \nMath group generic.\n\nNote means S4 generic log \nsignature one argument, x, base can\npassed methods (used method selection). \nhand, set method Math group\ngeneric base argument log ignored \nclass.\n\nlog1p expm1 may taken operating system,\navailable based Fortran subroutine\ndlnrel W. Fullerton Los Alamos Scientific Laboratory (see\nhttps://www.netlib.org/slatec/fnlib/dlnrel.f) (small x) \nsingle Newton step solution log1p(y) = x\nrespectively.\n\nBecker, R. ., Chambers, J. M. Wilks, . R. (1988)\nNew S Language.\nWadsworth & Brooks/Cole.\n(log, log10 exp.)\n\nChambers, J. M. (1998)\nProgramming Data. Guide S Language.\nSpringer. (logb.)\n\nTrig,\nsqrt,\nArithmetic.\n","code":"\na <- 11:19\nmin(a); max(a); mean(a); median(a); sd(a)## [1] 11## [1] 19## [1] 15## [1] 15## [1] 2.738613\nlog2(a)## [1] 3.459432 3.584963 3.700440 3.807355 3.906891 4.000000 4.087463 4.169925\n## [9] 4.247928\nlog1p(a)## [1] 2.484907 2.564949 2.639057 2.708050 2.772589 2.833213 2.890372 2.944439\n## [9] 2.995732\n?log1p\nlog(x, base = exp(1))\nlogb(x, base = exp(1))\nlog10(x)\nlog2(x)\n\nlog1p(x)\n\nexp(x)\nexpm1(x)\n\nlog(exp(3))\nlog10(1e7) # = 7\n\nx <- 10^-(1+2*1:9)\ncbind(x, log(1+x), log1p(x), exp(x)-1, expm1(x))\n"},{"path":"vectors.html","id":"data-types","chapter":"3 Vectors","heading":"3.4 Data types","text":"","code":""},{"path":"vectors.html","id":"checking-data-type","chapter":"3 Vectors","heading":"3.4.1 Checking data type","text":"","code":"\nmode(county)                # character## [1] \"character\"\nmode(income)                    # numeric## [1] \"numeric\"\nmode(income > mean(income)) # logical## [1] \"logical\"\ntesting <- c(\"26.142\", \"12.008\", \"7.032\", \"13.646\", \"4.589\")\nmode(testing)               # character## [1] \"character\""},{"path":"vectors.html","id":"converting-data-type","chapter":"3 Vectors","heading":"3.4.2 Converting data type","text":"numeric vector可以用as.character(x)轉成charcter；logical vector可以用as.numeric(x)轉為numeric。概念上可以說是character > numeric > logical。numeric vector可以用as.character(x)轉成charcter；logical vector可以用as.numeric(x)轉為numeric。概念上可以說是character > numeric > logical。如果硬是在logical vector後附加一個numeric element的話，那就會整個vector被轉為numeric vector；相仿地，如果numeric vector後附加一個character element的話那整個vector就會被轉為character vector。如果硬是在logical vector後附加一個numeric element的話，那就會整個vector被轉為numeric vector；相仿地，如果numeric vector後附加一個character element的話那整個vector就會被轉為character vector。可以用sum()函式來計算logical vector有幾個TRUE值。例如sum(%%2==1)就是計算a中有幾個奇數。TRUE可視為1、FALSE可視為0，所以加總起來就是TRUE有幾個。可以用sum()函式來計算logical vector有幾個TRUE值。例如sum(%%2==1)就是計算a中有幾個奇數。TRUE可視為1、FALSE可視為0，所以加總起來就是TRUE有幾個。","code":"\nincome.c <- as.character(income)\npopulation.c <- as.numeric(population)\n\na <- seq(11, 99, 11)\na <- c(a, \"100\")\n\na <- seq(11, 99, 11)\nsum(a%%2==1)## [1] 5\nmax(a)## [1] 99"},{"path":"vectors.html","id":"character-operations","chapter":"3 Vectors","heading":"3.5 Character operations","text":"","code":"\na <- seq(11, 55, 11)\npaste(\"A\", a)       # concatenate## [1] \"A 11\" \"A 22\" \"A 33\" \"A 44\" \"A 55\"\npaste0(\"A\", a)      # concatenate## [1] \"A11\" \"A22\" \"A33\" \"A44\" \"A55\""},{"path":"dataframe.html","id":"dataframe","chapter":"4 Dataframe","heading":"4 Dataframe","text":"","code":""},{"path":"dataframe.html","id":"基本操作","chapter":"4 Dataframe","heading":"4.1 基本操作","text":"","code":""},{"path":"dataframe.html","id":"產生新的dataframe","chapter":"4 Dataframe","heading":"4.1.1 產生新的Dataframe","text":"","code":""},{"path":"dataframe.html","id":"複製資料至vector","chapter":"4 Dataframe","heading":"4.1.1.1 複製資料至vector","text":"直接複製Wikipedia上的台北市某五區人口資料","code":"\npopulation <- c(158228, 126687, 228075, 204903, 308383, 187920)\ntown <- c(\"中正\", \"大同\", \"中山\", \"松山\", \"大安\", \"萬華\")\narea <- c(7.6071, 5.6815, 13.6821, 9.2878, 11.3614, 8.8522)"},{"path":"dataframe.html","id":"合併等長vector為dataframe","chapter":"4 Dataframe","heading":"4.1.1.2 合併等長vector為dataframe","text":"","code":"\ndf <- data.frame(town, population, area)\ndf$density = df$population / df$area\nstr(df)## 'data.frame':    6 obs. of  4 variables:\n##  $ town      : chr  \"中正\" \"大同\" \"中山\" \"松山\" ...\n##  $ population: num  158228 126687 228075 204903 308383 ...\n##  $ area      : num  7.61 5.68 13.68 9.29 11.36 ...\n##  $ density   : num  20800 22298 16670 22062 27143 ...\nsummary(df)\n# View(df)"},{"path":"dataframe.html","id":"存放台灣貿易各國進出口量","chapter":"4 Dataframe","heading":"4.1.1.3 存放台灣貿易各國進出口量","text":"運用台灣出口進口資料 台灣出口進口貿易資料查詢","code":"\ncountry <- c(\"CN\", \"US\", \"JP\", \"HK\", \"KR\", \"SG\", \"DE\", \"MY\", \"VN\", \"PH\", \"TH\", \"AU\", \"NL\", \"SA\", \"ID\", \"GB\", \"IN\", \"FR\", \"IT\", \"AE\")\n\nimport <- c(26.142, 12.008, 7.032, 13.646, 4.589, 5.768, 2.131, 2.802, 3.428, 3.019, 1.976, 1.118, 1.624, 0.449, 0.983, 1.302, 1.027, 0.553, 0.670, 0.455)\n\nexport <- c(22.987, 12.204, 11.837, 7.739, 5.381, 4.610, 2.866, 2.784, 2.414, 2.092, 1.839, 1.788, 1.665, 1.409, 1.391, 1.075, 0.974, 0.899, 0.800, 0.728)"},{"path":"dataframe.html","id":"合併vector為data.frame","chapter":"4 Dataframe","heading":"4.1.1.4 合併vector為data.frame","text":"這時候我們若以str(df)觀察該df的結構會發現，文字型態的資料被轉為Factors，這是我們所不樂見的。過去統計通常會把文字型態當成類別變數，於是用Factors作為資料型態，但資料科學中經常要處理大量的文字資料，此時，我們可以把read.csv的一個參數stringsAsFactors設為FALSE，意味著預設不要將文字的資料轉為Factor而是直接以文字變項來處理。* stringsAsFactors = FALSE也是read.csv()的參數（parameter、argument）。因為一般讀檔會預設把文字讀為類別變項也就是Factor，但資料分析經常要處理文字資料而不是類別變項，所以會希望預設不要把文字讀取為類別變項，因此要設定stringsAsFactors = FALSE。這時候我們若以str(df)觀察該df的結構會發現，文字型態的資料被轉為Factors，這是我們所不樂見的。過去統計通常會把文字型態當成類別變數，於是用Factors作為資料型態，但資料科學中經常要處理大量的文字資料，此時，我們可以把read.csv的一個參數stringsAsFactors設為FALSE，意味著預設不要將文字的資料轉為Factor而是直接以文字變項來處理。* stringsAsFactors = FALSE也是read.csv()的參數（parameter、argument）。因為一般讀檔會預設把文字讀為類別變項也就是Factor，但資料分析經常要處理文字資料而不是類別變項，所以會希望預設不要把文字讀取為類別變項，因此要設定stringsAsFactors = FALSE。為了避免每次都要打這串參數，可以把它設定為全域參數，可以在程式一開始時便加上options(stringsAsFactors = FASLE)，意味著底下所有的函式如果有stringsAsFactors這個參數，一律自動設為FALSE。為了避免每次都要打這串參數，可以把它設定為全域參數，可以在程式一開始時便加上options(stringsAsFactors = FASLE)，意味著底下所有的函式如果有stringsAsFactors這個參數，一律自動設為FALSE。甚至也可以建立一個新的、空的data.frame。df.test就R的用法就是一個變數，並不是df和test各自是一個變數。","code":"\ndf <- data.frame(country, import, export)\nstr(df)## 'data.frame':    20 obs. of  3 variables:\n##  $ country: chr  \"CN\" \"US\" \"JP\" \"HK\" ...\n##  $ import : num  26.14 12.01 7.03 13.65 4.59 ...\n##  $ export : num  22.99 12.2 11.84 7.74 5.38 ...\ndf <- data.frame(country, import, export, stringsAsFactors = FALSE)\nstr(df)## 'data.frame':    20 obs. of  3 variables:\n##  $ country: chr  \"CN\" \"US\" \"JP\" \"HK\" ...\n##  $ import : num  26.14 12.01 7.03 13.65 4.59 ...\n##  $ export : num  22.99 12.2 11.84 7.74 5.38 ...\ndf.test <- data.frame()"},{"path":"dataframe.html","id":"觀察dataframe","chapter":"4 Dataframe","heading":"4.1.2 觀察dataframe","text":"View(df) 用RStudio所提供的GUI直接觀看變數head(df) 取前面六筆資料（也就是六列的資料來概觀該資料）class(df)str(df)summary(df)","code":"\n# View(df)\nhead(df)    # get first part of the data.frame##   country import export\n## 1      CN 26.142 22.987\n## 2      US 12.008 12.204\n## 3      JP  7.032 11.837\n## 4      HK 13.646  7.739\n## 5      KR  4.589  5.381\n## 6      SG  5.768  4.610\nclass(df)## [1] \"data.frame\"\nstr(df)## 'data.frame':    20 obs. of  3 variables:\n##  $ country: chr  \"CN\" \"US\" \"JP\" \"HK\" ...\n##  $ import : num  26.14 12.01 7.03 13.65 4.59 ...\n##  $ export : num  22.99 12.2 11.84 7.74 5.38 ...\nsummary(df)##    country              import           export      \n##  Length:20          Min.   : 0.449   Min.   : 0.728  \n##  Class :character   1st Qu.: 1.016   1st Qu.: 1.312  \n##  Mode  :character   Median : 2.054   Median : 1.966  \n##                     Mean   : 4.536   Mean   : 4.374  \n##                     3rd Qu.: 4.884   3rd Qu.: 4.803  \n##                     Max.   :26.142   Max.   :22.987\n# look up help\nhelp(summary)\n?summary"},{"path":"dataframe.html","id":"觀察資料維度","chapter":"4 Dataframe","heading":"4.1.2.1 觀察資料維度","text":"","code":"\ndim(df)## [1] 20  3\nncol(df)## [1] 3\nnrow(df)## [1] 20\nlength(df)## [1] 3"},{"path":"dataframe.html","id":"操作dataframe","chapter":"4 Dataframe","heading":"4.1.3 操作dataframe","text":"","code":""},{"path":"dataframe.html","id":"取出一個變項","chapter":"4 Dataframe","heading":"4.1.3.1 取出一個變項","text":"names(df) 列出變數名稱df$發生.現.地點 顯示該變數內容df$發生時段 顯示該變數內容length(df$發生時段) 顯示該變數的長度（相當於有幾個）","code":"\nnames(df)## [1] \"country\" \"import\"  \"export\"\nhead(df$發生.現.地點)## NULL\nhead(df$發生時段)## NULL\nlength(df$發生時段)## [1] 0\nsummary(df)##    country              import           export      \n##  Length:20          Min.   : 0.449   Min.   : 0.728  \n##  Class :character   1st Qu.: 1.016   1st Qu.: 1.312  \n##  Mode  :character   Median : 2.054   Median : 1.966  \n##                     Mean   : 4.536   Mean   : 4.374  \n##                     3rd Qu.: 4.884   3rd Qu.: 4.803  \n##                     Max.   :26.142   Max.   :22.987"},{"path":"dataframe.html","id":"mutate透過運算產生新變數","chapter":"4 Dataframe","heading":"4.1.3.2 (mutate)透過運算產生新變數","text":"這裡容易犯錯的是，要記得跟程式講說你要加總或四則運算的是哪個df的variable。從下面的這個操作中，該data.frame會產生一個新的變數sub，這就相當於Excel中的某一行減去某一行，然後把資料放在新的一行。","code":"\ndf$sub <- df$import - df$export"},{"path":"dataframe.html","id":"filter篩選資料選取變數","chapter":"4 Dataframe","heading":"4.1.3.3 (filter)篩選資料、選取變數","text":"注意，要告訴程式import和export是哪個data.frame的。注意，要告訴程式import和export是哪個data.frame的。df[,]為存取df中某個區段的數值或某個數值的方法。因此df[1, 1]會取出第一行第一列，也就是第一筆資料的第一個vector。df[2, 3]則會取出第二筆資料的第三個variable。df[,]為存取df中某個區段的數值或某個數值的方法。因此df[1, 1]會取出第一行第一列，也就是第一筆資料的第一個vector。df[2, 3]則會取出第二筆資料的第三個variable。下面的例子nrow(df)為1894，有1894筆資料，所以自然df\\(import與df\\)export的長度都是1894。因此，比較這兩個變數的大小會得到一個長度為1894的boolean (logical) variable。因此把這個長度為1894、充滿TRUE和FALSE的logical vector丟進df的row之處，因為取自df，大小判斷式結果的長度自然和原本的df的列數相同。因此當這個TRUE/FALSE被丟在df的列之處，便會篩選出import大於p.xport的數值。下面的例子nrow(df)為1894，有1894筆資料，所以自然df\\(import與df\\)export的長度都是1894。因此，比較這兩個變數的大小會得到一個長度為1894的boolean (logical) variable。因此把這個長度為1894、充滿TRUE和FALSE的logical vector丟進df的row之處，因為取自df，大小判斷式結果的長度自然和原本的df的列數相同。因此當這個TRUE/FALSE被丟在df的列之處，便會篩選出import大於p.xport的數值。原本的df有五個variable，而上述的操作是篩選資料，所以被篩選的是列，因此行的數量、名稱都不會變。因此，我篩選完後，直接存取這個被篩選過的data.frame的country variable，自然是可以的。原本的df有五個variable，而上述的操作是篩選資料，所以被篩選的是列，因此行的數量、名稱都不會變。因此，我篩選完後，直接存取這個被篩選過的data.frame的country variable，自然是可以的。","code":"\ndf##    country import export    sub\n## 1       CN 26.142 22.987  3.155\n## 2       US 12.008 12.204 -0.196\n## 3       JP  7.032 11.837 -4.805\n## 4       HK 13.646  7.739  5.907\n## 5       KR  4.589  5.381 -0.792\n## 6       SG  5.768  4.610  1.158\n## 7       DE  2.131  2.866 -0.735\n## 8       MY  2.802  2.784  0.018\n## 9       VN  3.428  2.414  1.014\n## 10      PH  3.019  2.092  0.927\n## 11      TH  1.976  1.839  0.137\n## 12      AU  1.118  1.788 -0.670\n## 13      NL  1.624  1.665 -0.041\n## 14      SA  0.449  1.409 -0.960\n## 15      ID  0.983  1.391 -0.408\n## 16      GB  1.302  1.075  0.227\n## 17      IN  1.027  0.974  0.053\n## 18      FR  0.553  0.899 -0.346\n## 19      IT  0.670  0.800 -0.130\n## 20      AE  0.455  0.728 -0.273\nnames(df)## [1] \"country\" \"import\"  \"export\"  \"sub\"\nnrow(df)## [1] 20\n# filter row data by column value\ndf[df$import > df$export,]##    country import export   sub\n## 1       CN 26.142 22.987 3.155\n## 4       HK 13.646  7.739 5.907\n## 6       SG  5.768  4.610 1.158\n## 8       MY  2.802  2.784 0.018\n## 9       VN  3.428  2.414 1.014\n## 10      PH  3.019  2.092 0.927\n## 11      TH  1.976  1.839 0.137\n## 16      GB  1.302  1.075 0.227\n## 17      IN  1.027  0.974 0.053\ndf[df$import > df$export,]$country## [1] \"CN\" \"HK\" \"SG\" \"MY\" \"VN\" \"PH\" \"TH\" \"GB\" \"IN\"\ndf[df$import > df$export,1]## [1] \"CN\" \"HK\" \"SG\" \"MY\" \"VN\" \"PH\" \"TH\" \"GB\" \"IN\"\n# 1 row == a data.frame with only one data entry\nclass(df[df$import > df$export,1])## [1] \"character\"\nclass(df[,1]) # character vector## [1] \"character\"\nclass(df[1,]) # data.frame## [1] \"data.frame\"\nclass(unlist(df[1, -1])) # filter the 1st row and select all columns except 1## [1] \"numeric\""},{"path":"dataframe.html","id":"arrange-按某個變數排序","chapter":"4 Dataframe","heading":"4.1.3.4 (arrange) 按某個變數排序","text":"df.sorted <- df[order(df$import),]會使得整個df照import的大小排序重新做排列。因為order(df$import)會把資料照指定順序排列後的位置傳回來，所以把他丟給df的列的位置，便會使得df的資料照指定的順序排列。\n預設是由小到大，加上decreasing = T這個參數後變成由大而小。","code":"\n# sort rows by df$import column\ndf.sorted <- df[order(df$import),]\n# View(df.sorted)\n\n# sort rows in decreasing order\ndf.sorted <- df[order(df$import, decreasing = T),]\n\n# add - to column in order() can sort in decreasing order\ndf.sorted <- df[order(-df$import),]\n\nhead(df.sorted)##   country import export    sub\n## 1      CN 26.142 22.987  3.155\n## 4      HK 13.646  7.739  5.907\n## 2      US 12.008 12.204 -0.196\n## 3      JP  7.032 11.837 -4.805\n## 6      SG  5.768  4.610  1.158\n## 5      KR  4.589  5.381 -0.792"},{"path":"dataframe.html","id":"簡易繪圖","chapter":"4 Dataframe","heading":"4.2 簡易繪圖","text":"graphics::plot()為會預載入R的繪圖套件，如果希望繪圖的同時加上回歸線和資料點標籤的話，必須要三行一起執行。","code":"\n# plot(df) # raise error, 1st column is a character vector\nplot(df[, 2:3])\nplot(df[1:10, 2:3])\ntext(import, export, labels=country, cex= 0.5, pos=3)\nlines(1:25, 1:25, col='red')\n?plot## Help on topic 'plot' was found in the following packages:\n## \n##   Package               Library\n##   graphics              /Library/Frameworks/R.framework/Versions/4.1/Resources/library\n##   base                  /Library/Frameworks/R.framework/Resources/library\n## \n## \n## 用第一個符合…"},{"path":"dataframe.html","id":"基本操作使用dplyr","chapter":"4 Dataframe","heading":"4.3 基本操作：使用dplyr","text":"","code":"\nlibrary(dplyr)\ndf <- data.frame(country, import, export, stringsAsFactors = F)\ndf <- mutate(df, sub = import - export)\nfilter(df, import > export)##   country import export   sub\n## 1      CN 26.142 22.987 3.155\n## 2      HK 13.646  7.739 5.907\n## 3      SG  5.768  4.610 1.158\n## 4      MY  2.802  2.784 0.018\n## 5      VN  3.428  2.414 1.014\n## 6      PH  3.019  2.092 0.927\n## 7      TH  1.976  1.839 0.137\n## 8      GB  1.302  1.075 0.227\n## 9      IN  1.027  0.974 0.053\nselect(df, c(1, 3))##    country export\n## 1       CN 22.987\n## 2       US 12.204\n## 3       JP 11.837\n## 4       HK  7.739\n## 5       KR  5.381\n## 6       SG  4.610\n## 7       DE  2.866\n## 8       MY  2.784\n## 9       VN  2.414\n## 10      PH  2.092\n## 11      TH  1.839\n## 12      AU  1.788\n## 13      NL  1.665\n## 14      SA  1.409\n## 15      ID  1.391\n## 16      GB  1.075\n## 17      IN  0.974\n## 18      FR  0.899\n## 19      IT  0.800\n## 20      AE  0.728\nmessage(df$country)\nprint(df$country)##  [1] \"CN\" \"US\" \"JP\" \"HK\" \"KR\" \"SG\" \"DE\" \"MY\" \"VN\" \"PH\" \"TH\" \"AU\" \"NL\" \"SA\" \"ID\"\n## [16] \"GB\" \"IN\" \"FR\" \"IT\" \"AE\""},{"path":"dataframe.html","id":"tibble-data_frame-data.frame","chapter":"4 Dataframe","heading":"4.4 tibble, data_frame, data.frame","text":"警告： \"data_frame()\" deprecated tibble 1.1.0. Please use \"tibble()\" instead.","code":"\ndf <- data.frame(a=1:2, b=3:4, c=5:6)\nclass(df)## [1] \"data.frame\"\ndf <- data_frame(a=1:2, b=3:4, c=5:6)\nclass(df)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\ndf <- tibble(a=1:2, b=3:4, c=5:6)\nclass(df)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\""},{"path":"使用基礎r套件.html","id":"使用基礎r套件","chapter":"5 使用基礎R套件","heading":"5 使用基礎R套件","text":"","code":""},{"path":"使用基礎r套件.html","id":"案例產假支薪跨國跨時比較","chapter":"5 使用基礎R套件","heading":"5.1 案例：產假支薪跨國跨時比較","text":"本案例將利用R來重製華盛頓郵報在2016/08/13的一篇談論美國婦女產假支薪情形的報導。這個案例中將會應用到data.frame和基本的繪圖與資料摘要方法。case adaped Washington Post’s paid maternity leave exmaple introduce basic skill data.frame, plotting, data mamipulation.本案例將利用R來重製華盛頓郵報在2016/08/13的一篇談論美國婦女產假支薪情形的報導。這個案例中將會應用到data.frame和基本的繪圖與資料摘要方法。case adaped Washington Post’s paid maternity leave exmaple introduce basic skill data.frame, plotting, data mamipulation.原始新聞來源：https://www.washingtonpost.com/news/worldviews/wp/2016/08/13/-world--getting-better--paid-maternity-leave--u-s--/?tid=sm_tw&utm_term=.f8cd50280326#comments原始新聞來源：https://www.washingtonpost.com/news/worldviews/wp/2016/08/13/-world--getting-better--paid-maternity-leave--u-s--/?tid=sm_tw&utm_term=.f8cd50280326#comments","code":""},{"path":"使用基礎r套件.html","id":"reading-.xlsx-by-readxl-package","chapter":"5 使用基礎R套件","heading":"5.1.1 Reading .xlsx by readxl package","text":"readxl也包含在tidyverse的套件集中，所以應該已經在前次安裝過，不用特別安裝。","code":"\n# Import readxl package\nlibrary(readxl)\noptions(stringsAsFactors = FALSE)\n# Use read_excel() to convert excel sheet to data.frame\ndf <- read_excel(\"data/WORLD-MACHE_Gender_6.8.15.xls\", \"Sheet1\", col_names=T)"},{"path":"使用基礎r套件.html","id":"previewing-data-by-view-class-dim-str-summary-and-names","chapter":"5 使用基礎R套件","heading":"5.1.2 Previewing data by View(), class(), dim(), str(), summary() and names()","text":"","code":"\n# View(df)\nclass(df)       # [1] \"tbl_df\"     \"tbl\"        \"data.frame\"## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\ndim(df)## [1] 197 156\n# Show names of variables (vectors, columns) by names()\nnames(df)##   [1] \"country\"           \"iso2\"              \"iso3\"             \n##   [4] \"region\"            \"wb_econ\"           \"matleave_95\"      \n##   [7] \"matleave_96\"       \"matleave_97\"       \"matleave_98\"      \n##  [10] \"matleave_99\"       \"matleave_00\"       \"matleave_01\"      \n##  [13] \"matleave_02\"       \"matleave_03\"       \"matleave_04\"      \n##  [16] \"matleave_05\"       \"matleave_06\"       \"matleave_07\"      \n##  [19] \"matleave_08\"       \"matleave_09\"       \"matleave_10\"      \n##  [22] \"matleave_11\"       \"matleave_12\"       \"matleave_13\"      \n##  [25] \"matleave_wrr_95\"   \"matleave_wrr_96\"   \"matleave_wrr_97\"  \n##  [28] \"matleave_wrr_98\"   \"matleave_wrr_99\"   \"matleave_wrr_00\"  \n##  [31] \"matleave_wrr_01\"   \"matleave_wrr_02\"   \"matleave_wrr_03\"  \n##  [34] \"matleave_wrr_04\"   \"matleave_wrr_05\"   \"matleave_wrr_06\"  \n##  [37] \"matleave_wrr_07\"   \"matleave_wrr_08\"   \"matleave_wrr_09\"  \n##  [40] \"matleave_wrr_10\"   \"matleave_wrr_11\"   \"matleave_wrr_12\"  \n##  [43] \"matleave_wrr_13\"   \"bf_dur_95\"         \"bf_dur_96\"        \n##  [46] \"bf_dur_97\"         \"bf_dur_98\"         \"bf_dur_99\"        \n##  [49] \"bf_dur_00\"         \"bf_dur_01\"         \"bf_dur_02\"        \n##  [52] \"bf_dur_03\"         \"bf_dur_04\"         \"bf_dur_05\"        \n##  [55] \"bf_dur_06\"         \"bf_dur_07\"         \"bf_dur_08\"        \n##  [58] \"bf_dur_09\"         \"bf_dur_10\"         \"bf_dur_11\"        \n##  [61] \"bf_dur_12\"         \"bf_dur_13\"         \"mat_bfeed_6mon_95\"\n##  [64] \"mat_bfeed_6mon_96\" \"mat_bfeed_6mon_97\" \"mat_bfeed_6mon_98\"\n##  [67] \"mat_bfeed_6mon_99\" \"mat_bfeed_6mon_00\" \"mat_bfeed_6mon_01\"\n##  [70] \"mat_bfeed_6mon_02\" \"mat_bfeed_6mon_03\" \"mat_bfeed_6mon_04\"\n##  [73] \"mat_bfeed_6mon_05\" \"mat_bfeed_6mon_06\" \"mat_bfeed_6mon_07\"\n##  [76] \"mat_bfeed_6mon_08\" \"mat_bfeed_6mon_09\" \"mat_bfeed_6mon_10\"\n##  [79] \"mat_bfeed_6mon_11\" \"mat_bfeed_6mon_12\" \"mat_bfeed_6mon_13\"\n##  [82] \"minage_fem_leg_95\" \"minage_fem_leg_96\" \"minage_fem_leg_97\"\n##  [85] \"minage_fem_leg_98\" \"minage_fem_leg_99\" \"minage_fem_leg_00\"\n##  [88] \"minage_fem_leg_01\" \"minage_fem_leg_02\" \"minage_fem_leg_03\"\n##  [91] \"minage_fem_leg_04\" \"minage_fem_leg_05\" \"minage_fem_leg_06\"\n##  [94] \"minage_fem_leg_07\" \"minage_fem_leg_08\" \"minage_fem_leg_09\"\n##  [97] \"minage_fem_leg_10\" \"minage_fem_leg_11\" \"minage_fem_leg_12\"\n## [100] \"legal_diff_leg_95\" \"legal_diff_leg_96\" \"legal_diff_leg_97\"\n## [103] \"legal_diff_leg_98\" \"legal_diff_leg_99\" \"legal_diff_leg_00\"\n## [106] \"legal_diff_leg_01\" \"legal_diff_leg_02\" \"legal_diff_leg_03\"\n## [109] \"legal_diff_leg_04\" \"legal_diff_leg_05\" \"legal_diff_leg_06\"\n## [112] \"legal_diff_leg_07\" \"legal_diff_leg_08\" \"legal_diff_leg_09\"\n## [115] \"legal_diff_leg_10\" \"legal_diff_leg_11\" \"legal_diff_leg_12\"\n## [118] \"minage_fem_pc_95\"  \"minage_fem_pc_96\"  \"minage_fem_pc_97\" \n## [121] \"minage_fem_pc_98\"  \"minage_fem_pc_99\"  \"minage_fem_pc_00\" \n## [124] \"minage_fem_pc_01\"  \"minage_fem_pc_02\"  \"minage_fem_pc_03\" \n## [127] \"minage_fem_pc_04\"  \"minage_fem_pc_05\"  \"minage_fem_pc_06\" \n## [130] \"minage_fem_pc_07\"  \"minage_fem_pc_08\"  \"minage_fem_pc_09\" \n## [133] \"minage_fem_pc_10\"  \"minage_fem_pc_11\"  \"minage_fem_pc_12\" \n## [136] \"legal_diff_pc_95\"  \"legal_diff_pc_96\"  \"legal_diff_pc_97\" \n## [139] \"legal_diff_pc_98\"  \"legal_diff_pc_99\"  \"legal_diff_pc_00\" \n## [142] \"legal_diff_pc_01\"  \"legal_diff_pc_02\"  \"legal_diff_pc_03\" \n## [145] \"legal_diff_pc_04\"  \"legal_diff_pc_05\"  \"legal_diff_pc_06\" \n## [148] \"legal_diff_pc_07\"  \"legal_diff_pc_08\"  \"legal_diff_pc_09\" \n## [151] \"legal_diff_pc_10\"  \"legal_diff_pc_11\"  \"legal_diff_pc_12\" \n## [154] \"minwage_ppp_2013\"  \"mw_overtime\"       \"oecd\""},{"path":"使用基礎r套件.html","id":"select-variables","chapter":"5 使用基礎R套件","heading":"5.1.3 Select variables","text":"","code":"\n# Select the 3rd and 6th to 24th columns\nmatleave <- df[ , c(3, 6:24)]\n\n# Use class(), dim(), and str() to inspect the data\nclass(matleave)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\ndim(matleave)## [1] 197  20\nstr(matleave)## tibble [197 × 20] (S3: tbl_df/tbl/data.frame)\n##  $ iso3       : chr [1:197] \"AFG\" \"ALB\" \"DZA\" \"AND\" ...\n##  $ matleave_95: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_96: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_97: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_98: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_99: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_00: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_01: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_02: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_03: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_04: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_05: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_06: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_07: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_08: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_09: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_10: num [1:197] 2 5 3 3 2 2 2 5 NA 5 ...\n##  $ matleave_11: num [1:197] 2 5 3 3 2 2 2 5 3 5 ...\n##  $ matleave_12: num [1:197] 2 5 3 3 2 2 2 5 3 5 ...\n##  $ matleave_13: num [1:197] 2 5 3 3 2 2 2 5 3 5 ..."},{"path":"使用基礎r套件.html","id":"check-replace-nas","chapter":"5 使用基礎R套件","heading":"5.1.4 Check & Replace NAs","text":"NA: Availablev[.na(v)] select NA cells以0取代NA的資料格。避免繪圖產生錯誤sum(.na(matleave))的目的是檢測還有沒有NA值。如果有的話is.na()就會是TRUE，那麼加總後，如果不是0，那就代表還有NA。","code":"\n# is.na() to indicate each element is NA or NOT(TRUE/FALSE)\nhead(is.na(matleave), n=20)##        iso3 matleave_95 matleave_96 matleave_97 matleave_98 matleave_99\n##  [1,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [2,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [3,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [4,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [5,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [6,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [7,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [8,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [9,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [10,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [11,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [12,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [13,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [14,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [15,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [16,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [17,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [18,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [19,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [20,] FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##       matleave_00 matleave_01 matleave_02 matleave_03 matleave_04 matleave_05\n##  [1,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [2,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [3,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [4,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [5,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [6,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [7,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [8,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [9,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [10,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [11,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [12,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [13,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [14,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [15,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [16,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [17,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [18,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [19,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [20,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##       matleave_06 matleave_07 matleave_08 matleave_09 matleave_10 matleave_11\n##  [1,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [2,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [3,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [4,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [5,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [6,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [7,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [8,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n##  [9,]       FALSE       FALSE       FALSE       FALSE        TRUE       FALSE\n## [10,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [11,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [12,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [13,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [14,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [15,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [16,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [17,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [18,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [19,]       FALSE       FALSE       FALSE       FALSE       FALSE       FALSE\n## [20,]       FALSE        TRUE        TRUE       FALSE       FALSE       FALSE\n##       matleave_12 matleave_13\n##  [1,]       FALSE       FALSE\n##  [2,]       FALSE       FALSE\n##  [3,]       FALSE       FALSE\n##  [4,]       FALSE       FALSE\n##  [5,]       FALSE       FALSE\n##  [6,]       FALSE       FALSE\n##  [7,]       FALSE       FALSE\n##  [8,]       FALSE       FALSE\n##  [9,]       FALSE       FALSE\n## [10,]       FALSE       FALSE\n## [11,]       FALSE       FALSE\n## [12,]       FALSE       FALSE\n## [13,]       FALSE       FALSE\n## [14,]       FALSE       FALSE\n## [15,]       FALSE       FALSE\n## [16,]       FALSE       FALSE\n## [17,]       FALSE       FALSE\n## [18,]       FALSE       FALSE\n## [19,]       FALSE       FALSE\n## [20,]       FALSE       FALSE\n# Assign 0 to those NA data\nmatleave[is.na(matleave)] <- 0\n\n# anyNA() to check if there are still NA cells.\nanyNA(matleave)## [1] FALSE\n# sum(is.na()) to count the number of NA\nsum(is.na(matleave))## [1] 0"},{"path":"使用基礎r套件.html","id":"filtering-data","chapter":"5 使用基礎R套件","heading":"5.1.5 Filtering data","text":"","code":""},{"path":"使用基礎r套件.html","id":"filtered-by-the-last-year-value","chapter":"5 使用基礎R套件","heading":"5.1.5.1 Filtered by the last year value","text":"","code":"\n# Use logical comparison to see if the last year equals to 5\n# Assign matching data to var m5\nm5 <- matleave[matleave$'matleave_13'==5, ]\n\n# nrow() to count matching data\nnrow(m5)## [1] 34\n# Is it possible to use length() to check the data length?\n# matleave$'matleave_13'\n# matleave$'matleave_13'==5\n# length(matleave$'matleave_13'==5)"},{"path":"使用基礎r套件.html","id":"filtered-data-by-the-first-year-value","chapter":"5 使用基礎R套件","heading":"5.1.5.2 Filtered data by the first year value","text":"","code":"\n# filter rows whose 'matleave_95' is 5, and assign to var m55\nm55<- m5[m5$'matleave_95'==5,]\n\n# filter rows whose 'matleave_95' is not 5, and assign to var m05\nm05<- m5[m5$'matleave_95'!=5,]"},{"path":"使用基礎r套件.html","id":"plotting","chapter":"5 使用基礎R套件","heading":"5.1.6 Plotting","text":"Plotting second rows columns except 1st columnQuestion 為何要unlist()？請試著執行barplot(matleave[2, -1])這個沒有unlist()的版本，看看會有什麼錯誤訊息。資料結構有何差異呢？嘗試用class()或str()嘗試觀察沒有unlist()版本的資料，看看資料型態和有unlist()的會有何不同？","code":""},{"path":"使用基礎r套件.html","id":"plotting-one-line","chapter":"5 使用基礎R套件","heading":"5.1.6.1 Plotting one line","text":"Testing","code":"\n# barplot() the second row of m55\n# barplot(m55[2, ])       # raise error\n\n# barplot() the second row when neglecting the first column\n# barplot(m55[2, -1])     # raise error\n\n# Take a look at the data type of matleave[2, ]\nclass(matleave[2, -1])## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nclass(unlist(matleave[2, -1]))## [1] \"numeric\"\n# unlist() to convert a single row data.frame to a vector for barplot()\nbarplot(unlist(m55[2, -1]))\n# View(matleave[1]) # select the 1st variable\n# View(matleave[ ,1]) # select the 1st column\n# View(matleave[1, ]) # select the 1st row\n\nclass(m55[1])       # \"tbl_df\"     \"tbl\"        \"data.frame\"## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nclass(m55[ ,1]) # \"tbl_df\"     \"tbl\"        \"data.frame\"## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nclass(m55[1, ]) # \"tbl_df\"     \"tbl\"        \"data.frame\"## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nclass(m55$iso3) # character (vector)## [1] \"character\""},{"path":"使用基礎r套件.html","id":"more-arguments-args","chapter":"5 使用基礎R套件","heading":"5.1.6.2 More arguments (args)","text":"","code":"\n# barplot() the unlisted second row (neglecting the first col)\nbarplot(unlist(m55[2, -1]))\n# use ?barplot to know more argument of the function.\n?barplot\n\n# Add arguments ylim, space, border, and axat/yaxt one by one to barplot()\nbarplot(unlist(m55[2, -1]), ylim=c(0, 5))\nbarplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0)\nbarplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA)\nbarplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")"},{"path":"使用基礎r套件.html","id":"plotting-multiple-lines","chapter":"5 使用基礎R套件","heading":"5.1.6.3 Plotting multiple lines","text":"底下可以看見每一行非常相似且一致的特徵，僅有matleave內的索引由1被列出至6。因此，最好的方法是用迴圈（-loop）的方式將相同的程式碼，從1~6之間做六次。","code":"\n# plot the first row\nbarplot(unlist(m55[1, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\n\n# plot the second to 6th rows\nbarplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\nbarplot(unlist(m55[3, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\nbarplot(unlist(m55[4, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\nbarplot(unlist(m55[5, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\nbarplot(unlist(m55[6, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")"},{"path":"使用基礎r套件.html","id":"for-loop-to-plot-multiple-lines","chapter":"5 使用基礎R套件","heading":"5.1.6.4 for-loop to plot multiple lines","text":"","code":"\n# use for loop and use i as index to barplot multiple subgraphs\nfor(i in 1:6){\n  barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\n}"},{"path":"使用基礎r套件.html","id":"sub-plots","chapter":"5 使用基礎R套件","heading":"5.1.6.5 Sub-plots","text":"Check ?par get paremeters plottingCheck ?par get paremeters plotting**mai**: numerical vector form c(bottom, left, top, right) gives margin size specified inches.**mai**: numerical vector form c(bottom, left, top, right) gives margin size specified inches.**mfcol, mfrow**:vector form c(nr, nc). Subsequent figures drawn nr--nc array device columns (mfcol), rows (mfrow), respectively.**mfcol, mfrow**:vector form c(nr, nc). Subsequent figures drawn nr--nc array device columns (mfcol), rows (mfrow), respectively.","code":"\n# use ?par to get more plotting parameters\n?par\n\n# use par() to set-up the layout of subgraphs\n# use the parameter main=c(0.2, 0.2, 0.2, 0.2) to thrink the padding of figures.\npar(mfrow=c(3,2), mai= c(0.2, 0.2, 0.2, 0.2))\nfor(i in 1:6){\n  barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\n}\n# plot more rows to see what happens\npar(mfrow=c(3,2), mai= c(0.2, 0.2, 0.2, 0.2))\nfor(i in 1:10){\n    barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=\"n\", yaxt=\"n\")\n}\n# plot all subplots in a figure\n# nrow() to check number of row of m55.\nnrow(m55)## [1] 18\n# use par() to set-up plotting parameters.\npar(mfrow=c(4, 6), mai= c(0.2, 0.2, 0.2, 0.2))\n\n# use for-loop to plot all graph as subgraph\nfor (i in 1:nrow(m55)){\n  barplot(unlist(m55[i, -1]), border=NA, space=0, xaxt=\"n\", yaxt=\"n\", ylim = c(0,5))\n}\npar(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2))\nfor (i in 1:nrow(m55)){\n    barplot(unlist(m55[i, -1]), border=NA, space=0,xaxt=\"n\", yaxt=\"n\", ylim = c(0,5))\n    title(m55[i,1], line = -4, cex.main=3)\n}"},{"path":"使用基礎r套件.html","id":"practice02_1_1-plotting-more","chapter":"5 使用基礎R套件","heading":"5.1.7 Practice02_1_1 Plotting more","text":"","code":"\n# plotting matleave_95 != 5 but matleve_13 == 5\n\n# plotting for matleave_13 == 4"},{"path":"使用基礎r套件.html","id":"practice02_2_2-selecting-and-filtering-by-dplyr-i","chapter":"5 使用基礎R套件","heading":"5.1.8 Practice02_2_2 selecting and filtering by dplyr I","text":"","code":"\ndf <- read_excel(\"data/WORLD-MACHE_Gender_6.8.15.xls\", \"Sheet1\", col_names=T)\n\n# select columns by index\n# matleave <- df[ , c(3, 6:24)]\n\n# select all NA cells and assign 0 to them\n# matleave[is.na(matleave)] <- 0\n\n# filter rows by condition\n# m5 <- matleave[matleave$'matleave_13' == 5, ]\n\n# filter rows by condition\n# m55<- m5[m5$'matleave_95' == 5,]\n\n# plot\npar(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2))\nfor (i in c(1:nrow(m55))){\n    barplot(unlist(m55[i,-1]),\n            border=NA, space=0,xaxt=\"n\", yaxt=\"n\", ylim = c(0,5))\n    title(m55[i,1], line = -4, cex.main=3)\n}"},{"path":"使用基礎r套件.html","id":"more-clean-version","chapter":"5 使用基礎R套件","heading":"5.1.9 (More) Clean version","text":"","code":"\n# readxl::read_excel() to import the xls file\ndf <- read_excel(\"data/WORLD-MACHE_Gender_6.8.15.xls\", \"Sheet1\", col_names=T)\n\n# select iso3, and matleave columns by index\nmatleave <- df[ , c(3, 6:24)]\n\n# str() to inspect the data structure of \nstr(matleave)## tibble [197 × 20] (S3: tbl_df/tbl/data.frame)\n##  $ iso3       : chr [1:197] \"AFG\" \"ALB\" \"DZA\" \"AND\" ...\n##  $ matleave_95: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_96: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_97: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_98: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_99: num [1:197] 2 5 3 2 2 2 2 3 1 5 ...\n##  $ matleave_00: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_01: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_02: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_03: num [1:197] 2 5 3 3 2 2 2 3 1 5 ...\n##  $ matleave_04: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_05: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_06: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_07: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_08: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_09: num [1:197] 2 5 3 3 2 2 2 5 1 5 ...\n##  $ matleave_10: num [1:197] 2 5 3 3 2 2 2 5 NA 5 ...\n##  $ matleave_11: num [1:197] 2 5 3 3 2 2 2 5 3 5 ...\n##  $ matleave_12: num [1:197] 2 5 3 3 2 2 2 5 3 5 ...\n##  $ matleave_13: num [1:197] 2 5 3 3 2 2 2 5 3 5 ...\n# select all NA cells and assign 0 to them\nmatleave[is.na(matleave)] <- 0\n\n# filter rows by condition\nm5 <- matleave[matleave$'matleave_13' == 5, ]\n\n# filter rows by condition\nm55<- m5[m5$'matleave_95' == 5,]\n\n# plot\npar(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2))\nfor (i in c(1:nrow(m55))){\n    barplot(unlist(m55[i,-1]),\n            border=NA, space=0,xaxt=\"n\", yaxt=\"n\", ylim = c(0,5))\n    title(m55[i,1], line = -4, cex.main=3)\n}\nlibrary(tidyverse)\noptions(stringsAsFactors = F)\noptions(scipen = 999)\n\nlibrary(readxl)\nread_excel(\"data/WORLD-MACHE_Gender_6.8.15.xls\", \"Sheet1\", col_names=T) %>% \n    select(iso3, 6:24) %>% \n    filter(matleave_13 == 5, matleave_95 == 5) %>% \n    gather(\"year\", \"degree\", 2:20) %>% \n    # spread(year, degree, fill = 0) %>% View\n    replace_na(list(degree = 0)) %>%\n    mutate(year2 = as.POSIXct(strptime(year, \"matleave_%y\"))) %>%\n    mutate(year3 = lubridate::year(year2)) %>%\n    ggplot() + \n    aes(year3, degree) + \n    geom_col(color = \"royalblue\", fill = \"royalblue\") + \n    facet_wrap(~ iso3) +\n    theme_void()"},{"path":"使用基礎r套件.html","id":"more-the-fittest-version-to-compute-staysame","chapter":"5 使用基礎R套件","heading":"5.1.10 (More) The fittest version to compute staySame","text":"","code":"\n# staySame version\n# staySame <- apply(m5[,2:20], 1, function(x) length(unique(x[!is.na(x)]))) \n# m55 <- m5[staySame, ]\n# m50 <- m5[!staySame, ]"},{"path":"使用基礎r套件.html","id":"樞紐分析台北住宅竊盜點位","chapter":"5 使用基礎R套件","heading":"5.2 樞紐分析：台北住宅竊盜點位","text":"","code":""},{"path":"使用基礎r套件.html","id":"讀取檔案","chapter":"5 使用基礎R套件","heading":"5.2.1 讀取檔案","text":"首先要至臺北資料大平台上查詢「住宅竊盜」，可以找到臺北市住宅竊盜點位資訊。將該CSV檔下載至個人本機端，置入data 資料夾中，便可以用read.csv()讀取該檔案。read.csv() read csv convert data.frame用readr::read_csv()來讀取。。除了 base套件的read.csv()外，也可使用readr套件的read_csv()函式來讀取，該套件屬於tidyverse套件系的其中一個套件，如果已經有用install.packages(\"tidyverse\")安裝過，只要用library(tidyverse)就可以使用read_csv()函式。在此鼓勵各位使用tidyverse系列套件。普遍來說，read_csv() 的功能和效果都會比read.csv()好，該函式還會自動猜測每個變數的變數型態並直接進行轉換（尤其是有時間欄位的時候，會非常方便）。除錯：萬一遇到中文檔案會有讀檔編碼問題時，有可能該檔案是用big5來儲存的，可以在read_csv()中設定locale來指定讀取的編碼方法。如read_csv(url, locale = locale(encoding = \"Big5\"))直接依資料網址讀取檔案。現在的程式語言所設計的讀取檔案函式通常會允許使用者直接讀取資料所在的URL。所以，我們可以直接從網路上載入台北市竊盜案資料。首先要至臺北資料大平台上查詢「住宅竊盜」，可以找到臺北市住宅竊盜點位資訊，點選後對右上方的下載按右鍵可取得鏈結到該資料的URL（如https://data.taipei/api/getDatasetInfo/downloadResource?id=68785231-d6c5-47a1-b001-77eec70bec02&rid=93d9bc2d-af08-4db7-a56b-9f0a49226fa3）。由於該資料網址似非永久網址，故本範例並未執行以下程式碼，僅提供範例程式碼讓個人替換網址來做測試。(參考) 用R程式將該網址的檔案抓回本機端儲存。部分Mac電腦無法使用read.csv()從網路上取得資料又轉為data.frame，一個可行的辦法是先用GET(url,write_disk(\"data/tptheft.csv\"))將其取回並命名為data/tptheft.csv，之後再用df <- read.csv(\"data/tptheft.csv\")直接讀取該檔案。","code":"\ndf <- read.csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\")\nhead(df) ##   編號     案類 發生日期 發生時段                                    發生地點\n## 1    1 住宅竊盜  1030623    08~10                  臺北市中正區廈門街91~120號\n## 2    2 住宅竊盜  1040101    00~02              臺北市文山區萬美里萬寧街1~30號\n## 3    3 住宅竊盜  1040101    00~02 臺北市信義區富台里忠孝東路5段295巷6弄1~30號\n## 4    4 住宅竊盜  1040101    06~08             臺北市中山區新生北路1段91~120號\n## 5    5 住宅竊盜  1040101    10~12           臺北市文山區明興里興隆路4段1~30號\n## 6    6 住宅竊盜  1040102    00~02   臺北市士林區天福里1鄰忠誠路2段130巷1~30號\nstr(df)         # Checking the strcutrue of it## 'data.frame':    3347 obs. of  5 variables:\n##  $ 編號    : int  1 2 3 4 5 6 7 8 9 10 ...\n##  $ 案類    : chr  \"住宅竊盜\" \"住宅竊盜\" \"住宅竊盜\" \"住宅竊盜\" ...\n##  $ 發生日期: int  1030623 1040101 1040101 1040101 1040101 1040102 1040102 1040102 1040102 1040104 ...\n##  $ 發生時段: chr  \"08~10\" \"00~02\" \"00~02\" \"06~08\" ...\n##  $ 發生地點: chr  \"臺北市中正區廈門街91~120號\" \"臺北市文山區萬美里萬寧街1~30號\" \"臺北市信義區富台里忠孝東路5段295巷6弄1~30號\" \"臺北市中山區新生北路1段91~120號\" ...\nsummary(df)     # glimpse() is the tibble package's function.##       編號            案類              發生日期         發生時段        \n##  Min.   :   1.0   Length:3347        Min.   :1030623   Length:3347       \n##  1st Qu.: 837.5   Class :character   1st Qu.:1050320   Class :character  \n##  Median :1674.0   Mode  :character   Median :1060708   Mode  :character  \n##  Mean   :1674.0                      Mean   :1063954                     \n##  3rd Qu.:2510.5                      3rd Qu.:1080306                     \n##  Max.   :3347.0                      Max.   :1110328                     \n##    發生地點        \n##  Length:3347       \n##  Class :character  \n##  Mode  :character  \n##                    \n##                    \n## \nlibrary(readr)\ndf <- read_csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\")\n# df <- read_csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\", locale = locale(encoding = \"Big5\"))\ndf %>% head()"},{"path":"使用基礎r套件.html","id":"查看資料內容","chapter":"5 使用基礎R套件","heading":"5.2.2 查看資料內容","text":"View(df) 用RStudio所提供的GUI直接觀看變數。自行移去#註解符號來測試，因為knit成html檔時，有View()的指令都會造成knit程序中斷。head(df) 取前面六筆資料（也就是六列的資料來概觀該資料）class(df) 印出該str(df)","code":"\n# View(df)\nhead(df)    # get first part of the data.frame\nclass(df)## [1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\"\nstr(df)## spec_tbl_df [3,347 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n##  $ 編號    : num [1:3347] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ 案類    : chr [1:3347] \"住宅竊盜\" \"住宅竊盜\" \"住宅竊盜\" \"住宅竊盜\" ...\n##  $ 發生日期: num [1:3347] 1030623 1040101 1040101 1040101 1040101 ...\n##  $ 發生時段: chr [1:3347] \"08~10\" \"00~02\" \"00~02\" \"06~08\" ...\n##  $ 發生地點: chr [1:3347] \"臺北市中正區廈門街91~120號\" \"臺北市文山區萬美里萬寧街1~30號\" \"臺北市信義區富台里忠孝東路5段295巷6弄1~30號\" \"臺北市中山區新生北路1段91~120號\" ...\n##  - attr(*, \"spec\")=\n##   .. cols(\n##   ..   編號 = col_double(),\n##   ..   案類 = col_character(),\n##   ..   發生日期 = col_double(),\n##   ..   發生時段 = col_character(),\n##   ..   發生地點 = col_character()\n##   .. )\n##  - attr(*, \"problems\")=<externalptr>\nsummary(df)\n# look up help"},{"path":"使用基礎r套件.html","id":"觀察資料維度-1","chapter":"5 使用基礎R套件","heading":"5.2.3 觀察資料維度","text":"e.g., dim(), ncol(), nrow(),length()","code":"\ndim(df)## [1] 3347    5\nncol(df)## [1] 5\nnrow(df)## [1] 3347\nlength(df)## [1] 5"},{"path":"使用基礎r套件.html","id":"觀察變數名稱","chapter":"5 使用基礎R套件","heading":"5.2.4 觀察變數名稱","text":"names(df) 列出變數名稱df$發生地點 顯示該變數內容df$發生時段 顯示該變數內容length(df$發生時段) 顯示該變數的長度（相當於有幾個）","code":"\nnames(df)## [1] \"編號\"     \"案類\"     \"發生日期\" \"發生時段\" \"發生地點\"\nhead(df$發生地點)## [1] \"臺北市中正區廈門街91~120號\"                 \n## [2] \"臺北市文山區萬美里萬寧街1~30號\"             \n## [3] \"臺北市信義區富台里忠孝東路5段295巷6弄1~30號\"\n## [4] \"臺北市中山區新生北路1段91~120號\"            \n## [5] \"臺北市文山區明興里興隆路4段1~30號\"          \n## [6] \"臺北市士林區天福里1鄰忠誠路2段130巷1~30號\"\nhead(df$發生時段)## [1] \"08~10\" \"00~02\" \"00~02\" \"06~08\" \"10~12\" \"00~02\"\nlength(df$發生時段)## [1] 3347"},{"path":"使用基礎r套件.html","id":"萃取所需新變項","chapter":"5 使用基礎R套件","heading":"5.2.5 萃取所需新變項","text":"該data.frame包含編號、案類、發生日期、發生時段、發生地點五個變項。其中比較有意義的應該是發生日期、發生時段和發生地點。然而，發生地點幾乎是完整地址，除非要繪製發生的地圖點位地圖，才會需要近乎完整的地址。假設我們的目標是抽取出台北市的「行政區」，發生地點的格式還蠻一致的如「臺北市中正區廈門街91120號」。因此，我們只要抽出發生地點的第4到第5個字，或者第46個字即可。從一個字串中抽取出第n個字到第m個字，要用substr()或stringr套件的str_sub()。可以用?substr或?str_sub查詢help中的相關用法。在此我將中文變數現在時間的資料指給一個新的英文變項time。從變數發生地點，用substr()取出行政區（region）或用stringr::str_sub()?substr查詢其用法和意義。相當於getting sub string since x y。Practice. 萃取月份作為新變項month除了時間和地區可能會有差別外，那月份會不會竊盜案的數量也有差異呢？會不會冬天小偷也都在家休息了，夏天多呢？請嘗試從發生日期萃取出竊盜案發生的月份，並儲存為一個新的變項month。","code":"\n# Get substring of var \"發生時段\" and assign to a new time var\ndf$time <- df$發生時段\n\n# Get substring of var \"發生地點\" and assign to a new region var\ndf$region <- substr(df$發生地點, 4, 5)\nhead(df)\n# YOUR CODE SHOULD BE HERE"},{"path":"使用基礎r套件.html","id":"iv.-樞紐分析計數加總與彙整","chapter":"5 使用基礎R套件","heading":"5.2.6 IV. 樞紐分析：計數、加總與彙整。","text":"Pivot analysis: Counting Summarizing 清理完資料後，我們要回答的第一個數據問題通常是「那XXX的案例有幾個？」例如：大安區有多少竊盜案？10~12這個時段有多少案例。","code":""},{"path":"使用基礎r套件.html","id":"方法一counting-by-table","chapter":"5 使用基礎R套件","heading":"5.2.7 方法一：Counting by table()","text":"table()函式可以對Vector中的值進行計數（Counting）。table(df$time) 相當於去計數不同的時間區間出現多少起案例；table(df$region) 相當於去計數不同地區各出現多少起案例。提示：可以用class(tb_1) 觀察用table() 計數後所產生的資料型態（table）。","code":"\n# counting the frequency of time variable\n(tb_1 <- table(df$time)) ## \n## 00~02 02~04 03~05 04~06 05~07 06~08 08~10 09~11 10~12 11~03 11~13 12~14 12~15 \n##   272   214     8   156    23   191   305     6   338     1    26   338     2 \n## 14~16 15~17 15~18 16~18 17~19 18~20 18~21 19~21 20~22 21~23 21~24 22~24 23~01 \n##   342     3     1   246    21   314     1     4   303     5     1   206    20\nclass(tb_1)       # table## [1] \"table\"\n# counting the frequency of region variable\ntable(df$region)## \n## 北投 大安 大同 南港 內湖 士林 松山 萬華 文山 信義 中山 中正 \n##  318  311  172  181  303  373  220  350  204  214  438  263"},{"path":"使用基礎r套件.html","id":"方法二counting-by-tapply","chapter":"5 使用基礎R套件","heading":"5.2.8 方法二：Counting by tapply()","text":"我們也可用tapply() 函式來達到一樣的目的。Apply家族的函式都是，針對某個資料，將某個函式套用到某個物件上。tapply() 即是用來做計數的，tapply(df$編號, df$time, length)有三個輸入，第一個輸入為整體物件，第二個輸入為要據以彙整的變項，在此為df$time，第三個是要用來彙整的函式，因為這裡要做計數，所以要用length函式。註：同樣用class()來觀察彙整後的資料型態為array，和前者的table資料型態不同。","code":"\n# tapply() one arbitrary var by var time with length() function\n(tb_2 <- tapply(df$編號, df$time, length))## 00~02 02~04 03~05 04~06 05~07 06~08 08~10 09~11 10~12 11~03 11~13 12~14 12~15 \n##   272   214     8   156    23   191   305     6   338     1    26   338     2 \n## 14~16 15~17 15~18 16~18 17~19 18~20 18~21 19~21 20~22 21~23 21~24 22~24 23~01 \n##   342     3     1   246    21   314     1     4   303     5     1   206    20\nclass(tb_2)## [1] \"array\"\n# tapply() one arbitrary var by var region with length() function\ntapply(df$編號, df$region, length)## 北投 大安 大同 南港 內湖 士林 松山 萬華 文山 信義 中山 中正 \n##  318  311  172  181  303  373  220  350  204  214  438  263"},{"path":"使用基礎r套件.html","id":"v.-依照變數值篩選資料","chapter":"5 使用基礎R套件","heading":"5.2.9 V. 依照變數值篩選資料","text":"該項竊盜案資料整理時經常不慎用不同的時間區間來標記，有時候也會不小心把新北市的資料給那進來，所以需要做資料篩選。從各個時間區間的竊盜案出現次數來觀察，有少數的案件出現在奇數的時間區間如09~11或12~15等等需要篩除；從各個行政區的竊盜案出現次數來觀察，確實都是台北市的竊盜案。接下來要用base套件的R，根據某個變數值（例如上述的時間）來篩出符合條件的資料，或者篩去不符合條件的資料。其語法是要在df[ , ]逗號前加上篩選的條件，也就是對資料列進行篩選，篩出或篩除都是以整列為單位。在此的條件是df$time在00~02、02~04、…之間；或者是df$time不在03~05、05~07、…之間。表示法分別如下：%% 表示的是左方df$time的值是否是右方Vector中的其中一個%% 表示的是左方df$time的值是否是右方Vector中的其中一個如果要表示不包含，就在df%time加一個NOT，也就是!。如果要表示不包含，就在df%time加一個NOT，也就是!。依照各組時間的案例個數統計後，篩除資料未足100的時間區間如下，最後再用table(df$time) 計算一次，發現每個時段都兩三、百個案例，且涵蓋整日的時間。清理後沒有重疊的時間區間，做類別資料分析會比較準確。","code":"df$time %in% c(\"00~02\", \"02~04\", \"04~6\",...)\n!df$time %in% c(\"03~05\", \"05~07\", ...)\n# filter out irrelevant timestamp\ndf <- df[!df$time %in% c(\"03~05\", \"05~07\", \"09~11\", \"11~13\", \"12~15\", \"15~17\", \"15~18\", \"17~19\", \" 18~21\", \"19~21\", \"21~23\", \"21~24\", \"23~01\"), ]\n\ntable(df$time)## \n## 00~02 02~04 04~06 06~08 08~10 10~12 11~03 12~14 14~16 16~18 18~20 18~21 20~22 \n##   272   214   156   191   305   338     1   338   342   246   314     1   303 \n## 22~24 \n##   206\n# filter out irrelevant region(area)\n# df <- df[!df$region %in% c(\"三重\", \"中和\", \"淡水\", \"板橋\"), ]"},{"path":"使用基礎r套件.html","id":"vi.-雙變數樞紐分析","chapter":"5 使用基礎R套件","heading":"5.2.10 VI. 雙變數樞紐分析","text":"類別變項分析通常是要考驗兩個變項間的關係，從上述的計數中，我可以看見不同行政區或者不同時間的竊盜案數量，但我進一步想知道，那不同行政區的竊盜案常發生時間是否不同？這時後就要做時間和行政區的交叉分析。我們同樣可以用table()和tapply()來做兩個變項的交叉分析，寫法如下。","code":""},{"path":"使用基礎r套件.html","id":"by-table","chapter":"5 使用基礎R套件","heading":"5.2.10.1 (1) by table()","text":"用table()來交叉分析的結果如下，所得到的結果之變數型態仍是table型態。","code":"\n# Tabulating time and region variables\n(res_table <- table(df$time, df$region))##        \n##         北投 大安 大同 南港 內湖 士林 松山 萬華 文山 信義 中山 中正\n##   00~02   24   24   15   19   20   28    4   17   17   27   62   15\n##   02~04   17   15   10   12   15   29   13   29   14   12   26   22\n##   04~06   17   14   15    6   15   14    5   22    8   11   22    7\n##   06~08   24   19    9   13   16   17   11   21    9   13   20   19\n##   08~10   22   31   17   16   27   24   24   34   18   20   45   27\n##   10~12   35   34   12   19   33   35   35   41   18   18   38   20\n##   11~03    0    0    0    0    0    0    0    0    0    0    1    0\n##   12~14   34   49   12   15   26   46   23   33   25   20   30   25\n##   14~16   32   32   26   20   39   40   22   32   19   18   43   19\n##   16~18   33   25   13   11   24   30   20   26   16    8   21   19\n##   18~20   40   23   13   18   22   31   17   23   23   23   39   42\n##   18~21    0    0    0    0    0    0    0    0    0    0    1    0\n##   20~22   17   26   13   20   34   41   25   37   15   22   40   13\n##   22~24   15   12    9    9   18   23   14   20   17   16   33   20\n# Checking it class and its content\nclass(res_table)## [1] \"table\""},{"path":"使用基礎r套件.html","id":"by-tapply","chapter":"5 使用基礎R套件","heading":"5.2.10.2 (2) by tapply()","text":"用tapply()來做兩個變數交叉分析的語法如下，必須要把兩個Vector包在一個list()中。其他不變。兩個變項用tapply()交叉分析後的結果，變數型態會變成matrix。前者用table()來交叉分析的仍是table型態。","code":"\nres_tapply <- tapply(df$編號, list(df$time, df$region), length)\nclass(res_tapply)## [1] \"matrix\" \"array\"\nres_tapply##       北投 大安 大同 南港 內湖 士林 松山 萬華 文山 信義 中山 中正\n## 00~02   24   24   15   19   20   28    4   17   17   27   62   15\n## 02~04   17   15   10   12   15   29   13   29   14   12   26   22\n## 04~06   17   14   15    6   15   14    5   22    8   11   22    7\n## 06~08   24   19    9   13   16   17   11   21    9   13   20   19\n## 08~10   22   31   17   16   27   24   24   34   18   20   45   27\n## 10~12   35   34   12   19   33   35   35   41   18   18   38   20\n## 11~03   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA    1   NA\n## 12~14   34   49   12   15   26   46   23   33   25   20   30   25\n## 14~16   32   32   26   20   39   40   22   32   19   18   43   19\n## 16~18   33   25   13   11   24   30   20   26   16    8   21   19\n## 18~20   40   23   13   18   22   31   17   23   23   23   39   42\n## 18~21   NA   NA   NA   NA   NA   NA   NA   NA   NA   NA    1   NA\n## 20~22   17   26   13   20   34   41   25   37   15   22   40   13\n## 22~24   15   12    9    9   18   23   14   20   17   16   33   20\n# View(res)"},{"path":"使用基礎r套件.html","id":"by-dplyrcount","chapter":"5 使用基礎R套件","heading":"5.2.10.3 (3) by dplyr::count()","text":"這邊多介紹一個用dplyr套件的count()函式來做交叉分析的方法（未來會常用這個方法，因為dplyr是tidyverse系列套件的核心套件。dplyr的函式第一個參數永遠是該data.frame， 例如count()；後面time與region則是這個data.frame中的兩個變項。不像tapply()或table()的結果一樣，欄與列分別為time與region，count()出來的結果會有兩個變項分別是指定要計數的time與region ，且會新增一個變項n，代表這組數據（time x region）共有幾個。這種表達型態通常稱為long-table（長表）、而tapply()或table() 的結果通常稱為wide-table（寬表）為典型的交叉分析表。目前大部分的類別資料分析還是會採用交叉分析表的型態，但未來我們要用tidyverse系列套件做大量的數據彙整或視覺化時，都會盡可能想辦法轉為Long-table型態，讓每一欄剛好就是一個變項。只要是tidyverse系列套件所計算出來的資料型態幾乎都是類似data.frame的型態，例如觀察count的結果便是\"tbl_df\"     \"tbl\"        \"data.frame\"。那長表列可以轉為寬表嗎？可以，tidyverse系列套件中的tidyr套件有個函式spread()可以接著把某個變項展開為欄。例如原本上述的列是時間與行政區的交叉組合，但我可以把行政區展開為欄、或者把時間展開為欄。spread(res_count, region, n, fill = 0) 有四個參數，遵循tidyverse系列套件的規則，第一個位置為data.frame，第二個參數則是要被展開至欄的變項這裡為region，第三個參數則是因應region被展開後，那中間交叉分析的數值就是n，最後一個參數是避免spread時有些交叉組是沒有資料的，因此fill=0可以指定，如果某個time x region的交叉組別是沒資料的，就填上0，也有可能是用fill=NA填上NA。以下的例子中也提供了將time 展開至欄的寫法供參考。展開後的資料型態和前者計數後的資料型態一樣，都是\"tbl_df\"     \"tbl\"        \"data.frame\"。這是為什麼tidyverse系列的套件逐漸變成R的顯學的原因之一。寬表格亦可用tidyr的gather()函式轉回長表格型態：Practice 使用count()來計數請練習看看如果用count()來計數單一變項，如前述的region、time或前面練習中新產生的month。","code":"\n# counting by dplyr::count()\nlibrary(dplyr)\n(res_count <- count(df, time, region)) ## # A tibble: 146 × 3\n##    time  region     n\n##    <chr> <chr>  <int>\n##  1 00~02 北投      24\n##  2 00~02 大安      24\n##  3 00~02 大同      15\n##  4 00~02 南港      19\n##  5 00~02 內湖      20\n##  6 00~02 士林      28\n##  7 00~02 松山       4\n##  8 00~02 萬華      17\n##  9 00~02 文山      17\n## 10 00~02 信義      27\n## # … with 136 more rows\n(res_count <- count(df, time, region)) %>% datatable()\nclass(res_count)    # \"tbl_df\"     \"tbl\"        \"data.frame\"## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\nlibrary(tidyr)\n# spreading the region into columns\n(res_count_spread <- spread(res_count, region, n, fill = 0))## # A tibble: 14 × 13\n##    time   北投  大安  大同  南港  內湖  士林  松山  萬華  文山  信義  中山  中正\n##    <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1 00~02    24    24    15    19    20    28     4    17    17    27    62    15\n##  2 02~04    17    15    10    12    15    29    13    29    14    12    26    22\n##  3 04~06    17    14    15     6    15    14     5    22     8    11    22     7\n##  4 06~08    24    19     9    13    16    17    11    21     9    13    20    19\n##  5 08~10    22    31    17    16    27    24    24    34    18    20    45    27\n##  6 10~12    35    34    12    19    33    35    35    41    18    18    38    20\n##  7 11~03     0     0     0     0     0     0     0     0     0     0     1     0\n##  8 12~14    34    49    12    15    26    46    23    33    25    20    30    25\n##  9 14~16    32    32    26    20    39    40    22    32    19    18    43    19\n## 10 16~18    33    25    13    11    24    30    20    26    16     8    21    19\n## 11 18~20    40    23    13    18    22    31    17    23    23    23    39    42\n## 12 18~21     0     0     0     0     0     0     0     0     0     0     1     0\n## 13 20~22    17    26    13    20    34    41    25    37    15    22    40    13\n## 14 22~24    15    12     9     9    18    23    14    20    17    16    33    20\nclass(res_count_spread)## [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n# spreading the time into columns\n# res_count_spread <- spread(res_count, time, n, fill = 0)\nres_count_spread## # A tibble: 14 × 13\n##    time   北投  大安  大同  南港  內湖  士林  松山  萬華  文山  信義  中山  中正\n##    <chr> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1 00~02    24    24    15    19    20    28     4    17    17    27    62    15\n##  2 02~04    17    15    10    12    15    29    13    29    14    12    26    22\n##  3 04~06    17    14    15     6    15    14     5    22     8    11    22     7\n##  4 06~08    24    19     9    13    16    17    11    21     9    13    20    19\n##  5 08~10    22    31    17    16    27    24    24    34    18    20    45    27\n##  6 10~12    35    34    12    19    33    35    35    41    18    18    38    20\n##  7 11~03     0     0     0     0     0     0     0     0     0     0     1     0\n##  8 12~14    34    49    12    15    26    46    23    33    25    20    30    25\n##  9 14~16    32    32    26    20    39    40    22    32    19    18    43    19\n## 10 16~18    33    25    13    11    24    30    20    26    16     8    21    19\n## 11 18~20    40    23    13    18    22    31    17    23    23    23    39    42\n## 12 18~21     0     0     0     0     0     0     0     0     0     0     1     0\n## 13 20~22    17    26    13    20    34    41    25    37    15    22    40    13\n## 14 22~24    15    12     9     9    18    23    14    20    17    16    33    20\n# ??dplyr::count\n(long_table <- tidyr::gather(res_count_spread, region, n, -time))## # A tibble: 168 × 3\n##    time  region     n\n##    <chr> <chr>  <dbl>\n##  1 00~02 北投      24\n##  2 02~04 北投      17\n##  3 04~06 北投      17\n##  4 06~08 北投      24\n##  5 08~10 北投      22\n##  6 10~12 北投      35\n##  7 11~03 北投       0\n##  8 12~14 北投      34\n##  9 14~16 北投      32\n## 10 16~18 北投      33\n## # … with 158 more rows\n# YOUR CODE SHOULD BE HERE"},{"path":"使用基礎r套件.html","id":"vii.-繪圖-plotting","chapter":"5 使用基礎R套件","heading":"5.2.11 VII. 繪圖 Plotting","text":"通常這種類別資料交叉分析最常用的圖表型態之一便是Mosaic Plot（但事實上Mosaic Plot不見能夠被一眼就了解）。我們可以把交叉分析後的變項res_table直接用MosaicPlot來繪圖。","code":"\n# mosaicplot() to plot 2-dim categorical vars.\nmosaicplot(res_table)\n# Add argument main (figure title)\nmosaicplot(res_table, main=\"mosaic plot\")"},{"path":"使用基礎r套件.html","id":"無法顯示中文","chapter":"5 使用基礎R套件","heading":"5.2.11.1 (1) 無法顯示中文","text":"大部分的視覺化套件都無法順利顯示中文，除非特別指定所要用的中文字型。這方面網路上可以找到很多的說明，但非常討厭的是，幾乎每換一套視覺化工具，換一套語言，就有不同的中文字體指定方式。例如用base的plot()來繪圖或用ggplot()的中文字型指定方法便不同，且軸上面有中文、圖標有中文、或者圖內有中文都要分開指定，非常討人厭。Mosaic Plot屬於base R的plot()，其中文指定方法要指定在繪圖前的par()函式中（par為parameter的意思），指定方法為par(family=('Heiti TC Light'))，Heiti TC Light為字體名稱，為OSX上在用的黑體細字，STKaiti則為標楷體。然後，par()和mosaicplot()兩個函式要「同時執行」，也就是請你直接用shift-cmd(ctrl)-Enter執行整個code-cell，或者將該兩個函式選起來一次執行。","code":"\npar(family=('STKaiti'))\n# par(family=('Heiti TC Light'))\nmosaicplot(res_table, main=\"mosaic plot\", color=T)"},{"path":"使用基礎r套件.html","id":"自訂顏色","chapter":"5 使用基礎R套件","heading":"5.2.11.2 (2) 自訂顏色","text":"目前顏色實在過醜，你可以自訂顏色指給mosaicplot()。例如我底下便產製了12種顏色後，將其作為mosaicplot()的參數","code":"\n# Set up color by yourself.\ncolors <- c('#D0104C', '#DB4D6D', '#E83015',  '#F75C2F',\n            '#E79460', '#E98B2A', '#9B6E23', '#F7C242',\n            '#BEC23F', '#90B44B', '#66BAB7', '#1E88A8')\n# par(family=('STKaiti'))\npar(family=('Heiti TC Light'))\nmosaicplot(res_table, color=colors, border=0, off = 3,\n           main=\"Theft rate of Taipei city (region by hour)\")"},{"path":"使用基礎r套件.html","id":"option-視覺化殘差分析","chapter":"5 使用基礎R套件","heading":"5.2.12 (Option) 視覺化殘差分析","text":"","code":"\n# par(family=('STKaiti'))\npar(family=('Heiti TC Light'))\nmosaicplot(res_table, color=T, shade = T, border=0, off = 3,\n           main=\"Theft rate of Taipei city (region by hour)\")"},{"path":"data-manipulation-wity-tidyverse.html","id":"data-manipulation-wity-tidyverse","chapter":"6 Data Manipulation wity tidyverse","heading":"6 Data Manipulation wity tidyverse","text":"","code":""},{"path":"data-manipulation-wity-tidyverse.html","id":"base-to-dplyr-tp-theft","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1 base to dplyr: TP Theft","text":"","code":"\nlibrary(tidyverse)\n# options(stringsAsFactors = F) # default options in R ver.> 4.0"},{"path":"data-manipulation-wity-tidyverse.html","id":"reading-data","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.1 Reading data","text":"","code":"\n# Read by read_csv()\n# Will raise error\n# Error in make.names(x) : invalid multibyte string at '<bd>s<b8><b9>'\n# df <- read_csv(\"data/tp_theft.csv\")\n\n# read_csv() with locale = locale(encoding = \"Big5\")\nlibrary(readr)\ndf <- read_csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\")"},{"path":"data-manipulation-wity-tidyverse.html","id":"cleaning-data-i","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.2 Cleaning data I","text":"Renaming variables select()Generating variable yearGenerating variable monthRetrieving area","code":"\nselected_df <- df %>%\n    select(id = 編號, \n           cat = 案類, \n           date = `發生日期`, \n           time = `發生時段`, \n           location = `發生地點`) %>%\n    mutate(year = date %/% 10000) %>%\n    mutate(month = date %/% 100 %% 100) %>%\n    mutate(area = stringr::str_sub(location, 4, 6)) %>%\n    mutate(county = stringr::str_sub(location, 1, 3))"},{"path":"data-manipulation-wity-tidyverse.html","id":"cleaning-data-ii","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.3 Cleaning data II","text":"Filtering irrelevant data records","code":"\n# readr::guess_encoding(\"data/tp_theft.csv\")\nfiltered_df <- selected_df %>%\n    # count(year) %>% View\n    filter(county == \"臺北市\") %>%\n    filter(year >= 104) %>%\n    # count(time) %>% View\n    # count(location) %>%\n    filter(!area %in% c(\"中和市\", \"板橋市\"))"},{"path":"data-manipulation-wity-tidyverse.html","id":"long-to-wide-form","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.4 Long to wide form","text":"count() two variablesspread() spread one variable columns wide form","code":"\n# count() then spread()\ndf.wide <- filtered_df %>% \n    count(time, area) %>%\n    spread(area, n, fill=0) "},{"path":"data-manipulation-wity-tidyverse.html","id":"setting-time-as-row.name-for-mosaicplot","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.5 Setting time as row.name for mosaicplot","text":"","code":"\nrow.names(df.wide) <- df.wide$time\ndf.wide$time <- NULL\n# Specify fonts for Chinese\n# par(family=('STKaiti')) \npar(family=('Heiti TC Light')) # for mac\n\n# Specify colors\ncolors <- c('#D0104C', '#DB4D6D', '#E83015',  '#F75C2F',\n            '#E79460', '#E98B2A', '#9B6E23', '#F7C242',\n            '#BEC23F', '#90B44B', '#66BAB7', '#1E88A8')\n\n# mosaicplot()\nmosaicplot(df.wide, color=colors, border=0, off = 3,\n           main=\"Theft rate of Taipei city (region by hour)\")"},{"path":"data-manipulation-wity-tidyverse.html","id":"clean-version","chapter":"6 Data Manipulation wity tidyverse","heading":"6.1.6 Clean version","text":"","code":"\nlibrary(readr)\n# options(stringsAsFactors = F)\ndf <- read_csv(\"data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv\")\n\nselected_df <- df %>%\n    select(id = 編號, \n           cat = 案類,\n           date = `發生日期`, \n           time = `發生時段`, \n           location = `發生地點`) %>%\n    mutate(year = date %/% 10000) %>%\n    mutate(month = date %/% 100 %% 100) %>%\n    mutate(area = stringr::str_sub(location, 4, 6)) %>%\n    mutate(county = stringr::str_sub(location, 1, 3))\n\nselected_df %>% count(year)## # A tibble: 9 × 2\n##    year     n\n##   <dbl> <int>\n## 1   103     1\n## 2   104   687\n## 3   105   663\n## 4   106   560\n## 5   107   501\n## 6   108   411\n## 7   109   304\n## 8   110   189\n## 9   111    31\nselected_df %>% count(time)## # A tibble: 26 × 2\n##    time      n\n##    <chr> <int>\n##  1 00~02   272\n##  2 02~04   214\n##  3 03~05     8\n##  4 04~06   156\n##  5 05~07    23\n##  6 06~08   191\n##  7 08~10   305\n##  8 09~11     6\n##  9 10~12   338\n## 10 11~03     1\n## # … with 16 more rows\nselected_df %>% arrange(time)## # A tibble: 3,347 × 9\n##       id cat         date time  location                 year month area  county\n##    <dbl> <chr>      <dbl> <chr> <chr>                   <dbl> <dbl> <chr> <chr> \n##  1     2 住宅竊盜 1040101 00~02 臺北市文山區萬美里萬寧…   104     1 文山… 臺北市\n##  2     3 住宅竊盜 1040101 00~02 臺北市信義區富台里忠孝…   104     1 信義… 臺北市\n##  3     6 住宅竊盜 1040102 00~02 臺北市士林區天福里1鄰…    104     1 士林… 臺北市\n##  4    12 住宅竊盜 1040105 00~02 臺北市中山區南京東路3…    104     1 中山… 臺北市\n##  5    33 住宅竊盜 1040115 00~02 臺北市松山區饒河街181~…   104     1 松山… 臺北市\n##  6    74 住宅竊盜 1040131 00~02 臺北市南港區重陽路57巷…   104     1 南港… 臺北市\n##  7    75 住宅竊盜 1040201 00~02 臺北市北投區中心里中和…   104     2 北投… 臺北市\n##  8    92 住宅竊盜 1040210 00~02 臺北市北投區大同路200…    104     2 北投… 臺北市\n##  9    95 住宅竊盜 1040212 00~02 臺北市萬華區萬大路493…    104     2 萬華… 臺北市\n## 10   106 住宅竊盜 1040216 00~02 臺北市信義區吳興街269…    104     2 信義… 臺北市\n## # … with 3,337 more rows\nfiltered_df <- selected_df %>%\n    # count(year) %>% View\n    filter(year >= 104) %>%\n    filter(!time %in% c(\"03~05\", \"05~07\", \"09~11\", \"11~13\", \"15~17\", \"17~19\", \"18~21\", \"21~23\", \"23~01\"))\n    # count(time) %>% View\n    # count(location) %>%\n    # filter(!area %in% c(\"中和市\", \"板橋市\"))\n\ndf.wide <- filtered_df %>% \n    count(time, area) %>%\n    spread(area, n, fill=0) %>%\n    as.data.frame()\n\nrow.names(df.wide) <- df.wide$time\ndf.wide$time <- NULL\n\npar(family=('Heiti TC Light')) # for mac\n\n# Specify colors\ncolors <- c('#D0104C', '#DB4D6D', '#E83015',  '#F75C2F',\n            '#E79460', '#E98B2A', '#9B6E23', '#F7C242',\n            '#BEC23F', '#90B44B', '#66BAB7', '#1E88A8')\n\n# mosaicplot()\nmosaicplot(df.wide, color=colors, border=0, off = 3,\n           main=\"Theft rate of Taipei city (region by hour)\")  "},{"path":"data-manipulation-wity-tidyverse.html","id":"時間軸的視覺化","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2 時間軸的視覺化","text":"","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\n# options(stringsAsFactors = F) # default option in R > 4.0"},{"path":"data-manipulation-wity-tidyverse.html","id":"文字轉時間","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2.1 文字轉時間","text":"Convert “character time” R date.time object (POSIXct)\nread_csv() read_tsv() special cases general\nread_delim(). ’re useful reading common types \nflat file data, comma separated values tab separated values,\nrespectively. read_csv2() uses ; field separator , \ndecimal point. format common European countries.\n\nEither path file, connection, literal data\n(either single string raw vector).\n\nFiles ending .gz, .bz2, .xz, .zip \nautomatically uncompressed. Files starting http://,\nhttps://, ftp://, ftps:// automatically\ndownloaded. Remote gz files can also automatically downloaded \ndecompressed.\n\nLiteral data useful examples tests. recognised \nliteral data, input must either wrapped (), string\ncontaining least one new line, vector containing least one\nstring new line.\n\nUsing value clipboard() read system clipboard.\n\nSingle character used separate fields within record.\n\nSingle character used quote strings.\n\nfile use backslashes escape special\ncharacters? general escape_double backslashes\ncan used escape delimiter character, quote character, \nadd special characters like \\n.\n\nfile escape quotes doubling ?\n.e. option TRUE, value ““““ represents\nsingle quote, \".\n\nEither TRUE, FALSE character vector\ncolumn names.\n\nTRUE, first row input used column\nnames, included data frame. FALSE, column\nnames generated automatically: X1, X2, X3 etc.\n\ncol_names character vector, values used \nnames columns, first row input read \nfirst row output data frame.\n\nMissing (NA) column names generate warning, filled\ndummy names …1, …2 etc. Duplicate column names\ngenerate warning made unique, see name_repair control\ndone.\n\nOne NULL, cols() specification, \nstring. See vignette(“readr”) details.\n\nNULL, column types imputed guess_max rows\ninput interspersed throughout file. convenient (\nfast), robust. imputation fails, ’ll need increase\nguess_max supply correct types .\n\nColumn specifications created list() cols() must contain\none column specification column. want read \nsubset columns, use cols_only().\n\nAlternatively, can use compact string representation \ncharacter represents one column:\n\n\nc = character\n\n\nc = character\n\n\n= integer\n\n\n= integer\n\n\nn = number\n\n\nn = number\n\n\nd = double\n\n\nd = double\n\n\nl = logical\n\n\nl = logical\n\n\nf = factor\n\n\nf = factor\n\n\nD = date\n\n\nD = date\n\n\nT = date time\n\n\nT = date time\n\n\nt = time\n\n\nt = time\n\n\n? = guess\n\n\n? = guess\n\n\n_ - = skip\n\n\ndefault, reading file without column specification print \nmessage showing readr guessed . remove message,\nset show_col_types = FALSE set ’options(readr.show_col_types = FALSE).\n\n\n_ - = skip\n\ndefault, reading file without column specification print \nmessage showing readr guessed . remove message,\nset show_col_types = FALSE set ’options(readr.show_col_types = FALSE).\n\nColumns include results. can use \nmini-language dplyr::select() refer columns name. Use\nc() list() use one selection expression. Although \nusage less common, col_select also accepts numeric column index. See\n?tidyselect::language full details \nselection language.\n\nname column store file path. \nuseful reading multiple input files data file\npaths, data collection date. NULL (default) extra\ncolumn created.\n\nlocale controls defaults vary place place.\ndefault locale US-centric (like R), can use\nlocale() create locale controls things like\ndefault time zone, encoding, decimal mark, big mark, day/month\nnames.\n\nCharacter vector strings interpret missing values. Set \noption character() indicate missing values.\n\n missing values\ninside quotes treated missing values (default) strings. \nparameter soft deprecated readr 2.0.0.\n\nstring used identify comments. text \ncomment characters silently ignored.\n\nleading trailing whitespace (ASCII spaces tabs) trimmed \nfield parsing ?\n\nNumber lines skip reading data. comment \nsupplied commented lines ignored skipping.\n\nMaximum number lines read.\n\nMaximum number lines use guessing column types.\nSee vignette(“column-types”, package = “readr”) details.\n\nHandling column names. default behaviour \nensure column names “unique”. Various repair strategies \nsupported:\n\n\n“minimal”: name repair checks, beyond basic existence names.\n\n\n“minimal”: name repair checks, beyond basic existence names.\n\n\n“unique” (default value): Make sure names unique empty.\n\n\n“unique” (default value): Make sure names unique empty.\n\n\n“check_unique”: name repair, check unique.\n\n\n“check_unique”: name repair, check unique.\n\n\n“universal”: Make names unique syntactic.\n\n\n“universal”: Make names unique syntactic.\n\n\nfunction: apply custom name repair (e.g., name_repair = make.names\nnames style base R).\n\n\nfunction: apply custom name repair (e.g., name_repair = make.names\nnames style base R).\n\n\npurrr-style anonymous function, see rlang::as_function().\n\n\npurrr-style anonymous function, see rlang::as_function().\n\nargument passed repair vctrs::vec_as_names().\nSee details terms strategies used\nenforce .\n\nnumber processing threads use initial\nparsing lazy reading data. data contains newlines within\nfields parser automatically detect fall back using\none thread . However know file newlines within quoted\nfields safest set num_threads = 1 explicitly.\n\nDisplay progress bar? default display\ninteractive session knitting document. automatic\nprogress bar can disabled setting option readr.show_progress \nFALSE.\n\nFALSE, show guessed column types. \nTRUE always show column types, even supplied. NULL\n(default) show column types explicitly supplied\ncol_types argument.\n\nblank rows ignored altogether? .e. \noption TRUE blank rows represented . \nFALSE represented NA values columns.\n\nRead values lazily? default file initially \nindexed values read lazily accessed. Lazy reading \nuseful interactively, particularly interested subset\nfull dataset. Note, later write file read\nneed set lazy = FALSE. Windows file locked\nsystems memory map become invalid.\n\ntibble(). parsing problems, warning alert .\ncan retrieve full details calling problems() dataset.\n\nFunctions convert character representations objects \nclasses “POSIXlt” “POSIXct” representing calendar\ndates times.\n\nobject converted: character vector \nstrptime, object can converted \n“POSIXlt” strftime.\n\ncharacter string specifying time zone used \nconversion. System-specific (see .POSIXlt), \n““ current time zone, ”GMT” UTC.\nInvalid values commonly treated UTC, platforms \nwarning.\n\ncharacter string. default format\nmethods \n“%Y-%m-%d %H:%M:%S” element time\ncomponent midnight, “%Y-%m-%d”\notherwise. options(“digits.secs”) set, \nspecified number digits printed seconds.\n\narguments passed methods.\n\nlogical. time zone abbreviation appended\noutput? used printing times, reliable\nusing “%Z”.\n\nformat .character methods strftime\nconvert objects classes “POSIXlt” \n“POSIXct” character vectors.\n\nstrptime converts character vectors class “POSIXlt”:\ninput x first converted .character.\ninput string processed far necessary format\nspecified: trailing characters ignored.\n\nstrftime wrapper format.POSIXlt, \nformat.POSIXct first convert class “POSIXlt” \ncalling .POSIXlt (also work class\n“Date”). Note conversion depends \ntime zone.\n\nusual vector re-cycling rules applied x \nformat answer length longer \nvectors.\n\nLocale-specific conversions character strings used\nappropriate available. affects names days\nmonths, /PM indicator (used) separators output\nformats %x %X, via setting \nLC_TIME locale category. ‘current\nlocale’ descriptions might mean locale use start\nR session functions first used. (input,\nlocale-specific conversions can changed calling\nSys.setlocale category LC_TIME (\nLC_ALL). output, happens depends OS \nusually works.)\n\ndetails formats platform-specific, following \nlikely widely available: defined POSIX standard.\nconversion specification introduced %, usually\nfollowed single letter O E single\nletter. character format string part conversion\nspecification interpreted literally (%% gives\n%). Widely implemented conversion specifications include\n\n%\n\n\nAbbreviated weekday name current\nlocale platform. (Also matches full name input:\nlocales abbreviations names.)\n\n\nAbbreviated weekday name current\nlocale platform. (Also matches full name input:\nlocales abbreviations names.)\n\n%\n\n\nFull weekday name current locale. (Also\nmatches abbreviated name input.)\n\n\nFull weekday name current locale. (Also\nmatches abbreviated name input.)\n\n%b\n\n\nAbbreviated month name current locale \nplatform. (Also matches full name input: \nlocales abbreviations names.)\n\n\nAbbreviated month name current locale \nplatform. (Also matches full name input: \nlocales abbreviations names.)\n\n%B\n\n\nFull month name current locale. (Also\nmatches abbreviated name input.)\n\n\nFull month name current locale. (Also\nmatches abbreviated name input.)\n\n%c\n\n\nDate time. Locale-specific output,\n“%%b %e %H:%M:%S %Y” input.\n\n\nDate time. Locale-specific output,\n“%%b %e %H:%M:%S %Y” input.\n\n%C\n\n\nCentury (00–99): integer part year\ndivided 100.\n\n\nCentury (00–99): integer part year\ndivided 100.\n\n%d\n\n\nDay month decimal number (01–31).\n\n\nDay month decimal number (01–31).\n\n%D\n\n\nDate format %m/%d/%y: C99\nstandard says exact format (OSes\ncomply).\n\n\nDate format %m/%d/%y: C99\nstandard says exact format (OSes\ncomply).\n\n%e\n\n\nDay month decimal number (1–31), \nleading space single-digit number.\n\n\nDay month decimal number (1–31), \nleading space single-digit number.\n\n%F\n\n\nEquivalent %Y-%m-%d (ISO 8601 date\nformat).\n\n\nEquivalent %Y-%m-%d (ISO 8601 date\nformat).\n\n%g\n\n\nlast two digits week-based year\n(see %V). (Accepted ignored input.)\n\n\nlast two digits week-based year\n(see %V). (Accepted ignored input.)\n\n%G\n\n\nweek-based year (see %V) decimal\nnumber. (Accepted ignored input.)\n\n\nweek-based year (see %V) decimal\nnumber. (Accepted ignored input.)\n\n%h\n\n\nEquivalent %b.\n\n\nEquivalent %b.\n\n%H\n\n\nHours decimal number (00–23). special\nexception strings 24:00:00 accepted input,\nsince ISO 8601 allows .\n\n\nHours decimal number (00–23). special\nexception strings 24:00:00 accepted input,\nsince ISO 8601 allows .\n\n%\n\n\nHours decimal number (01–12).\n\n\nHours decimal number (01–12).\n\n%j\n\n\nDay year decimal number (001–366): \ninput, 366 valid leap year.\n\n\nDay year decimal number (001–366): \ninput, 366 valid leap year.\n\n%m\n\n\nMonth decimal number (01–12).\n\n\nMonth decimal number (01–12).\n\n%M\n\n\nMinute decimal number (00–59).\n\n\nMinute decimal number (00–59).\n\n%n\n\n\nNewline output, arbitrary whitespace input.\n\n\nNewline output, arbitrary whitespace input.\n\n%p\n\n\n/PM indicator locale. Used \nconjunction %%H. \nempty string locales (example OSes,\nnon-English European locales including Russia). behaviour \nundefined used input locale.\n\n\nplatforms accept %P output, uses lower-case\nversion (%p may also use lower case): others output\nP.\n\n\n/PM indicator locale. Used \nconjunction %%H. \nempty string locales (example OSes,\nnon-English European locales including Russia). behaviour \nundefined used input locale.\n\nplatforms accept %P output, uses lower-case\nversion (%p may also use lower case): others output\nP.\n\n%r\n\n\noutput, 12-hour clock time (using \nlocale’s PM): defined locales, OSes\nmisleading locales define /PM indicator.\ninput, equivalent %:%M:%S %p.\n\n\noutput, 12-hour clock time (using \nlocale’s PM): defined locales, OSes\nmisleading locales define /PM indicator.\ninput, equivalent %:%M:%S %p.\n\n%R\n\n\nEquivalent %H:%M.\n\n\nEquivalent %H:%M.\n\n%S\n\n\nSecond integer (00–61), allowing \ntwo leap-seconds (POSIX-compliant implementations\nignore leap seconds).\n\n\nSecond integer (00–61), allowing \ntwo leap-seconds (POSIX-compliant implementations\nignore leap seconds).\n\n%t\n\n\nTab output, arbitrary whitespace input.\n\n\nTab output, arbitrary whitespace input.\n\n%T\n\n\nEquivalent %H:%M:%S.\n\n\nEquivalent %H:%M:%S.\n\n%u\n\n\nWeekday decimal number (1–7, Monday 1).\n\n\nWeekday decimal number (1–7, Monday 1).\n\n%U\n\n\nWeek year decimal number (00–53) using\nSunday first day 1 week (typically \nfirst Sunday year day 1 week 1). US convention.\n\n\nWeek year decimal number (00–53) using\nSunday first day 1 week (typically \nfirst Sunday year day 1 week 1). US convention.\n\n%V\n\n\nWeek year decimal number (01–53) \ndefined ISO 8601.\nweek (starting Monday) containing 1 January four \ndays new year, considered week 1. Otherwise, \nlast week previous year, next week week\n1. (Accepted ignored input.)\n\n\nWeek year decimal number (01–53) \ndefined ISO 8601.\nweek (starting Monday) containing 1 January four \ndays new year, considered week 1. Otherwise, \nlast week previous year, next week week\n1. (Accepted ignored input.)\n\n%w\n\n\nWeekday decimal number (0–6, Sunday 0).\n\n\nWeekday decimal number (0–6, Sunday 0).\n\n%W\n\n\nWeek year decimal number (00–53) using\nMonday first day week (typically \nfirst Monday year day 1 week 1). UK convention.\n\n\nWeek year decimal number (00–53) using\nMonday first day week (typically \nfirst Monday year day 1 week 1). UK convention.\n\n%x\n\n\nDate. Locale-specific output,\n“%y/%m/%d” input.\n\n\nDate. Locale-specific output,\n“%y/%m/%d” input.\n\n%X\n\n\nTime. Locale-specific output,\n“%H:%M:%S” input.\n\n\nTime. Locale-specific output,\n“%H:%M:%S” input.\n\n%y\n\n\nYear without century (00–99). input, values\n00 68 prefixed 20 69 99 19 – \nbehaviour specified 2018 POSIX standard, \nalso say ‘expected future version \ndefault century inferred 2-digit year change’.\n\n\nYear without century (00–99). input, values\n00 68 prefixed 20 69 99 19 – \nbehaviour specified 2018 POSIX standard, \nalso say ‘expected future version \ndefault century inferred 2-digit year change’.\n\n%Y\n\n\nYear century. Note whereas \nzero original Gregorian calendar, ISO 8601:2004 defines \nvalid (interpreted 1BC): see\nhttps://en.wikipedia.org/wiki/0_(year). However, standards\nalso say years 1582 calendar used\nagreement parties involved.\n\n\ninput, years 0:9999 accepted.\n\n\nYear century. Note whereas \nzero original Gregorian calendar, ISO 8601:2004 defines \nvalid (interpreted 1BC): see\nhttps://en.wikipedia.org/wiki/0_(year). However, standards\nalso say years 1582 calendar used\nagreement parties involved.\n\ninput, years 0:9999 accepted.\n\n%z\n\n\nSigned offset hours minutes\nUTC, -0800 8 hours behind UTC. Values \n+1400 accepted. (Standard output. input\nR currently supports platforms.)\n\n\nSigned offset hours minutes\nUTC, -0800 8 hours behind UTC. Values \n+1400 accepted. (Standard output. input\nR currently supports platforms.)\n\n%Z\n\n\n(Output .) Time zone abbreviation \ncharacter string (empty available). may reliable\ntime zone changed abbreviations years.\n\n\n(Output .) Time zone abbreviation \ncharacter string (empty available). may reliable\ntime zone changed abbreviations years.\n\nleading zeros shown used output \noptional input. Names matched case-insensitively input:\nwhether capitalized output depends platform \nlocale. Note abbreviated names platform-specific (although\nstandards specify C locale must \nfirst three letters capitalized English name: convention\nwidely used English-language locales example French\nmonth abbreviations two Linux, macOS, Solaris\nWindows). Knowing abbreviations essential\nwish use %, %b %h part \ninput format: see examples check.\n%z %Z used output \nobject assigned time zone attempt made use values\ntime zone — guaranteed succeed.\n\nstandards less widely implemented \n\n%k\n\n\n24-hour clock time single digits preceded\nblank.\n\n\n24-hour clock time single digits preceded\nblank.\n\n%l\n\n\n12-hour clock time single digits preceded\nblank.\n\n\n12-hour clock time single digits preceded\nblank.\n\n%s\n\n\n(Output .) number seconds since \nepoch.\n\n\n(Output .) number seconds since \nepoch.\n\n%+\n\n\n(Output .) Similar %c, often\n“%%b %e %H:%M:%S %Z %Y”. May depend locale.\n\n\n(Output .) Similar %c, often\n“%%b %e %H:%M:%S %Z %Y”. May depend locale.\n\noutput also %O[dHImMUVwWy] may emit\nnumbers alternative locale-dependent format (e.g., roman\nnumerals), %E[cCyYxX] can use alternative\n‘era’ (e.g., different religious calendar). \nsupported OS-dependent. accepted input, \nstandard interpretation.\n\nSpecific R %OSn, output gives seconds\ntruncated 0 <= n <= 6 decimal places (%OS \nfollowed digit, uses setting \ngetOption(“digits.secs”), unset, n =\n0). , strptime %OS input seconds\nincluding fractional seconds. Note %S read\nfractional parts output.\n\nbehaviour conversion specifications (even \ncharacter sequences commencing % conversion\nspecifications) system-specific. systems document \nuse multi-byte characters format unsupported: UTF-8\nlocales unlikely cause problem.\n\nformat methods strftime return character vectors\nrepresenting time. NA times returned \nNA_character_. elements restricted 256 bytes, plus\ntime zone abbreviation usetz true. (known platforms\nlonger strings truncated 255 256 bytes, \nguaranteed C99 standard.)\n\nstrptime turns character representations object \nclass “POSIXlt”. time zone used set \nisdst component set “tzone” attribute \ntz != ““. specified time invalid (example\n“2010-02-30 08:00”) components result \nNA. (NB: means exactly says – \ninvalid time, just time exist time zone.)\nEveryone agrees years 1000 9999 printed 4\ndigits, standards define done outside\nrange. years 0 999 OSes pad zeros spaces \n4 characters, Linux outputs just number.\n\nOS facilities probably print years 1 CE (aka 1 AD)\n‘correctly’ (tend assume existence year 0: see\nhttps://en.wikipedia.org/wiki/0_(year), OSes get \ncompletely wrong). Common formats -45 -045.\n\nYears 9999 -999 normally printed five \ncharacters.\n\nplatforms support modifiers POSIX 2008 (others). \nLinux format “%04Y” assures minimum four characters\nzero-padding. internal code (used Windows \ndefault macOS) uses zero-padding default, formats\n%_4Y %_Y can used space padding \npadding.\n\nOffsets GMT (also known UTC) part conversion\ntimezones /class “POSIXct”, cause\ndifficulties often computed incorrectly.\n\nconventionally opposite sign time-zone\nspecifications (see Sys.timezone): positive values \nEast meridian. Although time zones \noffsets like 00:09:21 (Paris 1900), 00:44:30 (Liberia \n1972), offsets usually treated whole numbers minutes, \noften seen RFC 5322 email headers forms like\n-0800 (e.g., used Pacific coast USA winter).\n\nFormat %z can used input output: character\nstring, conventionally plus minus followed two digits \nhours two minutes: standards say empty string\noutput offset unknown, systems use \noffsets time zone use current year.\n\nInput uses POSIX function strptime output C99\nfunction strftime.\n\nHowever, OSes (notably Windows) provided strptime \nmany issues found , since 2000 R used\nfork code glibc. forked code uses \nsystem’s strftime find locale-specific day month\nnames /PM indicator.\n\nplatforms (including Windows default macOS) \nsystem’s strftime replaced (along rest \nC-level datetime code) code modified IANA’s tzcode\ndistribution (https://www.iana.org/time-zones).\n\ndefault formats follow rules ISO 8601 international\nstandard expresses day “2001-02-28” time \n“14:01:02” using leading zeroes . (ISO form uses \nspace separate dates times: R default.)\n\nstrptime input string need specify date\ncompletely: assumed unspecified seconds, minutes hours\nzero, unspecified year, month day current one.\n(However, month specified, day month \nspecified %d %e since current day \nmonth need valid specified month.) components may\nreturned NA (unknown tzone component \nrepresented empty string).\n\ntime zone specified invalid system, happens \nsystem-specific probably ignored.\n\nRemember time zones times occur \noccur twice transitions /‘daylight saving’\n(also known ‘summer’) time. strptime \nvalidate times (assume specific time zone), \nconversion .POSIXct . Conversion \nstrftime formatting/printing uses OS facilities may\nreturn nonsensical results non-existent times DST transitions.\n\nC locale %c required \n“%%b %e %H:%M:%S %Y”. Windows comply (\nuses date format understood outside N. America), format \nused R Windows locales.\n\nInternational Organization Standardization (2004, 2000, …)\n‘ISO 8601. Data elements interchange formats –\nInformation interchange – Representation dates times.’,\nslightly updated International Organization Standardization (2019)\n‘ISO 8601-1:2019. Date time – Representations \ninformation interchange – Part 1: Basic rules’.\nlinks versions available -line see (time writing)\nhttps://dotat./tmp/ISO_8601-2004_E.pdf \nhttps://www.qsl.net/g1smd/isopdf.htm; information \ncurrent official version, see https://www.iso.org/iso/iso8601.\n\nPOSIX 1003.1 standard, respects stricter ISO 8601.\n\nDateTimeClasses details date-time classes;\nlocales query set locale.\n\nsystem’s help page strftime see specify \nformats. (systems, including Windows, strftime \nreplaced comprehensive internal code.)\n","code":"\nptturl <- \"https://github.com/P4CSS/R4CSSData/raw/main/ptt_hang_posts.csv\"\nraw <- read.csv(url(ptturl))\nclean <- raw %>%\n        mutate(ptime = as.POSIXct(strptime(ptime, \"%Y-%m-%dT%H:%M:%SZ\", tz = \"ASIA/Taipeiw\")))\n\nraw <- read_csv(url(ptturl))\n?read_csv\nread_delim(\n  file,\n  delim = NULL,\n  quote = \"\\\"\",\n  escape_backslash = FALSE,\n  escape_double = TRUE,\n  col_names = TRUE,\n  col_types = NULL,\n  col_select = NULL,\n  id = NULL,\n  locale = default_locale(),\n  na = c(\"\", \"NA\"),\n  quoted_na = TRUE,\n  comment = \"\",\n  trim_ws = FALSE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  name_repair = \"unique\",\n  num_threads = readr_threads(),\n  progress = show_progress(),\n  show_col_types = should_show_types(),\n  skip_empty_rows = TRUE,\n  lazy = should_read_lazy()\n)\n\nread_csv(\n  file,\n  col_names = TRUE,\n  col_types = NULL,\n  col_select = NULL,\n  id = NULL,\n  locale = default_locale(),\n  na = c(\"\", \"NA\"),\n  quoted_na = TRUE,\n  quote = \"\\\"\",\n  comment = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  name_repair = \"unique\",\n  num_threads = readr_threads(),\n  progress = show_progress(),\n  show_col_types = should_show_types(),\n  skip_empty_rows = TRUE,\n  lazy = should_read_lazy()\n)\n\nread_csv2(\n  file,\n  col_names = TRUE,\n  col_types = NULL,\n  col_select = NULL,\n  id = NULL,\n  locale = default_locale(),\n  na = c(\"\", \"NA\"),\n  quoted_na = TRUE,\n  quote = \"\\\"\",\n  comment = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = show_progress(),\n  name_repair = \"unique\",\n  num_threads = readr_threads(),\n  show_col_types = should_show_types(),\n  skip_empty_rows = TRUE,\n  lazy = should_read_lazy()\n)\n\nread_tsv(\n  file,\n  col_names = TRUE,\n  col_types = NULL,\n  col_select = NULL,\n  id = NULL,\n  locale = default_locale(),\n  na = c(\"\", \"NA\"),\n  quoted_na = TRUE,\n  quote = \"\\\"\",\n  comment = \"\",\n  trim_ws = TRUE,\n  skip = 0,\n  n_max = Inf,\n  guess_max = min(1000, n_max),\n  progress = show_progress(),\n  name_repair = \"unique\",\n  num_threads = readr_threads(),\n  show_col_types = should_show_types(),\n  skip_empty_rows = TRUE,\n  lazy = should_read_lazy()\n)\n\n# Input sources -------------------------------------------------------------\n# Read from a path\nread_csv(readr_example(\"mtcars.csv\"))\nread_csv(readr_example(\"mtcars.csv.zip\"))\nread_csv(readr_example(\"mtcars.csv.bz2\"))\n## Not run: \n# Including remote paths\nread_csv(\"https://github.com/tidyverse/readr/raw/main/inst/extdata/mtcars.csv\")\n\n## End(Not run)\n\n# Or directly from a string with `I()`\nread_csv(I(\"x,y\\n1,2\\n3,4\"))\n\n# Column types --------------------------------------------------------------\n# By default, readr guesses the columns types, looking at `guess_max` rows.\n# You can override with a compact specification:\nread_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = \"dc\")\n\n# Or with a list of column types:\nread_csv(I(\"x,y\\n1,2\\n3,4\"), col_types = list(col_double(), col_character()))\n\n# If there are parsing problems, you get a warning, and can extract\n# more details with problems()\ny <- read_csv(I(\"x\\n1\\n2\\nb\"), col_types = list(col_double()))\ny\nproblems(y)\n\n# File types ----------------------------------------------------------------\nread_csv(I(\"a,b\\n1.0,2.0\"))\nread_csv2(I(\"a;b\\n1,0;2,0\"))\nread_tsv(I(\"a\\tb\\n1.0\\t2.0\"))\nread_delim(I(\"a|b\\n1.0|2.0\"), delim = \"|\")\n\nt <- \"2019-04-12T00:48:19Z\"\nclass(t)## [1] \"character\"\n?strptime\n## S3 method for class 'POSIXct'\nformat(x, format = \"\", tz = \"\", usetz = FALSE, ...)\n## S3 method for class 'POSIXlt'\nformat(x, format = \"\", usetz = FALSE, ...)\n\n## S3 method for class 'POSIXt'\nas.character(x, ...)\n\nstrftime(x, format = \"\", tz = \"\", usetz = FALSE, ...)\nstrptime(x, format, tz = \"\")\n\n## locale-specific version of date()\nformat(Sys.time(), \"%a %b %d %X %Y %Z\")\n\n## time to sub-second accuracy (if supported by the OS)\nformat(Sys.time(), \"%H:%M:%OS3\")\n\n## read in date info in format 'ddmmmyyyy'\n## This will give NA(s) in some non-English locales; setting the C locale\n## as in the commented lines will overcome this on most systems.\n## lct <- Sys.getlocale(\"LC_TIME\"); Sys.setlocale(\"LC_TIME\", \"C\")\nx <- c(\"1jan1960\", \"2jan1960\", \"31mar1960\", \"30jul1960\")\nz <- strptime(x, \"%d%b%Y\")\n## Sys.setlocale(\"LC_TIME\", lct)\nz\n\n## read in date/time info in format 'm/d/y h:m:s'\ndates <- c(\"02/27/92\", \"02/27/92\", \"01/14/92\", \"02/28/92\", \"02/01/92\")\ntimes <- c(\"23:03:20\", \"22:29:56\", \"01:03:30\", \"18:21:03\", \"16:56:26\")\nx <- paste(dates, times)\nstrptime(x, \"%m/%d/%y %H:%M:%S\")\n\n## time with fractional seconds\nz <- strptime(\"20/2/06 11:16:16.683\", \"%d/%m/%y %H:%M:%OS\")\nz # prints without fractional seconds\nop <- options(digits.secs = 3)\nz\noptions(op)\n\n## time zone names are not portable, but 'EST5EDT' comes pretty close.\n(x <- strptime(c(\"2006-01-08 10:07:52\", \"2006-08-07 19:33:02\"),\n               \"%Y-%m-%d %H:%M:%S\", tz = \"EST5EDT\"))\nattr(x, \"tzone\")\n\n## An RFC 5322 header (Eastern Canada, during DST)\n## In a non-English locale the commented lines may be needed.\n## prev <- Sys.getlocale(\"LC_TIME\"); Sys.setlocale(\"LC_TIME\", \"C\")\nstrptime(\"Tue, 23 Mar 2010 14:36:38 -0400\", \"%a, %d %b %Y %H:%M:%S %z\")\n## Sys.setlocale(\"LC_TIME\", prev)\n\n## Make sure you know what the abbreviated names are for you if you wish\n## to use them for input (they are matched case-insensitively):\nformat(seq.Date(as.Date('1978-01-01'), by = 'day', len = 7), \"%a\")\nformat(seq.Date(as.Date('2000-01-01'), by = 'month', len = 12), \"%b\")\n\nt1 <- strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")\nraw %>% glimpse()## Rows: 8,317\n## Columns: 7\n## $ plink    <chr> \"https://www.ptt.cc/bbs/HatePolitics/M.1555035677.A.24B.html\"…\n## $ board    <chr> \"HatePolitics\", \"HatePolitics\", \"HatePolitics\", \"HatePolitics…\n## $ pcontent <chr> \"\\n\\n韓國瑜赴哈佛大學前受訪表示，就是「keeping practice」，盡…\n## $ poster   <chr> \"lovebxcx\", \"ikr3699654\", \"sunyeah\", \"rock720429\", \"btm978952…\n## $ ptitle   <chr> \"Re: [新聞] 重申反對一國兩制　韓國瑜：看著我靈魂深\", \"Re: [討…\n## $ ptime    <dttm> 2019-04-12 02:21:14, 2019-04-12 02:13:45, 2019-04-12 02:10:1…\n## $ ipaddr   <chr> \"83.221.204.163\", \"114.43.176.110\", \"118.163.130.181\", \"118.1…"},{"path":"data-manipulation-wity-tidyverse.html","id":"時間作為機率分佈x軸","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2.2 時間作為機率分佈X軸","text":"","code":"\nraw %>%\n    ggplot() + aes(ptime) + \n    geom_density()"},{"path":"data-manipulation-wity-tidyverse.html","id":"逐月統計資料","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2.3 逐月統計資料","text":"\nLubridate provides tools make easier parse \nmanipulate dates. tools grouped common\npurpose. information function can found \nhelp documentation.\n\nLubridate’s parsing functions read strings R POSIXct\ndate-time objects. Users choose function whose name\nmodels order year (‘y’), month (‘m’) day\n(‘d’) elements appear string parsed:\ndmy(), myd(), ymd(),\nydm(), dym(), mdy(),\nymd_hms()). flexible user friendly parser\nprovided parse_date_time().\n\nLubridate can also parse partial dates strings \nPeriod objects functions\nhm(), hms() ms().\n\nLubridate inbuilt fast POSIX parser. strptime()\nformats various extensions supported English locales. See\nparse_date_time() details.\n\nLubridate distinguishes moments time (known \ninstants()) spans time (known time spans, see\nTimespan). Time spans separated \nDuration, Period \nInterval objects.\n\nInstants specific moments time. Date, POSIXct, \nPOSIXlt three object classes Base R recognizes \ninstants. .Date() tests whether object\ninherits Date class. .POSIXt() tests\nwhether object inherits POSIXlt POSIXct classes.\n.instant() tests whether object inherits \nthree classes.\n\nnow() returns current system time POSIXct\nobject. today() returns current system date.\nconvenience, 1970-01-01 00:00:00 saved \norigin. instant POSIXct\ntimes calculated. Try unclass(now()) see numeric structure \nunderlies POSIXct objects. POSIXct object saved number seconds\noccurred 1970-01-01 00:00:00.\n\nConceptually, instants combination measurements different units\n(.e, years, months, days, etc.). individual values \nunits can extracted instant set \naccessor functions second(), minute(),\nhour(), day(), yday(),\nmday(), wday(), week(),\nmonth(), year(), tz(),\ndst().\nNote: accessor functions named singular form\nelement. shouldn’t confused period\nhelper functions plural form units \nname (e.g, seconds()).\n\nInstants can rounded convenient unit using \nfunctions ceiling_date(), floor_date()\nround_date().\n\nLubridate provides two helper functions working time\nzones. with_tz() changes time zone \ninstant displayed. clock time displayed instant\nchanges, moment time described remains .\nforce_tz() changes time zone element \ninstant. clock time displayed remains , \nresulting instant describes new moment time.\n\ntimespan length time may may connected \nparticular instant. example, three months timespan. hour \nhalf. Base R uses difftime class objects record timespans.\nHowever, people always consistent expect time behave.\nSometimes passage time monotone progression instants \nmathematically reliable number line. occasions time must\nfollow complex conventions rules clock times see reflect \nexpect observe terms daylight, season, congruence \natomic clock. better navigate nuances time, lubridate creates three\nadditional timespan classes, specific consistent behavior:\nInterval, Period \nDuration.\n\n.difftime() tests whether object\ninherits difftime class. .timespan()\ntests whether object inherits four timespan\nclasses.\n\nDurations measure exact amount time occurs two\ninstants. can create unexpected results relation clock times \nleap second, leap year, change daylight savings time (DST) occurs \ninterval.\n\nFunctions working durations include .duration(),\n.duration() duration(). dseconds(),\ndminutes(), dhours(), ddays(),\ndweeks() dyears() convenient lengths.\n\nPeriods measure change clock time occurs two\ninstants. Periods provide robust predictions clock time presence \nleap seconds, leap years, changes DST.\n\nFunctions working periods include\n.period(), .period() \nperiod(). seconds(),\nminutes(), hours(), days(),\nweeks(), months() \nyears() quickly create periods convenient\nlengths.\n\nIntervals timespans begin specific instant \nend specific instant. Intervals retain complete information \ntimespan. provide reliable way convert \nperiods durations.\n\nFunctions working intervals include\n.interval(), .interval(),\ninterval(), int_shift(),\nint_flip(), int_aligns(),\nint_overlaps(), \n%within%. Intervals can also manipulated \nintersect, union, setdiff().\n\ndecimal_date() converts instant decimal \nyear.\nleap_year() tests whether instant occurs \nleap year.\npretty_dates() provides method making pretty\nbreaks date-times.\nlakers data set contains information\nLos Angeles Lakers 2008-2009 basketball season.\n\nMaintainer: Vitalie Spinu spinuvit@gmail.com\n\nAuthors:\n\n\nGarrett Grolemund\n\n\nGarrett Grolemund\n\n\nHadley Wickham\n\n\nHadley Wickham\n\ncontributors:\n\n\nDavis Vaughan [contributor]\n\n\nDavis Vaughan [contributor]\n\n\nIan Lyttle [contributor]\n\n\nIan Lyttle [contributor]\n\n\nImanuel Costigan [contributor]\n\n\nImanuel Costigan [contributor]\n\n\nJason Law [contributor]\n\n\nJason Law [contributor]\n\n\nDoug Mitarotonda [contributor]\n\n\nDoug Mitarotonda [contributor]\n\n\nJoseph Larmarange [contributor]\n\n\nJoseph Larmarange [contributor]\n\n\nJonathan Boiser [contributor]\n\n\nJonathan Boiser [contributor]\n\n\nChel Hee Lee [contributor]\n\n\nChel Hee Lee [contributor]\n\n\nGoogle Inc. [contributor, copyright holder]\n\n\nGoogle Inc. [contributor, copyright holder]\n\nGarrett Grolemund, Hadley Wickham (2011). Dates Times Made\nEasy lubridate. Journal Statistical Software, 40(3), 1-25.\nhttps://www.jstatsoft.org/v40/i03/.\n\nUseful links:\n\n\nhttps://lubridate.tidyverse.org\n\n\nhttps://lubridate.tidyverse.org\n\n\nhttps://github.com/tidyverse/lubridate\n\n\nhttps://github.com/tidyverse/lubridate\n\n\nReport bugs https://github.com/tidyverse/lubridate/issues\n\n\nReport bugs https://github.com/tidyverse/lubridate/issues\n","code":"\n?lubridate\nraw %>%\n    mutate(m = month(ptime)) %>% \n    count(m) %>%\n    ggplot() + aes(m, n) + \n    geom_col()"},{"path":"data-manipulation-wity-tidyverse.html","id":"逐日統計資料佳","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2.4 逐日統計資料（佳）","text":"","code":"\nraw %>%\n    filter(ptime >= as_date(\"2019-03-18\") & ptime < as_date(\"2019-04-01\")) %>%\n    mutate(m = floor_date(ptime, unit = \"day\")) %>% \n    count(m) %>%\n    ggplot() + aes(m, n) + \n    geom_col()"},{"path":"data-manipulation-wity-tidyverse.html","id":"每日逐時資料","chapter":"6 Data Manipulation wity tidyverse","heading":"6.2.5 每日逐時資料","text":"\nifelse returns value shape \ntest filled elements selected\neither yes \ndepending whether element test\nTRUE FALSE.\n\nobject can coerced logical mode.\n\nreturn values true elements test.\n\nreturn values false elements test.\n\nyes short, elements recycled.\nyes evaluated element test\ntrue, analogously .\n\nMissing values test give missing values result.\n\nvector length attributes (including dimensions \n“class”) test data values values \nyes . mode answer coerced \nlogical accommodate first values taken yes \nvalues taken .\n\nmode result may depend value test (see \nexamples), class attribute (see oldClass) \nresult taken test may inappropriate \nvalues selected yes .\n\nSometimes better use construction \n\n, possibly extended handle missing values test.\n\nnote (test) yes else much efficient\noften much preferable ifelse(test, yes, ) whenever\ntest simple true/false result, .e., \nlength(test) == 1.\n\nsrcref attribute functions handled specially: \ntest simple true result yes evaluates function\nsrcref attribute, ifelse returns yes including\nattribute (applies false test \nargument). functionality backwards compatibility, \nform (test) yes else used whenever yes \nfunctions.\n\nBecker, R. ., Chambers, J. M. Wilks, . R. (1988)\nNew S Language.\nWadsworth & Brooks/Cole.\n\n.\n","code":"\nclean %>%\n    filter(ptime >= as_datetime(\"2019-03-25\") & ptime < as_datetime(\"2019-04-01\")) %>%\n    mutate(d = floor_date(ptime, unit = \"day\")) %>%\n    mutate(h = hour(ptime)) %>%\n    count(d, h) %>%\n    mutate(wd = wday(d, label = F, locale = Sys.getlocale(\"LC_TIME\"))) %>%\n    mutate(isweekend = ifelse(wd >= 6, \"weekend\", \"weekday\")) %>%\n    ggplot() + aes(h, n, color = as.character(d)) + \n    geom_line() + \n    facet_wrap(~isweekend)\n?ifelse\nifelse(test, yes, no)\n  (tmp <- yes; tmp[!test] <- no[!test]; tmp)\n\nx <- c(6:-4)\nsqrt(x)  #- gives warning\nsqrt(ifelse(x >= 0, x, NA))  # no warning\n\n## Note: the following also gives the warning !\nifelse(x >= 0, sqrt(x), NA)\n\n\n## ifelse() strips attributes\n## This is important when working with Dates and factors\nx <- seq(as.Date(\"2000-02-29\"), as.Date(\"2004-10-04\"), by = \"1 month\")\n## has many \"yyyy-mm-29\", but a few \"yyyy-03-01\" in the non-leap years\ny <- ifelse(as.POSIXlt(x)$mday == 29, x, NA)\nhead(y) # not what you expected ... ==> need restore the class attribute:\nclass(y) <- class(x)\ny\n## This is a (not atypical) case where it is better *not* to use ifelse(),\n## but rather the more efficient and still clear:\ny2 <- x\ny2[as.POSIXlt(x)$mday != 29] <- NA\n## which gives the same as ifelse()+class() hack:\nstopifnot(identical(y2, y))\n\n\n## example of different return modes (and 'test' alone determining length):\nyes <- 1:3\nno  <- pi^(1:4)\nutils::str( ifelse(NA,    yes, no) ) # logical, length 1\nutils::str( ifelse(TRUE,  yes, no) ) # integer, length 1\nutils::str( ifelse(FALSE, yes, no) ) # double,  length 1\n"},{"path":"eda.html","id":"eda","chapter":"7 Explore Data Analysis","heading":"7 Explore Data Analysis","text":"","code":""},{"path":"eda.html","id":"tw-aqi-visual-studies","chapter":"7 Explore Data Analysis","heading":"7.1 TW AQI Visual Studies","text":"","code":"\nlibrary(tidyverse)\nlibrary(readxl)\n# options(stringsAsFactors = F)\naqi_data <- read_rds(\"https://github.com/p4css/R4CSS/raw/master/data/AQI_Chaozhou.rds\")"},{"path":"eda.html","id":"trending-central-tendency","chapter":"7 Explore Data Analysis","heading":"7.1.1 Trending: Central tendency","text":"Counting data month plotting ensure degree data loss.科普小學堂-空氣中的懸浮粒子台灣PM2.5三大面向：空汙現況多嚴重？要怪中國還是怪自己？ - 第 1 頁 - News Lens 關鍵評論網","code":"\ntoplot <- aqi_data %>%\n    arrange(日期)%>%\n    filter(測項==\"PM2.5\") %>%\n    gather(\"hour\", \"PM25\", 4:28) %>% \n    mutate(PM25 = as.numeric(PM25)) %>%\n    drop_na() %>%\n    group_by(日期) %>%\n    summarize(avg = mean(PM25)) %>% \n    ungroup() %>%\n    mutate(year = lubridate::year(日期), \n           month = lubridate::month(日期)) %>%\n    group_by(year, month) %>% \n    summarize(avg = mean(avg)) %>%\n    ungroup()\naqi_data %>%\n    filter(測項==\"PM2.5\") %>%\n    arrange(日期)%>%\n    gather(\"hour\", \"PM25\", 4:28) %>% \n    mutate(PM25 = as.numeric(PM25)) %>%\n    drop_na() %>%\n    group_by(日期) %>%\n    summarize(avg = mean(PM25)) %>% \n    ungroup() %>%\n    arrange(日期) %>%\n    mutate(year = lubridate::year(日期), \n           month = lubridate::month(日期)) %>%\n    count(year, month) %>%\n    mutate(rn = row_number()) %>%\n    ggplot() + aes(rn, n) + \n    geom_line() + theme_minimal()\nlibrary(gghighlight)\ntoplot %>%\n    mutate(month = as.character(month)) %>%\n    group_by(month) %>%\n    arrange(year) %>%\n    # mutate(diff = avg -first(avg),\n    #        month = as.character(month)) %>%\n    # ungroup() %>%\n    ggplot() + aes(year, avg, color = month) + \n    geom_line() + \n    # geom_point() + \n    gghighlight(month %in% c(\"11\", \"12\", \"1\", \"2\", \"3\")) + \n    theme_minimal()"},{"path":"eda.html","id":"trending-extreme-value","chapter":"7 Explore Data Analysis","heading":"7.1.2 Trending: Extreme value","text":"","code":"\ntoplot2 <- aqi_data %>%\n    arrange(日期)%>%\n    filter(測項==\"PM2.5\") %>%\n    gather(\"hour\", \"PM25\", 4:28) %>%\n    mutate(PM25 = as.numeric(PM25)) %>%\n    drop_na() %>%\n    group_by(日期) %>%\n    summarize(avg = sum(PM25)/24) %>% \n    ungroup() %>%\n    mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %>%\n    group_by(year, month) %>%\n    summarize(purple = sum(avg>150),\n              red = sum(avg>54),\n              orange = sum(avg>35)) %>%\n    ungroup()\n\ntoplot2 %>%\n    mutate(month = as.character(month)) %>%\n    group_by(month) %>%\n    arrange(year) %>%\n    ggplot() + aes(year, orange, color = month) + \n    geom_line() + \n    # geom_point() + \n    gghighlight(month %in% c(\"11\", \"12\", \"1\", \"2\", \"3\")) + \n    ylab(\"Days (PM25 > 35) in one month\") + \n    theme_minimal()\ntoplot3 <- aqi_data %>%\n    arrange(日期)%>%\n    filter(測項==\"PM2.5\") %>%\n    gather(\"hour\", \"PM25\", 4:28) %>%\n    mutate(PM25 = as.numeric(PM25)) %>%\n    drop_na() %>%\n    mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %>%\n    filter(month %in% c(11, 12, 1, 2, 3))\ntoplot3 %>%\n    mutate(year = as.character(year)) %>%\n    ggplot() + aes(y=year, x=PM25)  + \n    geom_boxplot(fill=\"skyblue\", alpha=0.2) + \n    xlim(0, 200) + \n    theme_minimal()"},{"path":"text-processing.html","id":"text-processing","chapter":"8 Text Processing","heading":"8 Text Processing","text":"","code":""},{"path":"text-processing.html","id":"tweets-分析","chapter":"8 Text Processing","heading":"8.1 Tweets 分析","text":"應用dplyr和ggplot做社群輿論資料（tweets）的探索性分析，其中除了dplyr和ggplot外，尚用到文字處理（stringr, extract()）、時間處理（lubridate），甚至包含一點keyness分析，為找出兩個群體文本中，對彼此相對突出關鍵字的文本探勘方法。本範例取材自David Robinson的blog文章「Text analysis Trump’s tweets confirms writes (angrier) Android half」。David Robinson是「Text Mining R」的共同作者， 可參考該書籍上的範例「7 Case study: comparing Twitter archives | Text Mining R (tidytextmining.com)」。","code":""},{"path":"text-processing.html","id":"載入並清理資料","chapter":"8 Text Processing","heading":"8.1.1 載入並清理資料","text":"R4.0後stringsAsFactors=F變為預設值，便不用再另行用options()設為全域適用的參數。","code":"\nlibrary(tidyverse)\nlibrary(lubridate)\noptions(scipen = 999)\n\nth <-  theme_minimal() + \n    theme(plot.title = element_text(size=24, face=\"bold\"),\n          legend.title = element_text(size=18, face=\"bold\"),\n          legend.text = element_text(size=18),\n          axis.title = element_text(hjust=0.5, size=18,\n                                    face=\"italic\"),\n          axis.text = element_text(size=18)\n          )\n\nnew_style <- function() {\n  font <- \"Helvetica\"\n  theme(\n      plot.title = element_text(family=font,\n                                size=28, face=\"bold\"),\n      plot.subtitle = element_text(family=font,\n                                   size=22,\n                                   margin=margin(9,0,9,0)),\n      plot.caption = element_blank(),\n      legend.position = \"top\",\n      legend.text.align = 0,\n      legend.background = element_blank(),\n      # legend.title = element_blank(),\n      legend.key = element_blank(),\n      legend.text = element_text(family=font,\n                             size=18,\n                             color=\"#222222\"),\n      axis.text = element_text(family=font,\n                               size=18,\n                               color=\"#222222\"),\n      axis.text.x = element_text(margin=margin(5, b = 10)),\n      axis.ticks = element_blank(),\n      axis.line = element_blank(),\n      panel.grid.minor = element_blank(),\n      panel.grid.major.y = element_line(color=\"#cbcbcb\"),\n      panel.grid.major.x = element_blank(),\n      panel.background = element_blank(),\n      strip.background = element_rect(fill=\"white\"),\n      strip.text = element_text(size  = 22,  hjust = 0)\n      )\n  }\nload(url(\"http://varianceexplained.org/files/trump_tweets_df.rda\"))\ndim(trump_tweets_df)## [1] 1512   16\nnames(trump_tweets_df)##  [1] \"text\"          \"favorited\"     \"favoriteCount\" \"replyToSN\"    \n##  [5] \"created\"       \"truncated\"     \"replyToSID\"    \"id\"           \n##  [9] \"replyToUID\"    \"statusSource\"  \"screenName\"    \"retweetCount\" \n## [13] \"isRetweet\"     \"retweeted\"     \"longitude\"     \"latitude\"\ntrump_tweets_df %>%\n    select(id, text, created, favoriteCount,  retweetCount, statusSource) %>%\n    head(20)## # A tibble: 20 × 6\n##    id          text  created             favoriteCount retweetCount statusSource\n##    <chr>       <chr> <dttm>                      <dbl>        <dbl> <chr>       \n##  1 7626698825… \"My … 2016-08-08 15:20:44          9214         3107 \"<a href=\\\"…\n##  2 7626415954… \"Joi… 2016-08-08 13:28:20          6981         2390 \"<a href=\\\"…\n##  3 7624396589… \"#IC… 2016-08-08 00:05:54         15724         6691 \"<a href=\\\"…\n##  4 7624253718… \"Mic… 2016-08-07 23:09:08         19837         6402 \"<a href=\\\"…\n##  5 7624008698… \"The… 2016-08-07 21:31:46         34051        11717 \"<a href=\\\"…\n##  6 7622845333… \"I s… 2016-08-07 13:49:29         29831         9892 \"<a href=\\\"…\n##  7 7621109187… \"Tha… 2016-08-07 02:19:37         19223         5784 \"<a href=\\\"…\n##  8 7621069044… \".@L… 2016-08-07 02:03:39         19543         7930 \"<a href=\\\"…\n##  9 7621044117… \"I a… 2016-08-07 01:53:45         75488        24663 \"<a href=\\\"…\n## 10 7620164261… \"#Cr… 2016-08-06 20:04:08         23661         7903 \"<a href=\\\"…\n## 11 7619881643… \"Hea… 2016-08-06 18:11:50         28069         8561 \"<a href=\\\"…\n## 12 7619369299… \"Any… 2016-08-06 14:48:14         35205        13129 \"<a href=\\\"…\n## 13 7619310105… \"Cro… 2016-08-06 14:24:43         36936        13250 \"<a href=\\\"…\n## 14 7618928294… \"Hil… 2016-08-06 11:53:00         32716         9356 \"<a href=\\\"…\n## 15 7617735761… \"Goo… 2016-08-06 03:59:08         34109        10385 \"<a href=\\\"…\n## 16 7617579885… \"'Tr… 2016-08-06 02:57:11         19436         8066 \"<a href=\\\"…\n## 17 7617548986… \"Tha… 2016-08-06 02:44:55         19330         5418 \"<a href=\\\"…\n## 18 7617118564… \"DON… 2016-08-05 23:53:53         30869        16786 \"<a href=\\\"…\n## 19 7616938031… \"Tha… 2016-08-05 22:42:08         19431         5681 \"<a href=\\\"…\n## 20 7616538754… \"#Ma… 2016-08-05 20:03:29         27568        13869 \"<a href=\\\"…"},{"path":"text-processing.html","id":"萃取資料","chapter":"8 Text Processing","heading":"8.1.2 萃取資料","text":"Extracting publishing device tweets","code":"\n# tidyr::extract()\n# stringr::str_replace\n\ntrump_tweets_df$statusSource[1]## [1] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android<\/a>\"\ntweets <- trump_tweets_df %>%\n    select(id, statusSource, text, created) %>%\n    # mutate(source = str_replace(statusSource, \n    #                             \".*Twitter for (.*?)<.*\", \"\\\\1\")) %>%\n    # mutate(source = str_extract(statusSource, 'Twitter for (.*?)<')) %>% View\n    extract(statusSource, \"source\", \"Twitter for (.*?)<\") %>%\n    filter(source %in% c(\"iPhone\", \"Android\"))\n\n# Using stringr::str_replace() to mutate a new source variable, replacing tidyr::\n\n# str(tweets)"},{"path":"text-processing.html","id":"視覺化探索","chapter":"8 Text Processing","heading":"8.1.3 視覺化探索","text":"","code":""},{"path":"text-processing.html","id":"發文時間","chapter":"8 Text Processing","heading":"8.1.3.1 發文時間","text":"Converting timezone lubridate::with_tz()Extracting hour timestamp lubridate::hour()Plotting number tweets hourDisplay y-axis percentage scales::percent_format()","code":"\nlibrary(scales) # for percent_format()\n# lubridate::hour()\n# lubridate::with_tz()\n# scales::percent_format()\n\ntoplot1 <- tweets %>%\n    count(source, hour = hour(with_tz(created, \"EST\"))) %>% \n    # group_by(source) %>%\n    mutate(percent = n / sum(n))\n    # ungroup() %>%\n    \ntoplot2 <- tweets %>%\n    count(source, hour = hour(with_tz(created, \"EST\"))) %>% \n    group_by(source) %>%\n    mutate(percent = n / sum(n)) %>%\n    ungroup()\n\np1 <- toplot1 %>%\n    ggplot() +\n    aes(hour, percent, color = source) +\n    geom_line(size = 1) +\n    scale_color_manual(name = \"Phone System\", \n                       labels = c(\"Android\", \"iPhone\"),\n                       values = c(\"royalblue\", \"gold\")) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(x = \"Hour of day (EST)\",\n         y = \"% of tweets\",\n         color = \"\") + theme_minimal()\np2 <- toplot2 %>%\n    ggplot() +\n    aes(hour, percent, color = source) +\n    geom_line(size = 1) + \n    scale_color_manual(name = \"Phone System\", \n                       labels = c(\"Android\", \"iPhone\"),\n                       values = c(\"royalblue\", \"gold\")) +\n    scale_y_continuous(labels = percent_format()) +\n    labs(x = \"Hour of day (EST)\",\n         y = \"% of tweets\",\n         color = \"\") + theme_minimal()\ncowplot::plot_grid(\n  p1, NULL, p2,\n  labels = c(\"(a) Normalized by all\", \"\", \"(b) Normalized in group\"),\n  nrow = 1, rel_widths = c(1, 0.1, 1)\n)"},{"path":"text-processing.html","id":"發文附圖","chapter":"8 Text Processing","heading":"8.1.3.2 發文附圖","text":"Filtering tweets starting \" (tweets mention #realdonaldtrump)Mutating new variable picture indicate whether text picture ?Counting source picturePlotting bar chart compare difference sources.","code":"\n# library(stringr)\ntoplot <- tweets %>%\n    filter(!str_detect(text, '^\"')) %>%\n    mutate(picture = if_else(str_detect(text, \"t.co\"),\n                             \"Picture/link\", \"No picture/link\")) %>%\n    count(source, picture)\np1 <- toplot %>%\n    ggplot() + \n    aes(source, n, fill = picture) + \n    geom_col(position=\"stack\", width = 0.5) + \n    scale_fill_manual(name = \"With Picture/link?\", \n                      labels = c(\"Yes\", \"No\"),\n                      values = c(\"royalblue\", \"gold\")) + \n    labs(x = \"\", y = \"Number of tweets\", fill = \"\") + theme_minimal()\n\np2 <- toplot %>%\n    ggplot() + \n    aes(source, n, fill = picture) + \n    geom_col(position=\"dodge\") + \n    scale_fill_manual(name = \"With Picture/link?\", \n                      labels = c(\"Yes\", \"No\"),\n                      values = c(\"royalblue\", \"gold\")) + \n    labs(x = \"\", y = \"Number of tweets\", fill = \"\") + theme_minimal()\n\ncowplot::plot_grid(\n  p1, NULL, p2,\n  labels = c(\"(a) Stacked\", \"\", \"(b) Dodged\"), nrow = 1, rel_widths = c(1, 0.1, 1)\n)"},{"path":"text-processing.html","id":"keyness","chapter":"8 Text Processing","heading":"8.1.4 Keyness","text":"","code":"\nlibrary(tidytext)   # unnest_tokens()\nlibrary(stringr)    # str_detect(), str_replace_all()\n\n# View(test)\n\n# stop_words$word\n\ntweet_words <- tweets %>%\n    filter(!str_detect(text, '^\"')) %>%\n    mutate(text = str_replace_all(text, \"https://t.co/[A-Za-z\\\\d]+|&amp;\", \"\")) %>%\n    # unnest_tokens(word, text) %>%\n    # unnest_tokens(word, text, token = \"regex\", pattern = \"[^A-Za-z\\\\d#@']\") %>%\n    mutate(word = str_split(text, \" \")) %>% \n    select(id, text, word, everything()) %>%\n    unnest(word) %>%\n    filter(!word %in% stop_words$word,\n           str_detect(word, \"[a-z]\"))\n# View(tweet_words)\ntweet_words %>%\n  count(word, sort = TRUE) %>%\n  head(20) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word, n)) +\n  geom_col(fill = \"royalblue\") +\n  ylab(\"Occurrences\") +\n  coord_flip() + theme_minimal() + \n  theme(axis.text = element_text(size=10))"},{"path":"text-processing.html","id":"詞頻差異","chapter":"8 Text Processing","heading":"8.1.4.1 詞頻差異","text":"","code":"\ntest <- tweet_words %>%\n    count(word, source) %>%\n    filter(n >= 5) %>%\n    pivot_wider(names_from = source, \n                values_from = n, \n                values_fill = 0)\n# View(test)\n\nword_by_source <- tweet_words %>%\n    count(word, source) %>%\n    filter(n >= 5) %>%\n    pivot_wider(names_from = source, \n                values_from = n, \n                values_fill = 0) %>%\n    # spread(source, n, fill = 0) %>%\n    ungroup()\n\nsum(word_by_source$iPhone)## [1] 1383\nsum(word_by_source$Android)## [1] 2132\nandroid_iphone_ratios <- word_by_source %>%\n    mutate(iPhone = (iPhone+1)/sum(iPhone+1)) %>%\n    mutate(Android = (Android+1)/sum(Android+1)) %>%\n    # mutate_at(.cols = vars(iPhone, Android),\n    # .funs = funs((. + 1) / sum(. + 1))) %>%\n    mutate(logratio = log2(Android / iPhone)) %>%\n    arrange(desc(logratio))"},{"path":"text-processing.html","id":"視覺化log-ratio","chapter":"8 Text Processing","heading":"8.1.4.2 視覺化log-ratio","text":"","code":"\nandroid_iphone_ratios %>%\n    group_by(logratio > 0) %>%\n    top_n(15, abs(logratio)) %>%\n    ungroup() %>%\n    mutate(word = reorder(word, logratio)) %>%\n    ggplot(aes(word, logratio, fill = logratio < 0)) +\n    geom_col() +\n    coord_flip() +\n    ylab(\"Android / iPhone log ratio\") +\n    scale_fill_manual(name = \"\", labels = c(\"Android\", \"iPhone\"),\n                      values = c(\"royalblue\", \"gold\")) + \n    theme_minimal() + \n    theme(axis.text = element_text(size=14))"},{"path":"crawler.html","id":"crawler","chapter":"9 Crawler","heading":"9 Crawler","text":"","code":""},{"path":"crawler.html","id":"scraping-104.com","chapter":"9 Crawler","heading":"9.1 Scraping 104.com","text":"","code":""},{"path":"crawler.html","id":"complete-code","chapter":"9 Crawler","heading":"9.1.1 Complete Code","text":"","code":"\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(jsonlite)\n# options(stringsAsFactors = F)\nall.df <- tibble()\nrefer_url <- \"https://www.104.com.tw\"\n\nfor(p in 1:10){\n    url <- str_c('https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8&order=12&asc=0&page=', \n                 p, \n                 \"&mode=s&jobsource=2018indexpoc\")\n    print(p)\n    res <- GET(url, add_headers(\"referer\"=refer_url)) %>%\n        content(\"text\") %>%\n        fromJSON()\n    \n    res$data$list$tags <- NULL\n    res$data$list$link <- NULL\n    \n    all.df <- bind_rows(all.df, res$data$list)\n}\n\nall.df$jobNo %>% unique %>% length"},{"path":"crawler.html","id":"step-by-step","chapter":"9 Crawler","heading":"9.1.2 Step-by-Step","text":"","code":""},{"path":"crawler.html","id":"get-the-first-pages","chapter":"9 Crawler","heading":"9.1.2.1 Get the first pages","text":"Must loading second page","code":"\nurl1 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=1&mode=s&jobsource=2018indexpoc\"\n\n# Assigning the 2nd page data url to url2\nurl2 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8&order=14&asc=0&page=2&mode=s&jobsource=2018indexpoc\"\n\n# Assigning the 3rd page data url to url3\nurl3 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=3&mode=s&jobsource=2018indexpoc\"\n\n# Getting back the url1 data, assigning to result1\n\nres <- GET(url2, config = add_headers(\"Referer\" = \"https://www.104.com.tw/\"))\n\nres1 <- content(res, \"text\") %>% fromJSON()\n\nresult2 <- fromJSON(content(GET(url2), \"text\"))\n\n# Tracing variable result2 and finding the data.frame, assigning to df2\ndf2 <- res1$data$list"},{"path":"crawler.html","id":"get-the-first-page-by-modifying-url","chapter":"9 Crawler","heading":"9.1.2.2 Get the first page by modifying url","text":"","code":"\n# Guessing the 1st page data url to url1\nurl1 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=1&mode=s&jobsource=2018indexpoc\"\n\n# Getting back the 1st page data\nurl1 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=1&mode=s&jobsource=2018indexpoc\"\n\nresult1 <- fromJSON(content(GET(url1), \"text\"))\n\ndf1 <- result1$data$list"},{"path":"crawler.html","id":"combine-two-data-with-the-same-variables","chapter":"9 Crawler","heading":"9.1.2.3 Combine two data with the same variables","text":"","code":"\n# all.df <- bind_rows(df1, df2) # will raise error\n# Error in bind_rows_(x, .id) : \n#   Argument 31 can't be a list containing data frames"},{"path":"crawler.html","id":"drop-out-hierarchical-variables","chapter":"9 Crawler","heading":"9.1.2.4 Drop out hierarchical variables","text":"Preserving numeric character, dropping list data.frame assigning NULL variable","code":"\n# Drop list and data.frame inside the data.frame\ndf1$link <- NULL\ndf1$tags <- NULL\ndf2$link <- NULL\ndf2$tags <- NULL\n\n# Re-binding two data.frame df1 and df2\nall.df <- bind_rows(df1, df2)"},{"path":"crawler.html","id":"dropping-hierarchical-variables-by-dplyr-way","chapter":"9 Crawler","heading":"9.1.2.5 Dropping hierarchical variables by dplyr way","text":"","code":"\n# Getting the 1st page data and dropping variable tags and link\n# Assigning to df1\ndf1 <- result1$data$list %>% select(-tags, -link)\n\n# Getting the 2nd page data and dropping variable tags and link\n# Assigning to df2\ndf2 <- result2$data$list %>% select(-tags, -link)\n\n# binding df1 and df2\nall.df <- bind_rows(df1, df2)"},{"path":"crawler.html","id":"finding-out-the-last-page-number","chapter":"9 Crawler","heading":"9.1.2.6 Finding out the last page number","text":"","code":"\n# Tracing the number of pages in result1\nlast_page_num <- result1$data$totalPage\n# Checking the availability of the last page\n\n# Examining if the last page data available by re-composing URL with paste0()\nurl.last_page <- paste0(\"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=\", last_page_num, \"&mode=s&jobsource=2018indexpoc\")\n\n# Getting back and parsing the last page data\nresult.last_page <- fromJSON(content(GET(url.last_page), \"text\"))"},{"path":"crawler.html","id":"using-for-loop-to-get-all-pages","chapter":"9 Crawler","heading":"9.1.2.7 Using for-loop to get all pages","text":"","code":"\nfor(p in 1:last_page_num){\n    url <- paste0(\"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=\", p, \"&mode=s&jobsource=2018indexpoc\")\n    result <- fromJSON(content(GET(url), \"text\"))\n    temp.df <- select(result$data$list)\n    print(paste(p, nrow(temp.df)))\n}"},{"path":"crawler.html","id":"combine-all-data.frame","chapter":"9 Crawler","heading":"9.1.2.8 combine all data.frame","text":"","code":"\n#  The 1st url of the query\nurl1 <- \"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=1&mode=s&jobsource=2018indexpoc\"\n\n# Getting back the 1st page data\nresult1 <- fromJSON(content(GET(url1), \"text\"))\n\n# Tracing and getting total number of page\nlast_page_num <- result1$data$totalPage\n\n# Truncating hierarchical variables: link and tags\nall.df <- select(result1$data$list, -link, -tags)\n\n# for-loop to getting back data and joining them\nfor(p in 1:last_page_num){\n    url <- paste0(\"https://www.104.com.tw/jobs/search/list?ro=0&kwop=7&keyword=%E7%88%AC%E8%9F%B2&order=1&asc=0&page=\", p, \"&mode=s&jobsource=2018indexpoc\")\n    result <- fromJSON(content(GET(url), \"text\"))\n    temp.df <- select(result$data$list)\n    all.df <- bind_rows(all.df, temp.df)\n    print(paste(p, nrow(all.df)))\n}"},{"path":"visualization.html","id":"visualization","chapter":"10 Visualization","heading":"10 Visualization","text":"","code":""},{"path":"visualization.html","id":"ggplot","chapter":"10 Visualization","heading":"10.1 ggplot簡介","text":"本節著重在介紹ggplot的基本概念與設定。不同類型的圖表則在下一節「ggplot圖表類型(II)」可在一開始便透過knitr::opts_chunk$set(echo = TRUE, fig.width = 2, fig.asp = 0.4)來一次設定所有圖片。fig.width = 8與fig.height = 6 是以英吋（inches）為單位，或用fig.dim = c(8, 6)一次設定長寬1。echo = TRUE是設定knit出輸出格式（如html）時，也要包含程式碼。如果echo = FALSE的話，就只會輸出文字和圖形。","code":""},{"path":"visualization.html","id":"繪圖基礎折線圖","chapter":"10 Visualization","heading":"10.2 繪圖基礎：折線圖","text":"","code":""},{"path":"visualization.html","id":"繪圖三要素","chapter":"10 Visualization","heading":"10.2.1 繪圖三要素","text":"用ggplot來繪製圖形有三個基本函式ggplot() + aes() + geom_圖表類型。指定要進行繪圖ggplot()：用%>%將資料（dataframe）pipe給ggplot()後，底下各增添的繪圖選項都用+的符號，類似不斷修正繪圖結果的意思。指定X／Y軸與群組因子aes()：指定圖表的X/Y軸分別是什麼變數，有些圖表只需要單一個變數（例如Density-chart和Histogram），有些需要X/Y兩個變數（例如Scatter-chart）什麼的變數要做視覺化，Boxplot甚至可以直接指定最大、最小、Q1、Q3和Median等多個變數。指定要繪製的圖表類型。例如Line-chart為geom_line()、Scatter-chart為geom_point()、Bar-chart為geom_col()或geom_bar()。查閱ggplot cheat sheet可以快速翻閱有哪些圖表類型。ggplot-cheat-sheetggplot() 會秀出預備要繪製的繪圖區指定X／Y軸與群組因子aes()：aes()會在繪圖區上繪製X與Y軸指定要繪製的圖表類型。例如Line-chart為geom_line()、此圖為一雙變數的圖，基於雙變數，可以將不同的圖同時繪製在同一個繪圖區上。例如以下同時繪製了geom_line()與geom_plot()。","code":"\ntibble(a=1:5, b=5:1) %>%\n    ggplot()\ntibble(a=1:5, b=5:1) %>%\n    ggplot() +\n    aes(x=a, y=b)\ntibble(a=1:5, b=5:1) %>%\n    ggplot() +\n    aes(x=a, y=b) + \n    geom_line()\ntibble(a=1:5, b=5:1) %>%\n    ggplot() +\n    aes(x=a, y=b) + \n    geom_line() + \n    geom_point()"},{"path":"visualization.html","id":"範例-紐時世代貧富不均","chapter":"10 Visualization","heading":"10.2.2 範例-紐時世代貧富不均","text":"Teach Inequality 28 New York Times Graphs - New York Times (nytimes.com)ggplot是以變數為基礎的視覺化套件，也就是說，當準備好dataframe後，就可以在ggplot中指定要用哪些變數來繪圖。也因此，務必把dataframe整理為tidy型態，也就是長表格（long-form）的型態。整理完資料後，我會習慣地用names(plot)或glimpse(plot)來看一下該資料所有的變項，好可以在下一階段的繪圖做參考。這是預期視覺化的結果先將year和Net_worth分別繪製在X與Y軸上，並用geom_line()繪製為折現圖。結果圖表中呈現鋸齒狀的折線，看似有問題，但其實是合理的。因為year是一個離散變數，而我們希望每個年齡層一條線的話，那就要照年齡層來分組。也因此，每一年都有有每個年齡層的資料，當我們把「年」作為X軸時，自然同一年就會有數筆不同年齡層的資料，因此才會是鋸齒狀的。不同的圖表類型是可以疊加在同一張圖上的。我們也可以把geom_point() 另一種圖表型態加入，也是可以的，兩者的X與Y不相衝突。geom_line()、geom_point()、geom_text()三者會經常伴隨出現。","code":"\nNW <- read_csv(\"nytdata/interactive_bulletin_charts_agecl_median.csv\") %>%\n    select(Category, year, Net_Worth)  %>%\n    group_by(Category) %>%\n    arrange(year) %>%\n    ungroup()\n\nNW %>% glimpse()## Rows: 66\n## Columns: 3\n## $ Category  <chr> \"Less than 35\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75 or o…\n## $ year      <dbl> 1989, 1989, 1989, 1989, 1989, 1989, 1992, 1992, 1992, 1992, …\n## $ Net_Worth <dbl> 16.17019, 112.47530, 195.11630, 195.25554, 154.34277, 144.29…\nNW %>%\n    ggplot() + \n    aes(x=year, y=Net_Worth) + \n    geom_line()\nNW %>%\n    ggplot() + \n    aes(x=year, y=Net_Worth) + \n    geom_line() +\n    geom_point()"},{"path":"visualization.html","id":"加入自變項群組","chapter":"10 Visualization","heading":"10.2.3 加入自變項群組","text":"上圖是我們把多個年齡層的逐年資料畫在同一條折線上，所以會呈現鋸齒狀折現的狀況。但這些年齡層並非在同一條線上呀？因此，我們要根據Category這個變數來做分組。如希望不同線條上不一樣的色彩，應指定color=Category。用color、fill或group來做分組？\ngeom_line()的色彩是在線，而不是在面上。如果色彩是在點（如geom_point()）或線（geom_line()）上，就是用color來指定顏色。但如果是如類似下面的例子，用geom_area()來視覺化的話，因為顏色填的是面，所以要用fill=Category。以下範例甚至同時指定color=Category, fill=Category。但折線圖如果要用geom_area()來視覺化的話，最好要上顏色的不要超過二個，不然就會像底下這個例子一樣，即使設定alpha=0.2的半透明，仍然會看不懂哪些顏色疊在一起。\ngeom_line()的色彩是在線，而不是在面上。如果色彩是在點（如geom_point()）或線（geom_line()）上，就是用color來指定顏色。但如果是如類似下面的例子，用geom_area()來視覺化的話，因為顏色填的是面，所以要用fill=Category。以下範例甚至同時指定color=Category, fill=Category。但折線圖如果要用geom_area()來視覺化的話，最好要上顏色的不要超過二個，不然就會像底下這個例子一樣，即使設定alpha=0.2的半透明，仍然會看不懂哪些顏色疊在一起。","code":"\nNW %>%\n    ggplot() + \n    aes(x=year, y=Net_Worth, group=Category) + \n    geom_line() + \n    geom_point(stat=\"identity\")\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line()\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category, fill=Category) + \n    geom_area(position=\"dodge\", alpha=0.2)"},{"path":"visualization.html","id":"圖表調整","chapter":"10 Visualization","heading":"10.3 圖表調整","text":"","code":""},{"path":"visualization.html","id":"點線型態","chapter":"10 Visualization","heading":"10.3.1 點線型態","text":"下面的例子同時用了geom_line()和geom_point()，且分別設定了線寬（size=1）、點的大小(size=2)，折線型態（linetype=\"dashed\"）、半透明程度（alpha）。ggplot2 line types : change line types graph R software? - Easy Guides - Wiki - STHDA","code":"\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line(size=1, linetype = \"dashed\", alpha=0.5) + \n    geom_point(size=2, color=\"dimgrey\", alpha=0.5)"},{"path":"visualization.html","id":"標題標籤與圖說","chapter":"10 Visualization","heading":"10.3.2 標題、標籤與圖說","text":"Titles, labels, legend\n設定標題與X／Y軸標題（法一）：以下設定了圖表的圖表標題、和X軸與Y軸的軸標題（xlab與ylab）。設定標題與X／Y軸標題（法二）：這是一次設定圖表標題（title）、次標題（suttitle）、X軸與Y軸標題的方法。調整X軸與Y軸標題位置的：必須要透過theme()來設定axis.title.x = element_text(hjust=1)。去除X／Y軸標題（不佳）：直接將空字串Assign給title、x、與y即可。去除X／Y軸標題（較佳）：透過設定theme()來調整。可發現透過這種設定方法，原本標題和X／Y軸標題的邊界空間就會被釋放出來。","code":"\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() + \n    theme_minimal() + \n    xlab(\"Year\") + \n    ylab(\"Net Worth\") + \n    ggtitle(\"Net Worth by year grouped by age groups\")\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() +  \n    theme_minimal() + \n    labs(title = \"Net Worth by year grouped by age groups\",\n         subtitle = \"Source from: ...\",\n         x = \"Year\",\n         y = \"Net Worth\")\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() + \n    theme_minimal() + \n    labs(title = \"Net Worth by year grouped by age groups\",\n         x = \"Year\",\n         y = \"Net Worth\") + \n    theme(axis.title.x = element_text(hjust=1),\n          axis.title.y = element_text(hjust=1))\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() + \n    theme_minimal() + \n    labs(title = \"\", x = \"\", y = \"\")\n# No extra space for xlab, ylab and title\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line(show.legend = F) + \n    theme_minimal() + \n    theme(plot.title = element_blank(),\n          axis.title.x = element_blank(),\n          axis.title.y = element_blank())"},{"path":"visualization.html","id":"字體樣式","chapter":"10 Visualization","heading":"10.3.3 字體樣式","text":"調整字型會建議都從theme()來做調整，所有圖面上看得到的字都有相對應的變數可以調整字型。例如以下的例子中，把標題的字型大小調整為14粗體、X與Y軸的字型則調整了向右對齊、10粗斜體、顏色為dimgrey。","code":"\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() + \n    theme_minimal() + \n    labs(title = \"Net Worth by year grouped by age groups\",\n         x = \"Year\",\n         y = \"Net Worth\") + \n    theme(plot.title = element_text(size=14, face=\"bold\"),\n          axis.title.x = element_text(hjust=1, size=10,\n                                      color=\"dimgrey\", \n                                      face=\"bold.italic\"),\n          axis.title.y = element_text(hjust=1, size=10,\n                                      color=\"dimgrey\", \n                                      face=\"bold.italic\")\n          )"},{"path":"visualization.html","id":"圖表主題色調","chapter":"10 Visualization","heading":"10.3.4 圖表主題色調","text":"ggplot也有其圖表主題色調。之前範例的灰色圖表背景就是預設的主題，ggplot中還有好幾個預設圖表主題可以選，例如theme_minimal()或theme_tw()等等。Modify components theme — theme • ggplot2 (tidyverse.org)bbplot/bbc_style.R master · bbc/bbplot (github.com)","code":"\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line() + \n    theme_minimal()"},{"path":"visualization.html","id":"預設主題","chapter":"10 Visualization","heading":"10.3.5 預設主題","text":"如果希望所有的圖表都有一致的顏色和排版的調性，可以在一開始編輯Rmd的時候就設計好一套theme()並指給一個變數（例如以下的th）。","code":"\nth <- theme(plot.title = element_text(size=14, face=\"bold\"),\n          axis.title.x = element_text(hjust=1, size=10,\n                                      color=\"dimgrey\", \n                                      face=\"bold.italic\"),\n          axis.title.y = element_text(hjust=1, size=10,\n                                      color=\"dimgrey\", \n                                      face=\"bold.italic\")\n          )\n\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color=Category) + \n    geom_line(linetype = \"dashed\", alpha=0.5) + \n    geom_point(size=2, color=\"dimgrey\", alpha=0.5) + \n    theme_minimal() + \n    labs(title = \"Net Worth by year grouped by age groups\",\n         x = \"Year\",\n         y = \"Net Worth\") + th"},{"path":"visualization.html","id":"顯示中文字體","chapter":"10 Visualization","heading":"10.3.6 顯示中文字體","text":"Python和R這些程式語言的預設視覺化套件都沒辦法顯示中文，所以如果要顯示中文的話，就要指定圖表標題、X、Y軸標籤、圖說和各個部件的字型。因為我在Mac上繪圖，所以我將字型指定為Heiti TC Light。如果想知道自己的電腦上有什麼可以用，可以到電腦的字體簿上查找中文字體名稱，或者上網google「ggplot 中文字型選擇」。下面這是一個長條圖的範例（barplot，不是histogram）。Barplot可以直接指定X軸為縣市（county）和Y軸為總人口數（people_total），但是要用geom_col()而非geom_bar()。除此之外，Bar的顏色有「面」的特徵，所以若要自訂整條bar的顏色，要用fill而非color，color只會是每條Bar的外框。舉例來說，中文字型可以是標楷體（BiauKai）、宋體（Songti TC）、黑體（Heiti TC Light）、蘋方（PingFang TC）、Noto（Noto Sans CJK TC）","code":"\ncounty <- read_csv(\"data/tw_population_opendata110N010.csv\") %>%\n    slice(-1, -(370:375)) %>%\n    type_convert() %>%\n    mutate(county = str_sub(site_id, 1, 3)) %>%\n    group_by(county) %>%\n    summarize(\n        area = sum(area), \n        people_total = sum(people_total)\n    ) %>%\n    ungroup()\ncounty %>%\n    arrange(desc(people_total)) %>%\n    ggplot() + aes(county, people_total) %>%\n    geom_col(fill=\"lightgrey\", color=\"black\") +\n    theme_minimal()\nth <- \n  theme(title = element_text(family=\"Heiti TC Light\"),\n        text = element_text(family=\"Heiti TC Light\"), \n        axis.text.y = element_text(family=\"PingFang TC\"),\n        axis.text.x = element_text(family=\"Heiti TC Light\"),\n        legend.text = element_text(family=\"Heiti TC Light\"),\n        plot.title = element_text(family=\"Heiti TC Light\")\n        )\ncounty %>%\n  ggplot() + aes(county, people_total) %>%\n  geom_col(fill=\"skyblue\") +\n  theme_minimal() + th + \n  theme(axis.text.x = element_text(angle = 45))"},{"path":"visualization.html","id":"xy軸方向","chapter":"10 Visualization","heading":"10.3.7 X/Y軸方向","text":"調整圖表方向通常coord_flip()後往往會希望這些bar會是由上而下排序好的，但用arrange(desc(people_total)是無法解決問題的，因為Y軸原本會是照Y軸的刻度排列，而不是Y軸的數值。所以，要被排序的應該是Y軸的「文字」也就是那些縣市。因此，我們需要將該縣市轉為factor（1~n），並且讓這些縣市被安排的factor數值照people_total排列，因此要用mutate(county = reorder(county, people_total))。reorder()是一個將文字轉factor的函式，但在此特別指定照people_total的編排。","code":"\ncounty %>%\n  ggplot() + aes(county, people_total) %>%\n  geom_col(fill=\"skyblue\") +\n  coord_flip() + \n  theme_minimal() + th + \n  theme(axis.text.x = element_text(angle = 45))\ncounty %>%\n  # arrange(desc(people_total) %>%\n  mutate(county = reorder(county, people_total)) %>%\n  ggplot() + aes(county, people_total) %>%\n  geom_col(fill=\"skyblue\") +\n  coord_flip() + \n  theme_minimal() + th"},{"path":"visualization.html","id":"視覺化說故事的技巧","chapter":"10 Visualization","heading":"10.4 視覺化說故事的技巧","text":"「說故事」才是整則資料新聞的核心，在運用圖表來輔助敘事時，應搭配說理說服的內容來突顯（highlight）圖面上的特徵，而不是留待讀者自己觀察。以下有三種highlight圖表部分資料的方法。第一個方法是在繪圖時用+ scale_color_manual()或+ scale_fill_manual()指定顏色給不同群組；方法二是利用gghighlight這個套件來指定要上色的群組，而且gghighlight可以和fill與color相互搭配，仍然可以用scale_fill_manual和scale_color_manual來指定顏色。但會有個狀況是，如果原本沒群組那怎麼辦？就自己用mutate()打造群組就好。方法各有利弊與使用時機。","code":""},{"path":"visualization.html","id":"依群組指定顏色","chapter":"10 Visualization","heading":"10.4.1 依群組指定顏色","text":"scale_color_manual() 與scale_fill_manual()","code":"\nNW %>% \n    ggplot() + aes(year, Net_Worth, color = Category) + \n    geom_line() + \n    scale_color_manual(\n        limits=c(\"65-74\", \"35-44\"),   # original chart group\n        values=c(\"gold\", \"skyblue\"),  # map to color\n        name=\"Age group\",             # legend title\n        breaks=c(\"65-74\", \"35-44\"),   # original legend group labels\n        labels=c(\"elder(65-74)\",\"younger(35-44)\"), # map to new labels\n        na.value = \"lightgrey\" # color for other groups\n        ) +\n    theme_minimal()"},{"path":"visualization.html","id":"使用gghighlight套件","chapter":"10 Visualization","heading":"10.4.2 使用gghighlight套件","text":"使用gghighlight仍能自己使用scale_color_manual()來指定顏色","code":"\nlibrary(gghighlight)\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color = Category) + \n    geom_line() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    theme_minimal() + \n    scale_x_continuous(breaks = NULL) + \n    theme(panel.background = element_rect(fill = \"whitesmoke\",\n                                colour = \"whitesmoke\",\n                                size = 0.5, linetype = \"solid\"))\nNW %>%    \n    ggplot() + aes(year, Net_Worth, color = Category) + \n    geom_line() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    scale_color_manual(\n        limits=c(\"65-74\", \"35-44\"),   # original chart group\n        values=c(\"gold\", \"skyblue\")) +   # map to color\n    theme_minimal()"},{"path":"visualization.html","id":"為視覺化建立群組","chapter":"10 Visualization","heading":"10.4.3 為視覺化建立群組","text":"這個方法是在原本的資料並沒有可以作為color或fill的因子，所以自行創建一個要突顯的群組。但事實上也可以用gghighlight直接達成","code":"\ncounty %>%\n  mutate(group = if_else(county %in% c(\"新竹縣\", \"新竹市\"), \"highlight\", \"other\")) %>%\n  mutate(county = reorder(county, people_total)) %>%\n  ggplot() + aes(county, people_total, fill=group) %>%\n  geom_col() +\n  scale_fill_manual(values=c(\"highlight\"=\"Khaki\", \"other\"=\"lightgrey\")) +\n  guides(fill=\"none\") + \n  coord_flip() + \n  theme_minimal() + th\ncounty %>%\n    mutate(county = reorder(county, people_total)) %>%\n    ggplot() + aes(county, people_total) %>%\n    geom_col(fill=\"deeppink\") +\n    gghighlight(county %in% c(\"新竹縣\", \"新竹市\")) + \n    guides(fill=\"none\") + \n    coord_flip() + \n    theme_minimal() + th"},{"path":"COORDINATE.html","id":"COORDINATE","chapter":"11 COORDINATE","heading":"11 COORDINATE","text":"Chap3 Coordination & Axis Fundamentals Data Visualization (clauswilke.com)Chapter 8 Visualizing distributions: Empirical cumulative distribution functions q-q plots","code":""},{"path":"COORDINATE.html","id":"排序以展示分佈","chapter":"11 COORDINATE","heading":"11.1 排序以展示分佈","text":"學術論文若要呈現一群數據的分佈時，最常用的是密度（分佈）函數、累積分佈函數，最常視覺化的方法是密度分佈圖（geom_density()）或直方圖（geom_histogram())。然而，對新聞等強調「說故事」的文體而言，說故事的技巧往往不是「那一群資源多或資源少的對象」，而經常要直指「那個對象」，要能夠看得見所敘述的對象在圖中的位置。此時，用密度分佈來呈現的話，只能看出，該對象在分佈的某個位置；但可以改用將資料對象根據某個數據來排序後，繪製折現圖的方式來表現。例如，若要繪製一個班級的成績分佈，通常X軸是分數（組），Y軸是獲得該分數（組）的人數；但其實可以將個體依照分數來做排序，Y軸不是某個分數（組）的個數，而是每個排序後的個體，而且以排序後的序號（Ranking）來表示。用折線圖繪製後，一樣可以看出分數的分佈，但卻能夠直接標記敘事中的某個對象是Y軸中得哪個點。","code":""},{"path":"COORDINATE.html","id":"section","chapter":"11 COORDINATE","heading":"11.1.1 ","text":"Figure 3.5: Population numbers Texas counties relative median value. Select counties highlighted name. dashed line indicates ratio 1, corresponding county median population number. populous counties approximately 100 times inhabitants median county, least populous counties approximately 100 times fewer inhabitants median county. Data source: 2010 Decennial U.S. Census.See ’s Going Graph? | Vaccination Country fromWhat Data Shows Vaccine Supply Demand Vulnerable Places - New York Times (nytimes.com)\noriginal chart animated along timeline.Data Shows Vaccine Supply Demand Vulnerable Places - New York Times (nytimes.com)See ’s Going Graph? | Vaccination Country fromWhat Data Shows Vaccine Supply Demand Vulnerable Places - New York Times (nytimes.com)original chart animated along timeline.Data Shows Vaccine Supply Demand Vulnerable Places - New York Times (nytimes.com)","code":""},{"path":"COORDINATE.html","id":"用log-scale放大長尾頭部","chapter":"11 COORDINATE","heading":"11.2 用Log-scale放大長尾頭部","text":"","code":"\nraw <- read_csv(\"data/opendata107Y020.csv\", show_col_types = FALSE)  %>% \n    slice(-1) %>% \n    type_convert()\n\ntoplot <- raw %>%\n    select(site_id, village, edu_age_15up_total) %>%\n    arrange(desc(edu_age_15up_total)) %>%\n    mutate(index = row_number()) %>%\n    mutate(label = ifelse(index <= 5 | index > n()-5, paste0(site_id, village), \"\"))\n\nlibrary(ggrepel)\np2 <- toplot %>% ggplot() + aes(index, edu_age_15up_total) + \n    geom_point(alpha=0.5, color=\"royalblue\") + \n    geom_text_repel(aes(label = label), point.padding = .4, color = \"black\",\n                  min.segment.length = 0, family = \"Heiti TC Light\") + \n    theme(axis.text.x=element_blank()) + \n    scale_y_log10(breaks = c(0, 1, 10, 100, 1000, 10000)) + \n    theme_minimal()\np1 <- toplot %>% ggplot() + aes(index, edu_age_15up_total) + \n    geom_point(alpha=0.5, color=\"royalblue\") + \n    theme(axis.text.x=element_blank()) + \n    theme_minimal()\n\ncowplot::plot_grid(\n  p2, NULL, p1,\n  labels = c(\"a\", \"\", \"b\"), nrow = 1, rel_widths = c(1, 0.1, 1)\n)"},{"path":"COORDINATE.html","id":"square-root-scale","chapter":"11 COORDINATE","heading":"11.3 Square-root scale","text":"Chap3 Coordination & Axis Fundamentals Data Visualization (clauswilke.com)Figure 3.8: Areas Northeastern U.S. states. () Areas shown linear scale. (b) Areas shown square-root scale. Data source: Google.前面是視覺化了各村里大於十五歲以上人口的人口數分佈，採用對數尺度（log-scale）可以觀察到比較小的村里。那有什麼是適合用平方根尺度（sqrt-scale）的呢？是土地嗎？密度嗎？還是人口數？是村里等級嗎？鄉鎮市區等級嗎？還是縣市等級？\nFigure 11.1: (ref:population-area)\n\nFigure 11.2: (ref:population-area)\n","code":"\ntown <- read_csv(\"data/tw_population_opendata110N010.csv\") %>%\n    slice(-1, -(370:375)) %>%\n    type_convert()\n\ntown %>%\n    arrange(desc(area)) %>%\n    mutate(index = row_number()) %>%\n    ggplot() + aes(index, area) %>%\n    geom_col(fill=\"skyblue\") +\n    scale_y_sqrt() + \n    theme_minimal()\ncounty <- town %>%\n    mutate(county = str_sub(site_id, 1, 3)) %>%\n    group_by(county) %>%\n    summarize(\n        area = sum(area), \n        people_total = sum(people_total)\n    ) %>%\n    ungroup()\n\np1 <- county %>%\n    arrange(desc(people_total)) %>%\n    mutate(index = row_number()) %>%\n    ggplot() + aes(index, people_total) %>%\n    geom_col(fill=\"lightgrey\") +\n    # scale_y_sqrt() +\n    theme_minimal()\n\np2 <- county %>%\n    arrange(desc(people_total)) %>%\n    mutate(index = row_number()) %>%\n    ggplot() + aes(index, people_total) %>%\n    geom_col(fill=\"khaki\") +\n    scale_y_sqrt(breaks=c(0, 250000, 500000, 1000000, 2000000, 4000000)) +\n    theme_minimal()\n\ncowplot::plot_grid(\n  p1, p2,\n  labels = c(\"a\", \"b\"), \n  nrow = 1\n)\nlibrary(tidyverse)\nlibrary(gghighlight)"},{"path":"COORDINATE.html","id":"座標軸從數值到增加值","chapter":"11 COORDINATE","heading":"11.4 座標軸從數值到增加值","text":"","code":""},{"path":"COORDINATE.html","id":"net-worth-by-age-group-wgoitg-of-nytimes","chapter":"11 COORDINATE","heading":"11.4.1 Net Worth by Age Group (WGOITG of NYTIMES)","text":"LEARNING NOTESMedian Inequality這個教學案例來自紐約時報的「’s going gragh」系列資料視覺化教學之Teach Inequality 28 New York Times Graphs - New York Times (nytimes.com) 。該圖表呈現在不同年代、不同年齡層的人所擁有的淨資產（包含土地、存款、投資等減去債務）。該圖表的結果指出，在不同年代的老年人是越來越有錢，但年輕人卻越來越窮（該曲線為減去1989年","code":""},{"path":"COORDINATE.html","id":"read-and-sort-data","chapter":"11 COORDINATE","heading":"11.4.2 Read and sort data","text":"Sorted arrange() function.","code":"\np1 <- read_csv(\"nytdata/interactive_bulletin_charts_agecl_median.csv\") %>%\n    select(year, Category, Net_Worth) %>%\n    group_by(Category) %>%\n    arrange(year) %>%\n    ungroup()\np1 %>% filter(year <= 1992) %>% knitr::kable()\np1 %>% ggplot() + aes(year, Net_Worth, color = Category) + \n    geom_line(linetype=\"dotted\") + \n    geom_point() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    theme_minimal() + \n    scale_x_continuous(breaks = NULL) + \n    theme(panel.background = element_rect(fill = \"white\",\n                                colour = \"white\",\n                                size = 0.5, linetype = \"solid\"))\np2 <- read_csv(\"nytdata/interactive_bulletin_charts_agecl_median.csv\") %>%\n    select(year, Category, NW = Net_Worth)  %>%\n    group_by(Category) %>%\n    arrange(year) %>%\n    mutate(increase = (NW-first(NW))/first(NW)) %>%\n    ungroup()\np2 %>% filter(year <= 1992) %>% knitr::kable()\np2 %>% ggplot() + aes(year, increase, color = Category) + \n    geom_line(linetype=\"dotted\") + \n    geom_point() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    theme_minimal() + \n    scale_y_continuous(labels=scales::parse_format()) + \n    scale_x_continuous(breaks = NULL) + \n    theme(panel.background = element_rect(fill = \"white\",\n                                colour = \"white\",\n                                size = 0.5, linetype = \"solid\"))"},{"path":"COORDINATE.html","id":"等比例座標軸","chapter":"11 COORDINATE","heading":"11.5 等比例座標軸","text":"","code":""},{"path":"COORDINATE.html","id":"unicef-optimistic-wgoith","chapter":"11 COORDINATE","heading":"11.5.1 UNICEF-Optimistic (WGOITH)","text":"https://www.nytimes.com/2021/11/17/upshot/global-survey-optimism.html https://changingchildhood.unicef.org/","code":"\nplot.opt <- read_csv(\"nytdata/unicef-changing-childhood-data.csv\") %>% \n    select(country = WP5, age = WP22140, bw = WP22092) %>%\n    mutate(country = ordered(country, \n                             levels=c(1, 3, 4, 10, 11, 12, \n                                      13, 14, 17, 29, 31, \n                                      33, 35, 36, 60, 61, \n                                      77, 79, 81, 87, 165), \n                             labels=c(\"USA\", \"Morocco\", \"Lebanon\", \n                                      \"Indonesia\", \"Bangladesh\", \n                                      \"UK\", \"France\", \"Germany\",\n                                      \"Spain\", \"Japan\", \"India\", \n                                      \"Brazil\", \"Nigeria\", \"Kenya\", \n                                      \"Ethiopia\", \"Mali\", \"Ukraine\",\n                                      \"Cameroon\", \"Zimbabwe\",\n                                      \"Argentina\", \"Peru\"))) %>%\n    count(country, age, bw) %>%\n    group_by(country, age) %>%\n    mutate(perc = n/sum(n)) %>% \n    ungroup() %>%\n    filter(bw == 1) %>%\n    select(country, age, perc) %>%\n    spread(age, perc) %>%\n    rename(`15-24y` = `1`, `40+y` = `2`)\n\nplot.opt %>% head(10) %>% knitr::kable()\nplot.opt %>%\n    ggplot() + aes(`40+y`, `15-24y`, label = country) + \n    geom_point(color = \"skyblue\", size = 2) + \n    xlim(0, 1) + ylim(0,1) + \n    geom_text(hjust = -0.1, vjust = -0.5) + \n    geom_abline(intercept = 0, slop = 1, \n                color=\"lightgrey\", alpha=0.5, linetype=\"dashed\") + \n    theme_minimal() + \n    theme(aspect.ratio=1)"},{"path":"colors.html","id":"colors","chapter":"12 COLORS","heading":"12 COLORS","text":"","code":""},{"path":"chart-types.html","id":"chart-types","chapter":"13 CHART TYPES","heading":"13 CHART TYPES","text":"","code":""},{"path":"amount.html","id":"amount","chapter":"14 AMOUNT","heading":"14 AMOUNT","text":"","code":""},{"path":"amount.html","id":"bar-chart","chapter":"14 AMOUNT","heading":"14.1 Bar chart","text":"","code":""},{"path":"amount.html","id":"heatmap-vaccination","chapter":"14 AMOUNT","heading":"14.2 Heatmap: Vaccination","text":"這個例子參考(Wilke 2019)在視覺化數量（Amount）時的熱圖範例（Heatmap），但改用為視覺化各國每百人完整注射COVID-19疫苗人數歷時資料。\n- https://ourworldindata.org/covid-vaccinations\n- https://github.com/owid/covid-19-data/tree/master/public/data/vaccinations這個案例使用了三個維度的資料，分別為X軸的時間（月）、Y軸的國家、以及用顏色來呈現各國疫苗注射量（每百人）。並使用geom_tile()來製作熱圖。然而，Y軸的排序卻會影響讀圖。例如，在第一個例子中，Y軸的順序是用最後一個時間點的疫苗注射比例來排序。但每個國家政策和疫苗可獲量均不同，故開始注射和覆蓋速度也差很多，最終覆蓋量也會差很多。所以如果以最終覆蓋量來排序的話，反而不易觀察過程的變化，且「顏色」並不容易用來比較最終覆蓋量的大小，因而會產生很多讀圖上的困擾。另一種繪圖策略是該書上的做法，其Y軸的排序是依照疫苗覆蓋率達到某個數值（例如每百人中有20人完整注射二劑疫苗）的時間早晚來排序。有此作為基準，每個國家在後續時間點的覆蓋速度的比較便比較容易。另外需要注意到，顏色的取捨、以及相對於尺度的漸層設計也會影響讀圖。本例子的資料前處理難度較高（OS：惡魔級）。困難來自於每個國家登記資料的時間不同，因此會產生大量NA值。但在這樣的狀況下，又要找到以月為時間單位的共同數值，就會更挑戰程式編寫者的資料清理技術。除此之外，如何偵測「每個國家超過每百人有二十人完整注射疫苗的時間點」，更是技巧中的技巧。是個磨練NA值處理和高難度資料前處理的好例子。https://clauswilke.com/dataviz/visualizing-amounts.htmlhttps://clauswilke.com/dataviz/visualizing-amounts.html","code":"\nlibrary(lubridate)\nraw <- read_csv(\"data/vaccinations.csv\")\n\nfullvaccinated <- raw %>% select(country = location, date, \n                                people_fully_vaccinated_per_hundred) %>%\n  drop_na(people_fully_vaccinated_per_hundred) %>%\n  mutate(m = floor_date(date, unit = \"month\")) %>%\n  group_by(country, m) %>%\n  arrange(date) %>%\n  slice(1) %>%\n  ungroup() %>%\n  select(-date)\n\nvperc_by_month <- fullvaccinated %>%\n  spread(m, people_fully_vaccinated_per_hundred, fill=NA) %>%\n  gather(month, perc, -country) %>%\n  arrange(country, month) %>%\n  group_by(country) %>%\n  arrange(month) %>%\n  mutate(perc = zoo::na.locf(perc, na.rm = F)) %>%\n  ungroup() %>%\n  arrange(country, month) %>%\n  replace_na(list(perc=0))\nwatched <- c(\"United Arab Emirates\", \"Japan\", \"Singapore\", \n             \"South Korea\", \"Taiwan\", \"Malaysia\", \n             \"Hong Kong\", \"New Zealand\", \"Thailand\", \n             \"Netherlands\", \"United States\", \"Israel\", \n             \"United Kingdom\", \"Indonesia\", \"Thailand\", \"Philippines\")\n\nvperc_by_month %>% \n  spread(month, perc) %>%\n  filter(country %in% watched) %>%\n  mutate(country = reorder(country, -`2022-05-01`)) %>%\n  gather(month, perc, -country) %>%\n  ggplot() + aes(month, country, fill=perc) + \n  geom_tile() + theme_minimal() + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\nvperc_by_month %>% \n  filter(country %in% watched) %>%\n  mutate(month = lubridate::as_date(month)) %>%\n  group_by(country) %>%\n  mutate(month1 = min((month[perc > 20]))) %>% \n  ungroup() %>%\n  spread(month, perc) %>%\n  mutate(country = reorder(country, -as.numeric(month1))) %>%\n  select(-month1) %>%\n  gather(month, perc, -country) %>%\n  ggplot() + aes(month, country, fill=perc) + \n  geom_tile() + theme_minimal() + \n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))"},{"path":"distribution-histogram-density.html","id":"distribution-histogram-density","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15 DISTRIBUTION: Histogram & Density","text":"contet chapter comes book Claus o. Wilke’s “Foundamentals Data Visualization”","code":"\nvilmaster <- readr::read_csv(\"data/tw_vil2018_elccand.csv\") %>%\n  drop_na(當選註記)"},{"path":"distribution-histogram-density.html","id":"density-plot","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.1 Density plot","text":"","code":"\np1 <- vilmaster %>%\n  ggplot()  + aes(年齡) + \n  geom_density() + th\n\np2 <- vilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_density(alpha=0.5) + th + \n  scale_fill_manual(\n    limits=c('1', '2'),           # original chart group\n    values=c(\"gold\", \"skyblue\"),  # map to color\n    name=\"性別\",                  # legend title\n    breaks=c(1, 2),               # original legend group labels\n    labels=c(\"Male\",\"Female\"),    # map to new labels\n    na.value = \"lightgrey\"        # color for other groups\n    )\n\ncowplot::plot_grid(\n  p1, p2,\n  labels = c(\"(a) Overall\", \"(b) Group by gender\"),\n  nrow = 1, rel_widths = c(1, 1)\n)"},{"path":"distribution-histogram-density.html","id":"density-with-different-bandwidth","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.1.1 Density with different bandwidth","text":"","code":"\nlibrary(ggridges) # for geom_density_line()\np.b05 <- vilmaster %>% ggplot()  + aes(年齡) + \n  geom_density_line(fill='gold', bw=0.5, kernel='gaussian') + th\n\np.b1 <- vilmaster %>% ggplot()  + aes(年齡) + \n  geom_density_line(fill='gold', bw=1, kernel='gaussian') + th\n\np.b5 <- vilmaster %>% ggplot()  + aes(年齡) + \n  geom_density_line(fill='gold', bw=5, kernel='gaussian') + th\n\np.rect <- vilmaster %>% ggplot()  + aes(年齡) + \n  geom_density_line(fill='gold', bw=8, kernel='rectangular') + th\n\ncowplot::plot_grid( p.b05, p.b1, p.b5, p.rect,\n  labels = c(\"(a) bw=.5\", \"(b) bw=1\", \"(c) bw=2\", \"(b) rect\"),\n  nrow = 2, rel_widths = c(1, 1)\n)"},{"path":"distribution-histogram-density.html","id":"histogram","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.2 Histogram","text":"","code":""},{"path":"distribution-histogram-density.html","id":"histogram-with-different-number-of-bins","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.2.1 Histogram with different number of bins","text":"","code":"\np10 <- vilmaster %>%\n  ggplot()  + aes(年齡) + \n  geom_histogram(bins=10, fill='royalblue') + th\n\np20 <- vilmaster %>%\n  ggplot()  + aes(年齡) + \n  geom_histogram(bins=20, fill='royalblue') + th\n\np30 <- vilmaster %>%\n  ggplot()  + aes(年齡) + \n  geom_histogram(bins=30, fill='royalblue') + th\n\np40 <- vilmaster %>%\n  ggplot()  + aes(年齡) + \n  geom_histogram(bins=40, fill='royalblue') + th\n\ncowplot::plot_grid(\n  p10, p20, p30, p40,\n  labels = c(\"(a) bins=10\", \"(b) bins=20\", \"(c) bins=30\", \"(b) bins=40\"),\n  nrow = 2, rel_widths = c(1, 1)\n)"},{"path":"distribution-histogram-density.html","id":"density-vs-histogram","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.2.2 Density vs histogram","text":"","code":"\npd <- vilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_density(alpha=0.5) + th + \n  scale_fill_manual(\n    values=c(\"1\"='gold', '2'=\"skyblue\"),\n    labels=c('1'=\"Male\",'2'=\"Female\"),\n    name='Sex'\n    )\n\nph <- vilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_histogram(bins=20, position=\"dodge\") + th + \n  scale_fill_manual(values=c(\"1\"='gold', '2'=\"skyblue \")) + \n  theme(legend.position=\"none\")\n\ncowplot::plot_grid(\n  pd, ph,\n  labels = c(\"(a) geom_density()\", \"(b) geom_histogram()\"),\n  nrow = 1, rel_widths = c(6, 4)\n)"},{"path":"distribution-histogram-density.html","id":"positions-of-bar-chart","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.2.3 Positions of bar chart","text":"","code":"\np.hist.dodge <- vilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_histogram(bins=20, position=\"dodge\") + th + \n  scale_fill_manual(\n    values=c(\"1\"='gold', '2'=\"skyblue \"),\n    labels=c('1'=\"Male\",'2'=\"Female\"),\n    name='Sex'\n  )\n\np.hist.stack <- vilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_histogram(bins=20, position=\"stack\") + th +\n  scale_fill_manual(values=c(\"1\"='gold', '2'=\"skyblue \")) + \n  theme(legend.position=\"none\")\n\ncowplot::plot_grid(\n  p.hist.dodge, p.hist.stack,\n  labels = c(\"(a) position:dodge\", \"(b) position:stack\"),\n  nrow = 1, rel_widths = c(6, 4)\n)"},{"path":"distribution-histogram-density.html","id":"display-two-groups-histogram-by-facet_wrap","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.2.4 Display two groups histogram by facet_wrap()","text":"","code":"\nvilmaster %>%\n  ggplot()  + aes(年齡, fill=factor(性別)) + \n  geom_histogram(bins=20, position=\"dodge\") + th + \n  scale_fill_manual(\n    values=c(\"1\"='gold', '2'=\"skyblue \"),\n    labels=c('1'=\"Male\",'2'=\"Female\"),\n    name='Sex'\n  ) + \n  facet_wrap(.~性別, nrow=1)"},{"path":"distribution-histogram-density.html","id":"pyramid-plot","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.3 Pyramid Plot","text":"","code":""},{"path":"distribution-histogram-density.html","id":"modify-geom_col-to-pyramid-plot","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.3.1 Modify geom_col() to pyramid plot","text":"","code":"\nvilmaster %>%\n  group_by(性別) %>%\n  mutate(age_group = cut(年齡, 0:20*5+.01)) %>%\n  count(age_group) %>%\n  ungroup() %>%\n  ggplot()  + aes(x=age_group, \n                  y=ifelse(性別=='1', -1, 1)*n,\n                  fill=factor(性別)) + \n  geom_col() + \n  scale_y_continuous(name = \"Count\", breaks = 250*(-6:2), labels = c(\"1500\", \"1250\", \"1000\", \"750\", \"500\", \"250\", \"0\", \"250\", \"500\")) + \n  coord_flip() + \n  scale_fill_manual(\n    values=c(\"1\"='gold', '2'=\"skyblue \"),\n    labels=c('1'=\"Male\",'2'=\"Female\"),\n    name='Sex'\n  ) + th + labs(y=\"Count\", x=\"Age Group\")"},{"path":"distribution-histogram-density.html","id":"box-plot-muitiple-distrubution","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.4 Box plot: Muitiple Distrubution","text":"","code":""},{"path":"distribution-histogram-density.html","id":"tw-salary-boxplot","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.4.1 TW-Salary (boxplot)","text":"Inspired Six Myths Choosing College Major - New York Times (nytimes.com) ’s Going Graph? | Jan. 9, 2018 - New York Times (nytimes.com)","code":"\nlibrary(readxl)\nraw <- read_excel(\"data/tw_salary109.xlsx\", sheet=1, trim_ws = T)\nraw\nraw %>%\n    slice(-(1:12)) %>%\n    mutate(Category = reorder(Category, desc(Median))) %>%\n    ggplot() + aes(y = Category, \n                   xlower=Q1, xmiddle=Median, xupper=Q3, xmin=0, xmax=150) +\n    geom_boxplot(stat = \"identity\", color=\"white\", fill=\"skyblue\") +\n    geom_point(aes(x = Mean)) + \n    th + \n    theme(panel.grid.minor = element_blank(), \n          panel.grid.major = element_blank())"},{"path":"distribution-histogram-density.html","id":"tw-income-boxplot","chapter":"15 DISTRIBUTION: Histogram & Density","heading":"15.4.2 TW-Income (boxplot)","text":"","code":"\nlibrary(gghighlight)\ntoplot <- read_csv(\"data/tw_income_107.csv\", ) %>%\n    filter(!`村里` %in% c(\"合計\", \"其他\", \"福住里\")) %>%\n    filter(鄉鎮市區 %in% c(\"信義區\")) %>%\n    mutate(村里 = reorder(村里, desc(中位數)))\n\ntoplot %>% \n    mutate(group = if_else((平均數>第三分位數), \"highlight\", \"none\")) %>%\n    ggplot() + aes(y = 村里, \n                   xlower=第一分位數, xmiddle=中位數, xupper=第三分位數, \n                   xmin= min(第一分位數), xmax=max(第三分位數), fill=group) +\n    geom_boxplot(stat = \"identity\", color=\"white\") +\n    scale_fill_manual(values = c(\"highlight\"=\"orangered\", \"none\"=\"skyblue\")) + guides(fill=FALSE) + \n    geom_point(aes(x = 平均數)) + \n    xlab(\"年所得（單位：千元）\") + \n    th + \n    theme(panel.grid.minor = element_blank(), \n          panel.grid.major = element_blank())"},{"path":"proportion.html","id":"proportion","chapter":"16 PROPORTION","heading":"16 PROPORTION","text":"","code":""},{"path":"proportion.html","id":"pie-chart","chapter":"16 PROPORTION","heading":"16.1 Pie Chart","text":"","code":""},{"path":"proportion.html","id":"dodged-bar-chart","chapter":"16 PROPORTION","heading":"16.2 Dodged Bar Chart","text":"","code":""},{"path":"proportion.html","id":"treemap-nested-proportion","chapter":"16 PROPORTION","heading":"16.3 Treemap: Nested Proportion","text":"","code":""},{"path":"proportion.html","id":"global-carbon-projects-wgoith-nytimes","chapter":"16 PROPORTION","heading":"16.3.1 Global Carbon Projects (WGOITH-NYTIMES)","text":"Historical Responsibility Climate Change? - New York Times (nytimes.com)","code":"\ntotreemap <- read_csv(\"nytdata/GCB2021v34_MtCO2_flat.csv\") %>% \n    drop_na(`Total`) %>%\n    filter(!Country %in% c(\"Global\", \"International Transport\")) %>%\n    filter(Year==2020) %>%\n    arrange(desc(`Total`)) %>%\n    mutate(perc = Total/sum(Total)) %>%\n    slice(1:20)\nlibrary(treemapify)\ntotreemap %>%\n    ggplot() + aes(area = perc, fill=`Per Capita`, label=Country) +\n    geom_treemap() + \n    geom_treemap_text(color=\"white\", \n                      place=\"centre\", \n                      grow=TRUE\n                      )"},{"path":"proportion.html","id":"tw-budget","chapter":"16 PROPORTION","heading":"16.3.2 TW Budget","text":"","code":"\nlibrary(zoo)\n# raw <- readxl::read_excel(\"data/111B歲出政事別預算總表.xls\")\nraw <- readxl::read_excel(\"data/111B歲出政事別預算表.xls\", skip=3, col_names = F) \nnames(raw) <- c(\"款\", \"科\", \"目\", \"節\", \"機構\", \"本年度預算\", \"上年度預算\", \"上年度決算\", \"預算差\")\n# raw$款 <- na.locf(raw$款)\n\ncleand <- raw %>%\n  filter(!is.na(款) | !is.na(科)) %>%\n  slice(-(1:2)) %>%\n  select(-目, -節) %>%\n  mutate(org = purrr::map(機構, function(x){str_split(x, \"\\n\")[[1]][2]})) %>%\n  mutate(款 = ifelse(!is.na(款), unlist(org), unlist(款))) %>%\n  mutate(款 = zoo::na.locf(款)) %>%\n  filter(!is.na(科)) %>%\n  select(-科) %>% type_convert()  %>%\n  mutate(上年度預算 = as.numeric(上年度預算), \n              上年度決算 = as.integer(上年度決算),\n              預算差 = as.numeric(預算差)) %>%\n  replace_na(list(上年度預算 = 0, 上年度決算 = 0)) %>%\n  mutate(預算差 = 本年度預算 - 上年度預算)\ncleand %>%\n  filter(款 %in% c(\"科學支出\")) %>%\n    ggplot() + aes(area = 本年度預算, fill=`本年度預算`, label=org) +\n    geom_treemap() + \n    geom_treemap_text(color=\"white\", \n                      place=\"centre\", \n                      grow=TRUE,\n                      family = \"Heiti TC Light\"\n                      ) + \n  theme(title = element_text(family = \"Heiti TC Light\"),\n        text = element_text(family = \"Heiti TC Light\"))\nlibrary(treemapify)\ncleand %>%\n  # filter(款 %in% c(\"科學支出\", \"教育支出\", \"國防支出\", \"司法支出\")) %>%\n    ggplot() + aes(area = 本年度預算, fill=`本年度預算`, label=org, subgroup = 款) +\n    geom_treemap() + \n    geom_treemap_subgroup_border(color=\"gold\") +\n    geom_treemap_subgroup_text(place = \"centre\", grow = T, alpha = 0.5, colour =\n                             \"gold\", min.size = 0,\n                             family = \"Heiti TC Light\") +\n    geom_treemap_text(color=\"white\", \n                      place=\"centre\", \n                      grow=F,\n                      family = \"Heiti TC Light\"\n                      ) + \n  theme(title = element_text(family = \"Heiti TC Light\"),\n        text = element_text(family = \"Heiti TC Light\"),\n        legend.position = \"none\")"},{"path":"association.html","id":"association","chapter":"17 ASSOCIATION","heading":"17 ASSOCIATION","text":"","code":""},{"path":"association.html","id":"等比例座標軸-1","chapter":"17 ASSOCIATION","heading":"17.1 等比例座標軸","text":"","code":""},{"path":"association.html","id":"unicef-optimistic-wgoith-1","chapter":"17 ASSOCIATION","heading":"17.1.1 UNICEF-Optimistic (WGOITH)","text":"https://www.nytimes.com/2021/11/17/upshot/global-survey-optimism.html https://changingchildhood.unicef.org/","code":"\nplot.opt <- read_csv(\"nytdata/unicef-changing-childhood-data.csv\") %>% \n    select(country = WP5, age = WP22140, bw = WP22092) %>%\n    mutate(country = ordered(country, \n                             levels=c(1, 3, 4, 10, 11, 12, \n                                      13, 14, 17, 29, 31, \n                                      33, 35, 36, 60, 61, \n                                      77, 79, 81, 87, 165), \n                             labels=c(\"USA\", \"Morocco\", \"Lebanon\", \n                                      \"Indonesia\", \"Bangladesh\", \n                                      \"UK\", \"France\", \"Germany\",\n                                      \"Spain\", \"Japan\", \"India\", \n                                      \"Brazil\", \"Nigeria\", \"Kenya\", \n                                      \"Ethiopia\", \"Mali\", \"Ukraine\",\n                                      \"Cameroon\", \"Zimbabwe\",\n                                      \"Argentina\", \"Peru\"))) %>%\n    count(country, age, bw) %>%\n    group_by(country, age) %>%\n    mutate(perc = n/sum(n)) %>% \n    ungroup() %>%\n    filter(bw == 1) %>%\n    select(country, age, perc) %>%\n    spread(age, perc) %>%\n    rename(`15-24y` = `1`, `40+y` = `2`)\n\nplot.opt %>% head(10) %>% knitr::kable()\nplot.opt %>%\n    ggplot() + aes(`40+y`, `15-24y`, label = country) + \n    geom_point(color = \"skyblue\", size = 2) + \n    xlim(0, 1) + ylim(0,1) + \n    geom_text(hjust = -0.1, vjust = -0.5) + \n    geom_abline(intercept = 0, slop = 1, \n                color=\"lightgrey\", alpha=0.5, linetype=\"dashed\") + \n    theme_minimal() + \n    theme(aspect.ratio=1)"},{"path":"time-trends.html","id":"time-trends","chapter":"18 TIME & TRENDS","heading":"18 TIME & TRENDS","text":"","code":""},{"path":"geospatial.html","id":"geospatial","chapter":"19 GEOSPATIAL","heading":"19 GEOSPATIAL","text":"","code":""},{"path":"appendix.html","id":"appendix","chapter":"20 Appendix","heading":"20 Appendix","text":"","code":""},{"path":"appendix.html","id":"dataset","chapter":"20 Appendix","heading":"20.1 Dataset","text":"111B歲出政事別預算表.xls -111B歲出政事別預算總表.xls臺北市住宅竊盜點位資訊-UTF8-BOM-1.csvopendata107Y020.csvopendata110Y060.csvtptheft.csvtw_income_107.csvtw_population_opendata110N010.csvtw_salary109.xlsxvillmast_excel.xlsWORLD-MACHE_Gender_6.8.15.xls","code":""},{"path":"wgoitg.html","id":"wgoitg","chapter":"21 WGOITG of NyTimes","heading":"21 WGOITG of NyTimes","text":"","code":"\nlibrary(tidyverse)\nlibrary(gghighlight)"},{"path":"wgoitg.html","id":"inequality-net-worth-by-age-group","chapter":"21 WGOITG of NyTimes","heading":"21.1 Inequality: Net Worth by Age Group","text":"LEARNING NOTES座標軸從數值到增加值這個教學案例來自紐約時報的「’s going gragh」系列資料視覺化教學之Teach Inequality 28 New York Times Graphs - New York Times (nytimes.com) 。該圖表呈現在不同年代、不同年齡層的人所擁有的淨資產（包含土地、存款、投資等減去債務）。該圖表的結果指出，在不同年代的老年人是越來越有錢，但年輕人卻越來越窮（該曲線為減去1989年Sorted arrange() function.","code":"\np1 <- read_csv(\"nytdata/interactive_bulletin_charts_agecl_median.csv\") %>%\n    select(year, Category, Net_Worth) %>%\n    group_by(Category) %>%\n    arrange(year) %>%\n    ungroup()\np1 %>% filter(year <= 1992) %>% knitr::kable()\np1 %>% ggplot() + aes(year, Net_Worth, color = Category) + \n    geom_line(linetype=\"dotted\") + \n    geom_point() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    theme_minimal() + \n    scale_x_continuous(breaks = NULL) + \n    theme(panel.background = element_rect(fill = \"white\",\n                                colour = \"white\",\n                                size = 0.5, linetype = \"solid\"))\np2 <- read_csv(\"nytdata/interactive_bulletin_charts_agecl_median.csv\") %>%\n    select(year, Category, NW = Net_Worth)  %>%\n    group_by(Category) %>%\n    arrange(year) %>%\n    mutate(increase = (NW-first(NW))/first(NW)) %>%\n    ungroup()\np2 %>% filter(year <= 1992) %>% knitr::kable()\np2 %>% ggplot() + aes(year, increase, color = Category) + \n    geom_line(linetype=\"dotted\") + \n    geom_point() + \n    gghighlight(Category %in% c(\"65-74\", \"35-44\")) + \n    theme_minimal() + \n    scale_y_continuous(labels=scales::parse_format()) + \n    scale_x_continuous(breaks = NULL) + \n    theme(panel.background = element_rect(fill = \"white\",\n                                colour = \"white\",\n                                size = 0.5, linetype = \"solid\"))"},{"path":"wgoitg.html","id":"unicef-global-survey-optimism","chapter":"21 WGOITG of NyTimes","heading":"21.2 UNICEF-Global Survey Optimism","text":"運用等比例之座標軸https://www.nytimes.com/2021/11/17/upshot/global-survey-optimism.html https://changingchildhood.unicef.org/","code":"\nplot.opt <- read_csv(\"nytdata/unicef-changing-childhood-data.csv\") %>% \n    select(country = WP5, age = WP22140, bw = WP22092) %>%\n    mutate(country = ordered(country, \n                             levels=c(1, 3, 4, 10, 11, 12, \n                                      13, 14, 17, 29, 31, \n                                      33, 35, 36, 60, 61, \n                                      77, 79, 81, 87, 165), \n                             labels=c(\"USA\", \"Morocco\", \"Lebanon\", \n                                      \"Indonesia\", \"Bangladesh\", \n                                      \"UK\", \"France\", \"Germany\",\n                                      \"Spain\", \"Japan\", \"India\", \n                                      \"Brazil\", \"Nigeria\", \"Kenya\", \n                                      \"Ethiopia\", \"Mali\", \"Ukraine\",\n                                      \"Cameroon\", \"Zimbabwe\",\n                                      \"Argentina\", \"Peru\"))) %>%\n    count(country, age, bw) %>%\n    group_by(country, age) %>%\n    mutate(perc = n/sum(n)) %>% \n    ungroup() %>%\n    filter(bw == 1) %>%\n    select(country, age, perc) %>%\n    spread(age, perc) %>%\n    rename(`15-24y` = `1`, `40+y` = `2`)\n\nplot.opt %>% head(10) %>% knitr::kable()\nplot.opt %>%\n    ggplot() + aes(`40+y`, `15-24y`, label = country) + \n    geom_point(color = \"skyblue\", size = 2) + \n    xlim(0, 1) + ylim(0,1) + \n    geom_text(hjust = -0.1, vjust = -0.5) + \n    geom_abline(intercept = 0, slop = 1, \n                color=\"lightgrey\", alpha=0.5, linetype=\"dashed\") + \n    theme_minimal() + \n    theme(aspect.ratio=1)"},{"path":"wgoitg.html","id":"global-carbon-projects","chapter":"21 WGOITG of NyTimes","heading":"21.3 Global Carbon Projects","text":"Historical Responsibility Climate Change? - New York Times (nytimes.com)","code":"\ntotreemap <- read_csv(\"nytdata/GCB2021v34_MtCO2_flat.csv\") %>% \n    drop_na(`Total`) %>%\n    filter(!Country %in% c(\"Global\", \"International Transport\")) %>%\n    filter(Year==2020) %>%\n    arrange(desc(`Total`)) %>%\n    mutate(perc = Total/sum(Total)) %>%\n    slice(1:20)\nlibrary(treemapify)\ntotreemap %>%\n    ggplot() + aes(area = perc, fill=`Per Capita`, label=Country) +\n    geom_treemap() + \n    geom_treemap_text(color=\"white\", \n                      place=\"centre\", \n                      grow=TRUE\n                      )"}]
