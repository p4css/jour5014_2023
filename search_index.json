[["index.html", "R for Data Journalism About", " R for Data Journalism HSIEH, JI-LUNG 2023-04-20 About 這本書是寫給臺大新聞所「新聞資料分析與視覺化」課程使用。該課程並重三個面向的訓練：程式語言、視覺化、資料新聞。學生必須先能夠熟練地使用R語言來操作、讀取、清理、視覺化資料；然後以產製新聞為課程目標，了解資料要如何清理，以及選擇適合的視覺化的方法來強化新聞敘事，並避免視覺化方式引起讀者對新聞的理解謬誤。準此，本書分為幾個部分，包含PART I介紹程式語言基礎；PART II則以國際或國內新聞為個案，來介紹資料獲取（爬蟲）、清理、合併、篩選、轉換；PART III則著重如何用資料視覺化來強化敘事。 本書所沿用的資料分析與視覺化案例均為國內、國外的新聞案例如各國產假支薪等級、居住正義、空氣污染、人口議題、COVID-19、資源區域分佈不均、選舉與公投、運輸交通等相關議題的新聞。並大量採用紐約時報挑選作為數據理解與視覺化推廣的「What’s going on in this graph?」系列新聞，包含美國不同年代各年齡層的淨資產來做視覺化案例。在視覺化教材的設計上，本書大量參考紐時「What’s going on in this graph?」的分類與(Wilke 2019)所著「Fundamentals of Data Visualization」一書的內容安排，強調利用資料視覺化方法來呈現新聞數據中的數量、分佈、比例、趨勢等，並均換用國內或紐時的相關資料新聞案例做範例，以利中文讀者的理解。 學習路徑 References "],["introduction.html", "Chapter 1 Introduction 1.1 Cases in the book", " Chapter 1 Introduction 本書從基本的 base R 語法開始學習，因為 R 語言最初是為統計學研究而開發的。因此，許多統計套件和基礎操作都是使用 base R 語法編寫的，這些知識對於瞭解 R 的核心功能和基本操作是非常重要的，並能夠建立起對於數據分析和統計建模的基礎知識。不過，現在 tidyverse 風格的編寫方式越來越流行，這種方式更加高效和可讀性更強，對於數據科學家而言是非常有用的。因此，我們的書籍會引入和使用 tidyverse 中的主要包和函數，例如 dplyr、ggplot2 和 tidyr，以便讀者能夠掌握這些工具，並能夠有效地應用於實際數據分析項目中。 當 R 的程式開始執行時，會預載入一些基本的套件，包括 stats、graphics、grDevices、utils 和 datasets。這些套件為 R 提供了基本的數據處理、統計分析、圖形顯示和檔案處理等功能。以下是這些套件的重要函式： stats：這個套件包含了許多統計分析相關的函式，例如假設檢定、方差分析、線性迴歸和時間序列分析等。其中，比較常用的函式有 t.test()、lm()、glm()、anova()、cor() 等。 graphics：這個套件提供了用於繪製各種圖形的函式，例如散佈圖、直方圖、盒鬚圖、線圖、散點矩陣等。其中，常用的函式有 plot()、hist()、boxplot()、lines()、points() 等。 grDevices：這個套件包含了用於輸出圖形的函式，例如 pdf()、png()、jpeg() 和 tiff() 等。 utils：這個套件包含了一些實用的函式，例如 install.packages()、help()、data() 等。 datasets：這個套件包含了一些內建的數據集，可以用來進行測試和練習，例如 iris、mtcars、CO2 等。可以使用 data() 函式載入這些數據集。 1.1 Cases in the book WP: Paid maternity leave Taipei Residential Hot spot: Contingency table, categorical data Trump’s tweets: Line plot, Bar chart, timeline, and text processing NYT: Net worth: Line plot NYT: Carbon Proportion: Treemap NYT: Optimism by countries NYT: Population growth Annual Budget of TW government: NA Processing, Treemap Vaccinating proportion by country x year: Proportion NYT: LeBron James’s Achievement "],["basic.html", "Chapter 2 R Basic 2.1 Using RStudio 2.2 First Attempt 2.3 R Q&amp;A", " Chapter 2 R Basic 本章介紹如何使用 RStudio 編寫和執行 R 程式語言、R語言的基本語法、以及Vector和data.frame資料型態。 2.1 Using RStudio 2.1.1 RStudio Interface RStudio的介面主要分為四大區塊，左上的區塊是「Source」（或現在可切換至「Visual」）是撰寫程式碼與R Markdown的區塊；每行程式碼的執行和執行結果都會出現在左下「Console」的區塊；右上角區塊最常用的是「Environment」這個分頁，程式碼執行過程產生的變數／變項都會出現在這裡。右下角區塊我最常用的是「Files」這個分頁，顯示的是我自己電腦本機端的檔案目錄。右下角區塊也常常用到「Packages」，可查閱現在的程式執行環境有載入哪些套件；當用help(some_function)查詢某個套件或某個函式的功能是，就會自動跳到「Help」分頁。 2.1.2 Writing R Markdown R Markdown這種格式讓程式寫作者可以將程式碼和非程式碼的內容寫在同一份文件中。例如我想要寫作一本關於程式的書，裡面有很多的程式碼，但也要有很多說明、章節與段落。此時，這些非程式碼的區塊通常被稱為「內容區塊（Text Cell）」，而程式碼的區塊就稱為「Code Cell」。尤其是資料分析師或資料科學家很愛用這種格式，因為經常要為程式的執行結果寫很多說明，甚至利用標題一、標題二來區分章節。 內容區塊使用Markdown格式撰寫，顧名思義，支援用Markdown這種標記語法來快速撰寫如標題一、標題二、點列、編號等格式化文字。詳細指令可以參考rmarkdown-cheatsheet (rstudio.com)。 程式碼區塊可以用下列鍵盤指令來新增和執行。 Cmd(Ctrl)+Option(Alt)+i 新增一個程式碼區塊 Cmd+Enter (Ctrl+Enter in Window) 執行程式碼區塊中游標所在的那一行指令。 Cmd(Ctrl)+Shift+Enter 執行游標所在的整個程式碼區塊 其他常用鍵盤指令 - 註解：用滑鼠或鍵盤圈選某幾行程式碼後，可用Cmd(Ctrl)+Shift+c來將這幾行標記為註解或將其去除註解標記。 Practice. 用鍵盤快速鍵新增一個程式碼區塊、輸入以下程式碼並嘗試用鍵盤快速鍵執行。 a &lt;- c(1, 2, 3, 4, 5) b &lt;- 4 a*b 2.1.3 Installing third-party packages 套件的使用分為安裝(install.packages(\"pkg_name\"))和載入（library(pkg_name)）兩個動作。通常安裝好R的時候就已經安裝好基本base套件。當執行R時便會將base套件預載入程式的執行環境中。 非常多的R使用者會編寫第三方套件，並且將這些套件開放給群眾使用。通常這些套件已經被上載到R cran提供下載。而R cran上的套件我們可以使用install.packages(\"package_name\")來自動安裝到我們的電腦中。 Practice 1. 執行以下程式碼 install.packages(&quot;tidyverse&quot;) install.packages(&quot;jsonlite&quot;) install.packages(&quot;httr&quot;) 2.1.3.1 Loading package 在安裝這些第三方套件之後，需要將它們載入到程式的運行環境中，然後才能使用。因此，需要使用 library(package_name) 命令來載入它們。 library(tidyverse) library(jsonlite) library(httr) 2.1.4 Code “Comment” 下列程式碼中開頭有#符號者為註解，程式設計師用這種註解來為程式碼做說明，便於自己日後閱讀或與他人溝通。程式在執行時會自動忽略前面有#符號的程式碼。如果要執行以下程式碼，要把前面的#記號給拿掉。在RStudio中你可以用滑鼠或鍵盤圈選下三行，然後用快速鍵command(ctrl)+shift+c就可以開關（Comment/Un-comment)這幾行程式碼。 # a &lt;- c(1, 2, 3, 4, 5) # b &lt;- 4 # a*b 2.2 First Attempt 2.2.1 Loading Open Data from the MOS library(httr) library(jsonlite) url &lt;- &quot;https://www.ris.gov.tw/rs-opendata/api/v1/datastore/ODRP024/107?page=1&quot; first_page &lt;- fromJSON(content(GET(url), &quot;text&quot;)) # head(first_page$responseData) head(first_page$responseData) %&gt;% rename(戶長=headhousehold_count) ## statistic_yyy district_code site_id village edu sex 戶長 ## 1 107 65000010001 新北市板橋區 留侯里 博畢 男 3 ## 2 107 65000010001 新北市板橋區 留侯里 碩畢 男 26 ## 3 107 65000010001 新北市板橋區 留侯里 大畢 男 71 ## 4 107 65000010001 新北市板橋區 留侯里 專畢 男 52 ## 5 107 65000010001 新北市板橋區 留侯里 高中畢 男 122 ## 6 107 65000010001 新北市板橋區 留侯里 國中畢 男 40 2.2.2 Obtaining ubike realtime data https://taipeicity.github.io/traffic_realtime/ url &lt;- &quot;https://tcgbusfs.blob.core.windows.net/blobyoubike/YouBikeTP.json&quot; ubike.list &lt;- fromJSON(content(GET(url),&quot;text&quot;, encoding = &quot;utf-8&quot;)) ubike.v &lt;- unlist(ubike.list$retVal) ubike.m &lt;- matrix(ubike.v, byrow = T, ncol = 14) ubike.df &lt;- as.data.frame(ubike.m) names(ubike.df) &lt;- names(ubike.list$retVal$`0001`) head(ubike.df) %&gt;% select(1:6) ## sno sna tot sbi sarea mday ## 1 0001 捷運市政府站(3號出口) 84 72 信義區 20221030161036 ## 2 0002 捷運國父紀念館站(2號出口) 16 3 大安區 20221030161031 ## 3 0004 市民廣場 32 0 信義區 20221030161017 ## 4 0005 興雅國中 10 1 信義區 20221030161041 ## 5 0006 臺北南山廣場 54 12 信義區 20221030161029 ## 6 0007 信義廣場(台北101) 20 2 信義區 20221030161027 2.2.3 Reading Taipei Residential Burglary Data 該資料網址可到臺北市資料大平臺 (data.taipei)上查詢「住宅竊盜點位資訊」後，點選「API」後複製取得。 url &lt;- &quot;https://data.taipei/api/v1/dataset/93d9bc2d-af08-4db7-a56b-9f0a49226fa3?scope=resourceAquire&quot; res &lt;- read_json(url, simplifyVector = T) df &lt;- res$result$results head(df) dplyr::glimpse(df) 2.3 R Q&amp;A 2.3.1 Encoding and Language Sys.setlocale(category = &quot;LC_ALL&quot;, locale = &quot;UTF-8&quot;) Sys.setlocale(category = &quot;LC_ALL&quot;, locale = &quot;cht&quot;) 如果讀取到資料有中文的話，此時，你只需要指定locale為cht，然後重開該data.frame就可以解決該問題。 Sys.setlocale(category = &quot;LC_ALL&quot;, locale = &quot;cht&quot;) 但你在寫程式剖析HTML時若使用了rvest這個套件，有可能在html_node()函式時會因為編碼而產生問題，此時你會需要把locale改為C。這個C指的是C語言的C。 Sys.setlocale(category = &quot;LC_ALL&quot;, locale = &quot;C&quot;) 參考連結：http://psmethods.postach.io/post/ru-he-geng-gai-rde-yu-she-yu-xi 參考連結：https://stat.ethz.ch/R-manual/R-devel/library/base/html/locales.html The locale describes aspects of the internationalization of a program. Initially most aspects of the locale of R are set to “C” (which is the default for the C language and reflects North-American usage) 2.3.2 RMD/R Notebook無法儲存 R Notebook 要存檔的時候檔名絕對不要有空白，若有空白就用底線_代替，否則Notebook寫到一半會無法預覽下半部的程式並出現錯誤訊息。若仍然無法儲存或出現錯誤訊息，應該只要開另外一個R Notebook檔案，複製程式碼即可。 "],["r-basic.html", "Chapter 3 R Basic 3.1 R Syntax 3.2 Vector 3.3 Calculating with vectors 3.4 Data types 3.5 Character operations", " Chapter 3 R Basic R base是R語言的基本程式庫和核心功能，提供了許多常用的指令和函數。以下是一些常見的R base指令： assignment operators（賦值運算符）：&lt;- 或 = 用來將數值、向量、函數等資料物件賦值給變數。 arithmetic operators（算術運算符）：+、-、*、/、^、%/%和%%用於數值運算，如加、減、乘、除、指數、整除和取餘等。 relational operators（關係運算符）：==、!=、&gt;、&gt;=、&lt;和&lt;=用於比較數值或字符型資料的大小關係，返回邏輯值（TRUE或FALSE）。 logical operators（邏輯運算符）：&amp;、|和!用於對邏輯值進行運算，如AND、OR和NOT等。 control flow statements（流程控制語句）：if、else、for、while、repeat、break和next用於控制程式的執行流程。 functions（函數）：R base提供了許多內置函數，如sum、mean、var、sd、cor、lm等，用於數值計算、統計分析、線性回歸等常見操作。 data structures（資料結構）：R base提供了多種資料結構，如向量、矩陣、數組、列表、因子等，用於存儲和處理不同類型的資料。 data input/output（資料輸入輸出）：R base提供了多種函數和工具，如read.table、write.table、read.csv、write.csv等，用於讀取和寫入資料。 3.1 R Syntax 3.1.1 Assignment &lt;- 將右邊的算式或數值指派給左邊的變數。右邊如果是numeric，那左邊的變數就是numeric variable；右邊如果是character，左邊的變數就是character variable。 在幾乎所有程式語言中，單等號=指的是assignment，把右方的算式、值或物件指給左方的變數。而比較兩者相不相等，則用雙等號==，例如1==3-2。 a &lt;- 1 b &lt;- c(1, 2, 3, 4) c &lt;- c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;) d &lt;- c(b, a) e &lt;- &quot;abcd&quot; 3.1.2 Comments 註解 註解：在程式碼區塊若前面有#字號後面跟著空白的話，那代表那行被標示為註解，程式執行時會自動跳過註解不執行。 快速鍵：當游標在某一行程式碼時打cmd(ctrl)-shift-c，就可以產生註解。 # df &lt;- data.frame(a = c(1, 2, 3), b = c(3, 4, 5)) 3.2 Vector 在R語言中，vector是一種基本的資料類型，它是由相同類型的元素組成的序列，可以存儲數值、文字、邏輯值等不同類型的資料。例如，以下是一個由整數元素組成的vector：my_vector &lt;- c(1, 2, 3, 4, 5)。 在程式碼中，只要是文字必用成對的雙引號或單引號包含其中，以區隔「變數」和「數字」。例如如果看到沒有雙引號的「英文字母」必定是變數名稱，或函式名稱。如果看到有雙引號的數字，那也是文字。 以下資料來自各縣市平均每月薪資所得或各縣市人口數。 3.2.1 Creating vectors vector通常用c()函數創建，其中c表示”combine”或”concatenate”，可以將多個元素組合成一個vector。 income &lt;- c(70100, 51300, 51100, 48400, 47600, 43000) county &lt;- c(&quot;台北&quot;, &quot;新北&quot;, &quot;桃園&quot;, &quot;高雄&quot;, &quot;台中&quot;, &quot;台南&quot;) population &lt;- c(2.6, 3.9, 2.2, 2.7, 2.8, 1.8) area &lt;- c(271.8, 2052.5, 1221, 2951.9, 2214.9, 2191.7) income ## [1] 70100 51300 51100 48400 47600 43000 county[c(5, 3, 1)] ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; county &lt;- county[c(5, 3, 1)] county ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; area ## [1] 271.8 2052.5 1221.0 2951.9 2214.9 2191.7 population ## [1] 2.6 3.9 2.2 2.7 2.8 1.8 3.2.1.1 Creating a sequence a &lt;- seq(11, 99, 11) a ## [1] 11 22 33 44 55 66 77 88 99 b &lt;- 11:20 b ## [1] 11 12 13 14 15 16 17 18 19 20 3.2.1.2 Creating sequences by distribution x &lt;- runif(10000000, 1, 10) # uniform dist, n=1000 plot(density(x)) x &lt;- rnorm(1000, 1, 10) # uniform dist, n=1000 plot(density(x)) x &lt;- rnorm(10000000, 1, 10) # normal dist, n=1000 plot(density(x)) 3.2.2 Viewing county ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; income ## [1] 70100 51300 51100 48400 47600 43000 head(county) ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; tail(county) ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; length(county) ## [1] 3 mode(county) ## [1] &quot;character&quot; class(county) ## [1] &quot;character&quot; # View(county) length(county) ## [1] 3 length(income) ## [1] 6 3.2.3 Subsetting, filtering vector可以用中括號[]搭配數字來取用vector中的元素，下標從1開始。例如，要取用上述的vector中的第三個元素，可以使用my_vector[3]。 It is important to know how to neglect first n or last n elements. For example, a[1:(length(a)-2)] will neglect the last two elements. Thinking why I need parentheses for length(a)-2 here. county ## [1] &quot;台中&quot; &quot;桃園&quot; &quot;台北&quot; county[c(5, 3, 1)] # how about country[c(1, 3, 5)] ## [1] NA &quot;台北&quot; &quot;台中&quot; county[3:6] # is it equal to country[c(3, 4, 5, 6)] ## [1] &quot;台北&quot; NA NA NA a &lt;- 11:19 a[3:length(a)] ## [1] 13 14 15 16 17 18 19 a[length(a):3] ## [1] 19 18 17 16 15 14 13 3.2.4 Deleting Without assignment, deletion won’t change original vectors b &lt;- 11:20 b[-(3:5)] ## [1] 11 12 16 17 18 19 20 b[-c(1, 3, 5)] ## [1] 12 14 16 17 18 19 20 b ## [1] 11 12 13 14 15 16 17 18 19 20 Correct deleting operations with assignment to replace original vector b &lt;- b[-(3:5)] b ## [1] 11 12 16 17 18 19 20 a &lt;- seq(11, 99, 11) a &lt;- a[-c(1, 3, 5)] a ## [1] 22 44 66 77 88 99 3.2.5 Concatenating Concatenating is quite useful for web crawling when you crawl article links page by page. You may be not sure the number of page you need to crawl. So you need to append entire new vector to old vector. It is concatenating. (“Appending” often means adding one new element at the end of data.) a &lt;- 1:10 a &lt;- c(a, 11) a ## [1] 1 2 3 4 5 6 7 8 9 10 11 b ## [1] 11 12 16 17 18 19 20 a &lt;- c(a, b) a ## [1] 1 2 3 4 5 6 7 8 9 10 11 11 12 16 17 18 19 20 a &lt;- c(a, a, b) a ## [1] 1 2 3 4 5 6 7 8 9 10 11 11 12 16 17 18 19 20 1 2 3 4 5 6 7 ## [26] 8 9 10 11 11 12 16 17 18 19 20 11 12 16 17 18 19 20 3.3 Calculating with vectors 3.3.1 Arithmetic operations a &lt;- 11:19 a + 3 ## [1] 14 15 16 17 18 19 20 21 22 a / 2 ## [1] 5.5 6.0 6.5 7.0 7.5 8.0 8.5 9.0 9.5 a %% 2 ## [1] 1 0 1 0 1 0 1 0 1 a %/% 2 ## [1] 5 6 6 7 7 8 8 9 9 a %% 2== 0 ## [1] FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE which(a %% 2== 0) ## [1] 2 4 6 8 a[which(a%% 2 == 0)] ## [1] 12 14 16 18 a[c(2, 4, 6, 8)] ## [1] 12 14 16 18 a %% 2 != 0 ## [1] TRUE FALSE TRUE FALSE TRUE FALSE TRUE FALSE TRUE a[a%% 2 == 0] ## [1] 12 14 16 18 a[a%%2 != 0] ## [1] 11 13 15 17 19 a &lt;- a %% 2 # modular arithmetic, get the reminder a &lt;- a %/% 2 # Quotient 3.3.2 Logic comparisons a %% 2 == 0 # deteting odd/even number ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE a %% 2 != 0 ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE a[a%%2==0] ## [1] 0 0 0 0 0 0 0 0 0 a &gt; b ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE income &gt; mean(income) ## [1] TRUE FALSE FALSE FALSE FALSE FALSE TRUE == T # == equal to, ## [1] TRUE TRUE != F # != Not equal to ## [1] TRUE any(a&gt;11) # is there any element larger than 1 ## [1] FALSE all(a&gt;11) # are all elements larger than 1 ## [1] FALSE 3.3.3 Subsetting by logic comparisons two methods to filter data from vectors, by index vector or a logical vector with equal length. a &lt;- seq(11, 55, 11) a[c(T, F, T, F, T)] ## [1] 11 33 55 a[a%%2==1] ## [1] 11 33 55 a%%2 ## [1] 1 0 1 0 1 a%%2==1 ## [1] TRUE FALSE TRUE FALSE TRUE a &lt;- c(&quot;你好&quot;,&quot;你好棒棒&quot;,&quot;你好棒&quot;,&quot;你真的好棒&quot;) a[nchar(a)&gt;3] ## [1] &quot;你好棒棒&quot; &quot;你真的好棒&quot; # which will return &quot;index-of&quot; a &lt;- seq(11, 55, 11) a[which(a%%2==1)] ## [1] 11 33 55 which(a%%2==1) ## [1] 1 3 5 3.3.4 Sorting and ordering sort(x)的結果必須用&lt;-覆蓋原本的x，此時的x才算被排序的結果。 order(x)函式會傳回x數值由小到大的索引。這個例子的結果是5, 4, 3, 6, 1, 2，也就是5位置的那個數最小、4那個位置的數次小、接下來3, 6, 1, 2。 x[order(x)]把order(x)結果（也就是c(5, 4, 3, 6, 1, 2)）傳給原本的x便會使得原本的x重新排序。通常order()的用途是，我們可以將兩個等長的variables例如var1和var2，依據var2來重新排序var1，例如var1[order(var2)]。 x &lt;- c(33, 55, 22, 13, 4, 24) mode(x) ## [1] &quot;numeric&quot; class(x) ## [1] &quot;numeric&quot; sort(x) ## [1] 4 13 22 24 33 55 # x &lt;- sort(x) # assign to replace original x order(x) ## [1] 5 4 3 6 1 2 x[order(x)] ## [1] 4 13 22 24 33 55 x[c(5, 4, 3, 6, 1, 2)] ## [1] 4 13 22 24 33 55 3.3.5 Built-in math functions a &lt;- 11:19 min(a); max(a); mean(a); median(a); sd(a) ## [1] 11 ## [1] 19 ## [1] 15 ## [1] 15 ## [1] 2.738613 log2(a) ## [1] 3.459432 3.584963 3.700440 3.807355 3.906891 4.000000 4.087463 4.169925 ## [9] 4.247928 log1p(a) ## [1] 2.484907 2.564949 2.639057 2.708050 2.772589 2.833213 2.890372 2.944439 ## [9] 2.995732 ?log1p 3.4 Data types 3.4.1 Checking data type mode(county) # character ## [1] &quot;character&quot; mode(income) # numeric ## [1] &quot;numeric&quot; mode(income &gt; mean(income)) # logical ## [1] &quot;logical&quot; testing &lt;- c(&quot;26.142&quot;, &quot;12.008&quot;, &quot;7.032&quot;, &quot;13.646&quot;, &quot;4.589&quot;) mode(testing) # character ## [1] &quot;character&quot; 3.4.2 Converting data type numeric vector可以用as.character(x)轉成charcter；logical vector可以用as.numeric(x)轉為numeric。概念上可以說是character &gt; numeric &gt; logical。 如果硬是在logical vector後附加一個numeric element的話，那就會整個vector被轉為numeric vector；相仿地，如果numeric vector後附加一個character element的話那整個vector就會被轉為character vector。 可以用sum()函式來計算logical vector有幾個TRUE值。例如sum(a%%2==1)就是計算a中有幾個奇數。TRUE可視為1、FALSE可視為0，所以加總起來就是TRUE有幾個。 income.c &lt;- as.character(income) population.c &lt;- as.numeric(population) a &lt;- seq(11, 99, 11) a &lt;- c(a, &quot;100&quot;) a &lt;- seq(11, 99, 11) sum(a%%2==1) ## [1] 5 max(a) ## [1] 99 3.5 Character operations a &lt;- seq(11, 55, 11) paste(&quot;A&quot;, a) # concatenate ## [1] &quot;A 11&quot; &quot;A 22&quot; &quot;A 33&quot; &quot;A 44&quot; &quot;A 55&quot; paste0(&quot;A&quot;, a) # concatenate ## [1] &quot;A11&quot; &quot;A22&quot; &quot;A33&quot; &quot;A44&quot; &quot;A55&quot; "],["dataframe.html", "Chapter 4 Dataframe 4.1 基本操作 4.2 簡易繪圖 4.3 基本操作：使用dplyr 4.4 tibble, data_frame, data.frame 4.5 Database - SQLite 4.6 Paid Maternity Leave", " Chapter 4 Dataframe 4.1 基本操作 4.1.1 產生新的Dataframe 4.1.1.1 複製資料至vector 直接複製Wikipedia上的台北市某五區人口資料 population &lt;- c(158228, 126687, 228075, 204903, 308383, 187920) town &lt;- c(&quot;中正&quot;, &quot;大同&quot;, &quot;中山&quot;, &quot;松山&quot;, &quot;大安&quot;, &quot;萬華&quot;) area &lt;- c(7.6071, 5.6815, 13.6821, 9.2878, 11.3614, 8.8522) 4.1.1.2 合併等長vector為dataframe df &lt;- data.frame(town, population, area) df$density = df$population / df$area str(df) ## &#39;data.frame&#39;: 6 obs. of 4 variables: ## $ town : chr &quot;中正&quot; &quot;大同&quot; &quot;中山&quot; &quot;松山&quot; ... ## $ population: num 158228 126687 228075 204903 308383 ... ## $ area : num 7.61 5.68 13.68 9.29 11.36 ... ## $ density : num 20800 22298 16670 22062 27143 ... summary(df) ## town population area density ## Length:6 Min. :126687 Min. : 5.681 Min. :16670 ## Class :character 1st Qu.:165651 1st Qu.: 7.918 1st Qu.:20907 ## Mode :character Median :196412 Median : 9.070 Median :21645 ## Mean :202366 Mean : 9.412 Mean :21700 ## 3rd Qu.:222282 3rd Qu.:10.843 3rd Qu.:22239 ## Max. :308383 Max. :13.682 Max. :27143 # View(df) 4.1.1.3 存放台灣貿易各國進出口量 運用台灣出口進口資料 台灣出口進口貿易資料查詢 country &lt;- c(&quot;CN&quot;, &quot;US&quot;, &quot;JP&quot;, &quot;HK&quot;, &quot;KR&quot;, &quot;SG&quot;, &quot;DE&quot;, &quot;MY&quot;, &quot;VN&quot;, &quot;PH&quot;, &quot;TH&quot;, &quot;AU&quot;, &quot;NL&quot;, &quot;SA&quot;, &quot;ID&quot;, &quot;GB&quot;, &quot;IN&quot;, &quot;FR&quot;, &quot;IT&quot;, &quot;AE&quot;) import &lt;- c(26.142, 12.008, 7.032, 13.646, 4.589, 5.768, 2.131, 2.802, 3.428, 3.019, 1.976, 1.118, 1.624, 0.449, 0.983, 1.302, 1.027, 0.553, 0.670, 0.455) export &lt;- c(22.987, 12.204, 11.837, 7.739, 5.381, 4.610, 2.866, 2.784, 2.414, 2.092, 1.839, 1.788, 1.665, 1.409, 1.391, 1.075, 0.974, 0.899, 0.800, 0.728) 4.1.1.4 合併vector為data.frame 這時候我們若以str(df)觀察該df的結構會發現，文字型態的資料被轉為Factors，這是我們所不樂見的。過去統計通常會把文字型態當成類別變數，於是用Factors作為資料型態，但資料科學中經常要處理大量的文字資料，此時，我們可以把read.csv的一個參數stringsAsFactors設為FALSE，意味著預設不要將文字的資料轉為Factor而是直接以文字變項來處理。* stringsAsFactors = FALSE也是read.csv()的參數（parameter、argument）。因為一般讀檔會預設把文字讀為類別變項也就是Factor，但資料分析經常要處理文字資料而不是類別變項，所以會希望預設不要把文字讀取為類別變項，因此要設定stringsAsFactors = FALSE。 為了避免每次都要打這串參數，可以把它設定為全域參數，可以在程式一開始時便加上options(stringsAsFactors = FASLE)，意味著底下所有的函式如果有stringsAsFactors這個參數，一律自動設為FALSE。 df &lt;- data.frame(country, import, export) str(df) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ country: chr &quot;CN&quot; &quot;US&quot; &quot;JP&quot; &quot;HK&quot; ... ## $ import : num 26.14 12.01 7.03 13.65 4.59 ... ## $ export : num 22.99 12.2 11.84 7.74 5.38 ... df &lt;- data.frame(country, import, export, stringsAsFactors = FALSE) str(df) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ country: chr &quot;CN&quot; &quot;US&quot; &quot;JP&quot; &quot;HK&quot; ... ## $ import : num 26.14 12.01 7.03 13.65 4.59 ... ## $ export : num 22.99 12.2 11.84 7.74 5.38 ... 甚至也可以建立一個新的、空的data.frame。 df.test就R的用法就是一個變數，並不是df和test各自是一個變數。 df.test &lt;- data.frame() 4.1.2 觀察dataframe View(df) 用RStudio所提供的GUI直接觀看變數 head(df) 取前面六筆資料（也就是六列的資料來概觀該資料） class(df) str(df) summary(df) # View(df) head(df) # get first part of the data.frame ## country import export ## 1 CN 26.142 22.987 ## 2 US 12.008 12.204 ## 3 JP 7.032 11.837 ## 4 HK 13.646 7.739 ## 5 KR 4.589 5.381 ## 6 SG 5.768 4.610 class(df) ## [1] &quot;data.frame&quot; str(df) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ country: chr &quot;CN&quot; &quot;US&quot; &quot;JP&quot; &quot;HK&quot; ... ## $ import : num 26.14 12.01 7.03 13.65 4.59 ... ## $ export : num 22.99 12.2 11.84 7.74 5.38 ... summary(df) ## country import export ## Length:20 Min. : 0.449 Min. : 0.728 ## Class :character 1st Qu.: 1.016 1st Qu.: 1.312 ## Mode :character Median : 2.054 Median : 1.966 ## Mean : 4.536 Mean : 4.374 ## 3rd Qu.: 4.884 3rd Qu.: 4.803 ## Max. :26.142 Max. :22.987 # look up help help(summary) ?summary 4.1.2.1 觀察資料維度 dim(df) ## [1] 20 3 ncol(df) ## [1] 3 nrow(df) ## [1] 20 length(df) ## [1] 3 4.1.3 操作dataframe 4.1.3.1 取出一個變項 names(df) 列出變數名稱 df$發生.現.地點 顯示該變數內容 df$發生時段 顯示該變數內容 length(df$發生時段) 顯示該變數的長度（相當於有幾個） names(df) ## [1] &quot;country&quot; &quot;import&quot; &quot;export&quot; head(df$發生.現.地點) ## NULL head(df$發生時段) ## NULL length(df$發生時段) ## [1] 0 summary(df) ## country import export ## Length:20 Min. : 0.449 Min. : 0.728 ## Class :character 1st Qu.: 1.016 1st Qu.: 1.312 ## Mode :character Median : 2.054 Median : 1.966 ## Mean : 4.536 Mean : 4.374 ## 3rd Qu.: 4.884 3rd Qu.: 4.803 ## Max. :26.142 Max. :22.987 4.1.3.2 (mutate)透過運算產生新變數 這裡容易犯錯的是，要記得跟程式講說你要加總或四則運算的是哪個df的variable。 從下面的這個操作中，該data.frame會產生一個新的變數sub，這就相當於Excel中的某一行減去某一行，然後把資料放在新的一行。 df$sub &lt;- df$import - df$export 4.1.3.3 (filter)篩選資料、選取變數 注意，要告訴程式import和export是哪個data.frame的。 df[,]為存取df中某個區段的數值或某個數值的方法。因此df[1, 1]會取出第一行第一列，也就是第一筆資料的第一個vector。df[2, 3]則會取出第二筆資料的第三個variable。 下面的例子nrow(df)為1894，有1894筆資料，所以自然df\\(import與df\\)export的長度都是1894。因此，比較這兩個變數的大小會得到一個長度為1894的boolean (logical) variable。因此把這個長度為1894、充滿TRUE和FALSE的logical vector丟進df的row之處，因為取自df，大小判斷式結果的長度自然和原本的df的列數相同。因此當這個TRUE/FALSE被丟在df的列之處，便會篩選出import大於p.xport的數值。 原本的df有五個variable，而上述的操作是篩選資料，所以被篩選的是列，因此行的數量、名稱都不會變。因此，我篩選完後，直接存取這個被篩選過的data.frame的country variable，自然是可以的。 df ## country import export sub ## 1 CN 26.142 22.987 3.155 ## 2 US 12.008 12.204 -0.196 ## 3 JP 7.032 11.837 -4.805 ## 4 HK 13.646 7.739 5.907 ## 5 KR 4.589 5.381 -0.792 ## 6 SG 5.768 4.610 1.158 ## 7 DE 2.131 2.866 -0.735 ## 8 MY 2.802 2.784 0.018 ## 9 VN 3.428 2.414 1.014 ## 10 PH 3.019 2.092 0.927 ## 11 TH 1.976 1.839 0.137 ## 12 AU 1.118 1.788 -0.670 ## 13 NL 1.624 1.665 -0.041 ## 14 SA 0.449 1.409 -0.960 ## 15 ID 0.983 1.391 -0.408 ## 16 GB 1.302 1.075 0.227 ## 17 IN 1.027 0.974 0.053 ## 18 FR 0.553 0.899 -0.346 ## 19 IT 0.670 0.800 -0.130 ## 20 AE 0.455 0.728 -0.273 names(df) ## [1] &quot;country&quot; &quot;import&quot; &quot;export&quot; &quot;sub&quot; nrow(df) ## [1] 20 # filter row data by column value df[df$import &gt; df$export,] ## country import export sub ## 1 CN 26.142 22.987 3.155 ## 4 HK 13.646 7.739 5.907 ## 6 SG 5.768 4.610 1.158 ## 8 MY 2.802 2.784 0.018 ## 9 VN 3.428 2.414 1.014 ## 10 PH 3.019 2.092 0.927 ## 11 TH 1.976 1.839 0.137 ## 16 GB 1.302 1.075 0.227 ## 17 IN 1.027 0.974 0.053 df[df$import &gt; df$export,]$country ## [1] &quot;CN&quot; &quot;HK&quot; &quot;SG&quot; &quot;MY&quot; &quot;VN&quot; &quot;PH&quot; &quot;TH&quot; &quot;GB&quot; &quot;IN&quot; df[df$import &gt; df$export,1] ## [1] &quot;CN&quot; &quot;HK&quot; &quot;SG&quot; &quot;MY&quot; &quot;VN&quot; &quot;PH&quot; &quot;TH&quot; &quot;GB&quot; &quot;IN&quot; # 1 row == a data.frame with only one data entry class(df[df$import &gt; df$export,1]) ## [1] &quot;character&quot; class(df[,1]) # character vector ## [1] &quot;character&quot; class(df[1,]) # data.frame ## [1] &quot;data.frame&quot; class(unlist(df[1, -1])) # filter the 1st row and select all columns except 1 ## [1] &quot;numeric&quot; 4.1.3.4 (arrange) 按某個變數排序 df.sorted &lt;- df[order(df$import),]會使得整個df照import的大小排序重新做排列。因為order(df$import)會把資料照指定順序排列後的位置傳回來，所以把他丟給df的列的位置，便會使得df的資料照指定的順序排列。 預設是由小到大，加上decreasing = T這個參數後變成由大而小。 # sort rows by df$import column df.sorted &lt;- df[order(df$import),] # View(df.sorted) # sort rows in decreasing order df.sorted &lt;- df[order(df$import, decreasing = T),] # add - to column in order() can sort in decreasing order df.sorted &lt;- df[order(-df$import),] head(df.sorted) ## country import export sub ## 1 CN 26.142 22.987 3.155 ## 4 HK 13.646 7.739 5.907 ## 2 US 12.008 12.204 -0.196 ## 3 JP 7.032 11.837 -4.805 ## 6 SG 5.768 4.610 1.158 ## 5 KR 4.589 5.381 -0.792 4.2 簡易繪圖 graphics::plot()為會預載入R的繪圖套件，如果希望繪圖的同時加上回歸線和資料點標籤的話，必須要三行一起執行。 # plot(df) # raise error, 1st column is a character vector plot(df[, 2:3]) plot(df[1:10, 2:3]) text(import, export, labels=country, cex= 0.5, pos=3) lines(1:25, 1:25, col=&#39;red&#39;) ?plot ## Help on topic &#39;plot&#39; was found in the following packages: ## ## Package Library ## graphics /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library ## base /Library/Frameworks/R.framework/Resources/library ## ## ## Using the first match ... 4.3 基本操作：使用dplyr library(dplyr) df &lt;- data.frame(country, import, export, stringsAsFactors = F) df &lt;- mutate(df, sub = import - export) filter(df, import &gt; export) ## country import export sub ## 1 CN 26.142 22.987 3.155 ## 2 HK 13.646 7.739 5.907 ## 3 SG 5.768 4.610 1.158 ## 4 MY 2.802 2.784 0.018 ## 5 VN 3.428 2.414 1.014 ## 6 PH 3.019 2.092 0.927 ## 7 TH 1.976 1.839 0.137 ## 8 GB 1.302 1.075 0.227 ## 9 IN 1.027 0.974 0.053 select(df, c(1, 3)) ## country export ## 1 CN 22.987 ## 2 US 12.204 ## 3 JP 11.837 ## 4 HK 7.739 ## 5 KR 5.381 ## 6 SG 4.610 ## 7 DE 2.866 ## 8 MY 2.784 ## 9 VN 2.414 ## 10 PH 2.092 ## 11 TH 1.839 ## 12 AU 1.788 ## 13 NL 1.665 ## 14 SA 1.409 ## 15 ID 1.391 ## 16 GB 1.075 ## 17 IN 0.974 ## 18 FR 0.899 ## 19 IT 0.800 ## 20 AE 0.728 message(df$country) print(df$country) ## [1] &quot;CN&quot; &quot;US&quot; &quot;JP&quot; &quot;HK&quot; &quot;KR&quot; &quot;SG&quot; &quot;DE&quot; &quot;MY&quot; &quot;VN&quot; &quot;PH&quot; &quot;TH&quot; &quot;AU&quot; &quot;NL&quot; &quot;SA&quot; &quot;ID&quot; ## [16] &quot;GB&quot; &quot;IN&quot; &quot;FR&quot; &quot;IT&quot; &quot;AE&quot; 4.4 tibble, data_frame, data.frame 警告： \"data_frame()\" was deprecated in tibble 1.1.0. Please use \"tibble()\" instead. df &lt;- data.frame(a=1:2, b=3:4, c=5:6) class(df) ## [1] &quot;data.frame&quot; df &lt;- data_frame(a=1:2, b=3:4, c=5:6) class(df) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; df &lt;- tibble(a=1:2, b=3:4, c=5:6) class(df) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 4.5 Database - SQLite 4.6 Paid Maternity Leave 本案例將使用R重新製作華盛頓郵報2016年8月13日的一篇報導，該報導探討了美國婦女產假支薪情況。案例中將應用data.frame和基本的繪圖與資料摘要方法。 原始新聞來源：The world is getting better at paid maternity leave. The U.S. is not. - The Washington Post。該篇報導提及，美國因為目前的政策不保障帶薪產假，許多女性感到必須在工作和照顧家庭之間做出選擇，這種性別不平等破壞了她們在工作機會上的平等機會。同時，世界各地的婦女待遇正在逐漸改善。至少190個國家對嬰兒的母親規定了某種形式的帶薪假期，產假待遇在56個國家有所提高。專家表示，現在美國城市和州正通過不同形式的帶薪家庭假法案，這顯示美國雇主正在展示有競爭力的福利不會影響員工表現。特別是科技公司，如Twitter、Facebook和Google等，處於提供員工帶薪產假福利的前沿，美國可能有望追趕其他國家。 本案例主要呈現核心的視覺化概念，可以在Review Paid Maternity by dplyr找到更詳盡的案例說明與解析。 4.6.1 Reading .xlsx by readxl package readxl也包含在tidyverse的套件集中，所以應該已經在前次安裝過，不用特別安裝。 但readxl不會隨著tidyverse套件被載入R的執行環境，所以如果要用readxl()來讀取excel檔的話，需要用library(readxl)將其載入。 # Import readxl package library(readxl) 這段程式碼使用read_excel()函式從data資料夾中的WORLD-MACHE_Gender_6.8.15.xls檔案中的Sheet1工作表讀取資料。其中col_names=T為該函式的參數，表示第一列為欄位名稱。讀取後的資料會被Assign給變數df。 # Use read_excel() to convert excel sheet to data.frame df &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) 4.6.2 Previewing data by View(), class(), dim(), str(), summary() and names() # View(df) class(df) # [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; dim(df) ## [1] 197 156 # Show names of variables (vectors, columns) by names() names(df) ## [1] &quot;country&quot; &quot;iso2&quot; &quot;iso3&quot; ## [4] &quot;region&quot; &quot;wb_econ&quot; &quot;matleave_95&quot; ## [7] &quot;matleave_96&quot; &quot;matleave_97&quot; &quot;matleave_98&quot; ## [10] &quot;matleave_99&quot; &quot;matleave_00&quot; &quot;matleave_01&quot; ## [13] &quot;matleave_02&quot; &quot;matleave_03&quot; &quot;matleave_04&quot; ## [16] &quot;matleave_05&quot; &quot;matleave_06&quot; &quot;matleave_07&quot; ## [19] &quot;matleave_08&quot; &quot;matleave_09&quot; &quot;matleave_10&quot; ## [22] &quot;matleave_11&quot; &quot;matleave_12&quot; &quot;matleave_13&quot; ## [25] &quot;matleave_wrr_95&quot; &quot;matleave_wrr_96&quot; &quot;matleave_wrr_97&quot; ## [28] &quot;matleave_wrr_98&quot; &quot;matleave_wrr_99&quot; &quot;matleave_wrr_00&quot; ## [31] &quot;matleave_wrr_01&quot; &quot;matleave_wrr_02&quot; &quot;matleave_wrr_03&quot; ## [34] &quot;matleave_wrr_04&quot; &quot;matleave_wrr_05&quot; &quot;matleave_wrr_06&quot; ## [37] &quot;matleave_wrr_07&quot; &quot;matleave_wrr_08&quot; &quot;matleave_wrr_09&quot; ## [40] &quot;matleave_wrr_10&quot; &quot;matleave_wrr_11&quot; &quot;matleave_wrr_12&quot; ## [43] &quot;matleave_wrr_13&quot; &quot;bf_dur_95&quot; &quot;bf_dur_96&quot; ## [46] &quot;bf_dur_97&quot; &quot;bf_dur_98&quot; &quot;bf_dur_99&quot; ## [49] &quot;bf_dur_00&quot; &quot;bf_dur_01&quot; &quot;bf_dur_02&quot; ## [52] &quot;bf_dur_03&quot; &quot;bf_dur_04&quot; &quot;bf_dur_05&quot; ## [55] &quot;bf_dur_06&quot; &quot;bf_dur_07&quot; &quot;bf_dur_08&quot; ## [58] &quot;bf_dur_09&quot; &quot;bf_dur_10&quot; &quot;bf_dur_11&quot; ## [61] &quot;bf_dur_12&quot; &quot;bf_dur_13&quot; &quot;mat_bfeed_6mon_95&quot; ## [64] &quot;mat_bfeed_6mon_96&quot; &quot;mat_bfeed_6mon_97&quot; &quot;mat_bfeed_6mon_98&quot; ## [67] &quot;mat_bfeed_6mon_99&quot; &quot;mat_bfeed_6mon_00&quot; &quot;mat_bfeed_6mon_01&quot; ## [70] &quot;mat_bfeed_6mon_02&quot; &quot;mat_bfeed_6mon_03&quot; &quot;mat_bfeed_6mon_04&quot; ## [73] &quot;mat_bfeed_6mon_05&quot; &quot;mat_bfeed_6mon_06&quot; &quot;mat_bfeed_6mon_07&quot; ## [76] &quot;mat_bfeed_6mon_08&quot; &quot;mat_bfeed_6mon_09&quot; &quot;mat_bfeed_6mon_10&quot; ## [79] &quot;mat_bfeed_6mon_11&quot; &quot;mat_bfeed_6mon_12&quot; &quot;mat_bfeed_6mon_13&quot; ## [82] &quot;minage_fem_leg_95&quot; &quot;minage_fem_leg_96&quot; &quot;minage_fem_leg_97&quot; ## [85] &quot;minage_fem_leg_98&quot; &quot;minage_fem_leg_99&quot; &quot;minage_fem_leg_00&quot; ## [88] &quot;minage_fem_leg_01&quot; &quot;minage_fem_leg_02&quot; &quot;minage_fem_leg_03&quot; ## [91] &quot;minage_fem_leg_04&quot; &quot;minage_fem_leg_05&quot; &quot;minage_fem_leg_06&quot; ## [94] &quot;minage_fem_leg_07&quot; &quot;minage_fem_leg_08&quot; &quot;minage_fem_leg_09&quot; ## [97] &quot;minage_fem_leg_10&quot; &quot;minage_fem_leg_11&quot; &quot;minage_fem_leg_12&quot; ## [100] &quot;legal_diff_leg_95&quot; &quot;legal_diff_leg_96&quot; &quot;legal_diff_leg_97&quot; ## [103] &quot;legal_diff_leg_98&quot; &quot;legal_diff_leg_99&quot; &quot;legal_diff_leg_00&quot; ## [106] &quot;legal_diff_leg_01&quot; &quot;legal_diff_leg_02&quot; &quot;legal_diff_leg_03&quot; ## [109] &quot;legal_diff_leg_04&quot; &quot;legal_diff_leg_05&quot; &quot;legal_diff_leg_06&quot; ## [112] &quot;legal_diff_leg_07&quot; &quot;legal_diff_leg_08&quot; &quot;legal_diff_leg_09&quot; ## [115] &quot;legal_diff_leg_10&quot; &quot;legal_diff_leg_11&quot; &quot;legal_diff_leg_12&quot; ## [118] &quot;minage_fem_pc_95&quot; &quot;minage_fem_pc_96&quot; &quot;minage_fem_pc_97&quot; ## [121] &quot;minage_fem_pc_98&quot; &quot;minage_fem_pc_99&quot; &quot;minage_fem_pc_00&quot; ## [124] &quot;minage_fem_pc_01&quot; &quot;minage_fem_pc_02&quot; &quot;minage_fem_pc_03&quot; ## [127] &quot;minage_fem_pc_04&quot; &quot;minage_fem_pc_05&quot; &quot;minage_fem_pc_06&quot; ## [130] &quot;minage_fem_pc_07&quot; &quot;minage_fem_pc_08&quot; &quot;minage_fem_pc_09&quot; ## [133] &quot;minage_fem_pc_10&quot; &quot;minage_fem_pc_11&quot; &quot;minage_fem_pc_12&quot; ## [136] &quot;legal_diff_pc_95&quot; &quot;legal_diff_pc_96&quot; &quot;legal_diff_pc_97&quot; ## [139] &quot;legal_diff_pc_98&quot; &quot;legal_diff_pc_99&quot; &quot;legal_diff_pc_00&quot; ## [142] &quot;legal_diff_pc_01&quot; &quot;legal_diff_pc_02&quot; &quot;legal_diff_pc_03&quot; ## [145] &quot;legal_diff_pc_04&quot; &quot;legal_diff_pc_05&quot; &quot;legal_diff_pc_06&quot; ## [148] &quot;legal_diff_pc_07&quot; &quot;legal_diff_pc_08&quot; &quot;legal_diff_pc_09&quot; ## [151] &quot;legal_diff_pc_10&quot; &quot;legal_diff_pc_11&quot; &quot;legal_diff_pc_12&quot; ## [154] &quot;minwage_ppp_2013&quot; &quot;mw_overtime&quot; &quot;oecd&quot; 4.6.3 Select variables 由於所需要的資料為第三欄的變數iso3（為國家代碼）和第六至24欄的matleave95~matleave13共29年的資料，所以需要在df[ , ]中選出這幾欄。只要把所要取的欄以vector的型態放在df[row,col]之col的位置，便可以選出所要的欄。 # Select the 3rd and 6th to 24th columns matleave &lt;- df[ , c(3, 6:24)] # Use class(), dim(), and str() to inspect the data class(matleave) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; dim(matleave) ## [1] 197 20 str(matleave) ## tibble [197 × 20] (S3: tbl_df/tbl/data.frame) ## $ iso3 : chr [1:197] &quot;AFG&quot; &quot;ALB&quot; &quot;DZA&quot; &quot;AND&quot; ... ## $ matleave_95: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_96: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_97: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_98: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_99: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_00: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_01: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_02: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_03: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_04: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_05: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_06: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_07: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_08: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_09: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_10: num [1:197] 2 5 3 3 2 2 2 5 NA 5 ... ## $ matleave_11: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... ## $ matleave_12: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... ## $ matleave_13: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... 4.6.4 Check &amp; Replace NAs NA: Not Available v[is.na(v)] will select all NA cells 以0取代NA的資料格。避免繪圖產生錯誤 sum(is.na(matleave))的目的是檢測還有沒有NA值。如果有的話is.na()就會是TRUE，那麼加總後，如果不是0，那就代表還有NA。 # is.na() to indicate each element is NA or NOT(TRUE/FALSE) head(is.na(matleave), n=20) ## iso3 matleave_95 matleave_96 matleave_97 matleave_98 matleave_99 ## [1,] FALSE FALSE FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE FALSE ## [7,] FALSE FALSE FALSE FALSE FALSE FALSE ## [8,] FALSE FALSE FALSE FALSE FALSE FALSE ## [9,] FALSE FALSE FALSE FALSE FALSE FALSE ## [10,] FALSE FALSE FALSE FALSE FALSE FALSE ## [11,] FALSE FALSE FALSE FALSE FALSE FALSE ## [12,] FALSE FALSE FALSE FALSE FALSE FALSE ## [13,] FALSE FALSE FALSE FALSE FALSE FALSE ## [14,] FALSE FALSE FALSE FALSE FALSE FALSE ## [15,] FALSE FALSE FALSE FALSE FALSE FALSE ## [16,] FALSE FALSE FALSE FALSE FALSE FALSE ## [17,] FALSE FALSE FALSE FALSE FALSE FALSE ## [18,] FALSE FALSE FALSE FALSE FALSE FALSE ## [19,] FALSE FALSE FALSE FALSE FALSE FALSE ## [20,] FALSE FALSE FALSE FALSE FALSE FALSE ## matleave_00 matleave_01 matleave_02 matleave_03 matleave_04 matleave_05 ## [1,] FALSE FALSE FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE FALSE ## [7,] FALSE FALSE FALSE FALSE FALSE FALSE ## [8,] FALSE FALSE FALSE FALSE FALSE FALSE ## [9,] FALSE FALSE FALSE FALSE FALSE FALSE ## [10,] FALSE FALSE FALSE FALSE FALSE FALSE ## [11,] FALSE FALSE FALSE FALSE FALSE FALSE ## [12,] FALSE FALSE FALSE FALSE FALSE FALSE ## [13,] FALSE FALSE FALSE FALSE FALSE FALSE ## [14,] FALSE FALSE FALSE FALSE FALSE FALSE ## [15,] FALSE FALSE FALSE FALSE FALSE FALSE ## [16,] FALSE FALSE FALSE FALSE FALSE FALSE ## [17,] FALSE FALSE FALSE FALSE FALSE FALSE ## [18,] FALSE FALSE FALSE FALSE FALSE FALSE ## [19,] FALSE FALSE FALSE FALSE FALSE FALSE ## [20,] FALSE FALSE FALSE FALSE FALSE FALSE ## matleave_06 matleave_07 matleave_08 matleave_09 matleave_10 matleave_11 ## [1,] FALSE FALSE FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE FALSE ## [7,] FALSE FALSE FALSE FALSE FALSE FALSE ## [8,] FALSE FALSE FALSE FALSE FALSE FALSE ## [9,] FALSE FALSE FALSE FALSE TRUE FALSE ## [10,] FALSE FALSE FALSE FALSE FALSE FALSE ## [11,] FALSE FALSE FALSE FALSE FALSE FALSE ## [12,] FALSE FALSE FALSE FALSE FALSE FALSE ## [13,] FALSE FALSE FALSE FALSE FALSE FALSE ## [14,] FALSE FALSE FALSE FALSE FALSE FALSE ## [15,] FALSE FALSE FALSE FALSE FALSE FALSE ## [16,] FALSE FALSE FALSE FALSE FALSE FALSE ## [17,] FALSE FALSE FALSE FALSE FALSE FALSE ## [18,] FALSE FALSE FALSE FALSE FALSE FALSE ## [19,] FALSE FALSE FALSE FALSE FALSE FALSE ## [20,] FALSE TRUE TRUE FALSE FALSE FALSE ## matleave_12 matleave_13 ## [1,] FALSE FALSE ## [2,] FALSE FALSE ## [3,] FALSE FALSE ## [4,] FALSE FALSE ## [5,] FALSE FALSE ## [6,] FALSE FALSE ## [7,] FALSE FALSE ## [8,] FALSE FALSE ## [9,] FALSE FALSE ## [10,] FALSE FALSE ## [11,] FALSE FALSE ## [12,] FALSE FALSE ## [13,] FALSE FALSE ## [14,] FALSE FALSE ## [15,] FALSE FALSE ## [16,] FALSE FALSE ## [17,] FALSE FALSE ## [18,] FALSE FALSE ## [19,] FALSE FALSE ## [20,] FALSE FALSE # Assign 0 to those NA data matleave[is.na(matleave)] &lt;- 0 # anyNA() to check if there are still NA cells. anyNA(matleave) ## [1] FALSE # sum(is.na()) to count the number of NA sum(is.na(matleave)) ## [1] 0 4.6.5 Filtering data 4.6.5.1 Filtered by the last year value matleave[matleave$'matleave_13'==5, ]中的第一個matleave表示要篩選的資料集，中括號中的matleave$'matleave_13'==5是篩選條件，表示matleave資料集中的matleave_13變數的值等於5。中括號中的逗號後方未有欄為名稱表示保留所有欄位的資料，僅篩選出符合條件的列，並將篩選結果賦值給變數m5。 # Use logical comparison to see if the last year equals to 5 # Assign matching data to var m5 m5 &lt;- matleave[matleave$&#39;matleave_13&#39;==5, ] # nrow() to count matching data nrow(m5) ## [1] 34 # Is it possible to use length() to check the data length? # matleave$&#39;matleave_13&#39; # matleave$&#39;matleave_13&#39;==5 # length(matleave$&#39;matleave_13&#39;==5) 4.6.5.2 Filtered data by the first year value # filter rows whose &#39;matleave_95&#39; is 5, and assign to var m55 m55&lt;- m5[m5$&#39;matleave_95&#39;==5,] # filter rows whose &#39;matleave_95&#39; is not 5, and assign to var m05 m05&lt;- m5[m5$&#39;matleave_95&#39;!=5,] 4.6.6 Plotting Plotting the second rows and all columns except 1st column Question 為何要unlist()？請試著執行barplot(matleave[2, -1])這個沒有unlist()的版本，看看會有什麼錯誤訊息。資料結構有何差異呢？ 嘗試用class()或str()嘗試觀察沒有unlist()版本的資料，看看資料型態和有unlist()的會有何不同？ 4.6.6.1 Plotting one line # barplot() the second row of m55 # barplot(m55[2, ]) # raise error # barplot() the second row when neglecting the first column # barplot(m55[2, -1]) # raise error # Take a look at the data type of matleave[2, ] class(matleave[2, -1]) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(unlist(matleave[2, -1])) ## [1] &quot;numeric&quot; # unlist() to convert a single row data.frame to a vector for barplot() barplot(unlist(m55[2, -1])) Testing # View(matleave[1]) # select the 1st variable # View(matleave[ ,1]) # select the 1st column # View(matleave[1, ]) # select the 1st row class(m55[1]) # &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(m55[ ,1]) # &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(m55[1, ]) # &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(m55$iso3) # character (vector) ## [1] &quot;character&quot; 4.6.6.2 More arguments (args) 這行程式碼使用R中的barplot函數繪製一個長條圖，其中的參數說明如下： unlist(m55[2, -1]): 將m55資料集的第2行（不包括第1欄）轉換為一個向量，並作為長條圖的高度（即每個長條的高度）。 ylim=c(0, 5): 設置y軸的範圍為0到5，即長條圖的最大高度為5。 space=0: 設置相鄰兩個長條之間的距離為0，即長條緊密相連。 border=NA: 設置長條的邊框為透明，即不顯示邊框。 xaxt=\"n\": 不顯示x軸的標籤。 yaxt=\"n\": 不顯示y軸的標籤。 # barplot() the unlisted second row (neglecting the first col) barplot(unlist(m55[2, -1])) # use ?barplot to know more argument of the function. ?barplot # Add arguments ylim, space, border, and axat/yaxt one by one to barplot() barplot(unlist(m55[2, -1]), ylim=c(0, 5)) barplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0) barplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA) barplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) 4.6.6.3 Plotting multiple lines 底下可以看見每一行非常相似且一致的特徵，僅有matleave內的索引由1被列出至6。因此，最好的方法是用迴圈（for-loop）的方式將相同的程式碼，從1~6之間做六次。 # plot the first row barplot(unlist(m55[1, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) # plot the second to 6th rows barplot(unlist(m55[2, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) barplot(unlist(m55[3, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) barplot(unlist(m55[4, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) barplot(unlist(m55[5, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) barplot(unlist(m55[6, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) 4.6.6.4 for-loop to plot multiple lines 這段R語言程式碼使用for-loop來重複執行一個指定的程式區塊，將m55資料集的前六行資料分別繪製成長條圖。在這段程式碼中，變數i控制了for-loop的迭代次數，它從1到6依次取值，然後依次執行所指定的程式區塊。 一般的for-loop的結構如下：for (variable in sequence) {# code block to be executed}。其中，變數variable是用來控制for-loop的迭代次數的，它會從序列sequence中逐一取出元素，並將其賦值給變數variable，然後執行大括號{...}中所指定的程式區塊。 # use for loop and use i as index to barplot multiple subgraphs for(i in 1:6){ barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) } 4.6.6.5 Subplots 在R語言中，par（parameter的縮寫）是一個用於設置繪圖參數的函數，通過它可以控制繪圖的外觀、尺寸、排列等各方面，以便更好地展示數據和分析結果。par函數可以用來設置以下參數： mfrow：設置畫布的分割，即將畫布分為多少行和多少列。 mai：設置畫布的邊緣大小，包括上下左右四個邊緣的大小。 cex：設置字體大小的縮放比例。 col：設置線條、點和字體的顏色。 pch：設置散點圖中點的形狀。 lty：設置線條的類型。 在這段程式碼中，par函數被用來設置畫布的分割和邊緣大小，具體來說，par(mfrow=c(3,2), mai= c(0.2, 0.2, 0.2, 0.2))表示將畫布分為3行2列的子圖，並設置邊緣大小為0.2，包括上下左右四個邊緣。這樣可以方便地在同一張畫布上顯示多個圖形，並控制它們之間的排列和間距。 # use ?par to get more plotting parameters ?par # use par() to set-up the layout of subgraphs # use the parameter main=c(0.2, 0.2, 0.2, 0.2) to thrink the padding of figures. par(mfrow=c(3,2), mai= c(0.2, 0.2, 0.2, 0.2)) for(i in 1:6){ barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) } # plot more rows to see what happens par(mfrow=c(3,2), mai= c(0.2, 0.2, 0.2, 0.2)) for(i in 1:10){ barplot(unlist(m55[i, -1]), ylim=c(0, 5), space=0, border=NA, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;) } # plot all subplots in a figure # nrow() to check number of row of m55. nrow(m55) ## [1] 18 # use par() to set-up plotting parameters. par(mfrow=c(4, 6), mai= c(0.2, 0.2, 0.2, 0.2)) # use for-loop to plot all graph as subgraph for (i in 1:nrow(m55)){ barplot(unlist(m55[i, -1]), border=NA, space=0, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, ylim = c(0,5)) } par(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2)) for (i in 1:nrow(m55)){ barplot(unlist(m55[i, -1]), border=NA, space=0,xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, ylim = c(0,5)) title(m55[i,1], line = -4, cex.main=3) } 4.6.7 Practice. Plotting more # plotting matleave_95 != 5 but matleve_13 == 5 # plotting for matleave_13 == 4 4.6.8 Practice. Selecting and filtering by dplyr I df &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) # select columns by index # matleave &lt;- df[ , c(3, 6:24)] # select all NA cells and assign 0 to them # matleave[is.na(matleave)] &lt;- 0 # filter rows by condition # m5 &lt;- matleave[matleave$&#39;matleave_13&#39; == 5, ] # filter rows by condition # m55&lt;- m5[m5$&#39;matleave_95&#39; == 5,] # plot par(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2)) for (i in c(1:nrow(m55))){ barplot(unlist(m55[i,-1]), border=NA, space=0,xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, ylim = c(0,5)) title(m55[i,1], line = -4, cex.main=3) } 4.6.9 (More) Clean version # readxl::read_excel() to import the xls file df &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) # select iso3, and matleave columns by index matleave &lt;- df[ , c(3, 6:24)] # str() to inspect the data structure of str(matleave) ## tibble [197 × 20] (S3: tbl_df/tbl/data.frame) ## $ iso3 : chr [1:197] &quot;AFG&quot; &quot;ALB&quot; &quot;DZA&quot; &quot;AND&quot; ... ## $ matleave_95: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_96: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_97: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_98: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_99: num [1:197] 2 5 3 2 2 2 2 3 1 5 ... ## $ matleave_00: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_01: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_02: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_03: num [1:197] 2 5 3 3 2 2 2 3 1 5 ... ## $ matleave_04: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_05: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_06: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_07: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_08: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_09: num [1:197] 2 5 3 3 2 2 2 5 1 5 ... ## $ matleave_10: num [1:197] 2 5 3 3 2 2 2 5 NA 5 ... ## $ matleave_11: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... ## $ matleave_12: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... ## $ matleave_13: num [1:197] 2 5 3 3 2 2 2 5 3 5 ... # select all NA cells and assign 0 to them matleave[is.na(matleave)] &lt;- 0 # filter rows by condition m5 &lt;- matleave[matleave$&#39;matleave_13&#39; == 5, ] # filter rows by condition m55&lt;- m5[m5$&#39;matleave_95&#39; == 5,] # plot par(mfrow=c(4,6), mai= c(0.2, 0.2, 0.2, 0.2)) for (i in c(1:nrow(m55))){ barplot(unlist(m55[i,-1]), border=NA, space=0,xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, ylim = c(0,5)) title(m55[i,1], line = -4, cex.main=3) } 4.6.10 (More) The fittest version to compute staySame # staySame version # staySame &lt;- apply(m5[,2:20], 1, function(x) length(unique(x[!is.na(x)]))) # m55 &lt;- m5[staySame, ] # m50 &lt;- m5[!staySame, ] "],["counting-and-cross-tabulation.html", "Chapter 5 Counting and Cross-tabulation 5.1 Taipei Residential Burglary 5.2 Read online files 5.3 Counting Review 5.4 Pivoting long-wide tables 5.5 Residuals analysis", " Chapter 5 Counting and Cross-tabulation 交叉分析是一種對兩個或多個變數進行聯合分析的方法，通常用於研究不同類別或組別之間的關係和差異。交叉分析可以幫助我們發現變數之間的相互作用，以及不同類別或組別之間的異同點，進而進行更深入的分析和解釋。 在交叉分析中，通常會使用交叉表（cross tabulation）或稱為列聯表（contingency table）來對變數進行分析。交叉表是一種二維資料表格，其中一個變數作為行標籤，另一個變數作為列標籤，每個資料格中則表示兩個變數的交叉次數或百分比。交叉表可以幫助我們從不同角度瞭解變數之間的關係和差異，例如： 發現變數之間的相關性：可以通過交叉表計算兩個變數之間的相關係數或卡方檢定值，以評估它們之間的相關性程度。 比較不同類別或組別之間的差異：可以通過交叉表比較不同類別或組別之間的差異，例如不同性別、年齡、教育程度、地區等對某一變數的影響。 發現變數之間的交互作用：可以通過交叉表比較不同類別或組別之間的差異，並分析它們之間的交互作用，以進一步瞭解變數之間的關係和影響。 5.1 Taipei Residential Burglary 觀察值、點位資料：公部門所發布的開放資料通常會根據某些類別進行統計，例如年齡、性別、教育程度、地區等等，只有少部分的資料會用觀察值（Observation）的方式來記錄，也就是每一個案例紀錄一筆資料。例如疫情一開始人數還少的時候，會逐一記錄每個個案；地理資訊系統上面記錄某些機構或某些特定地點的時候也是點位資料；或在觀察輿情時，每筆發言或留言都是一筆觀察值。「臺北市住宅竊盜點位資訊」就是逐案紀錄的點位資料。而以下的例子也是點位資料，主要為主要為噪音、竊盜、交通事故等相關點位資料。 臺北市街頭隨機強盜案件點位資訊、 臺北市街頭隨機搶奪案件點位資訊、 臺北市汽車竊盜點位資訊、 臺北市機車竊盜點位資訊、 臺北市自行車竊盜點位資訊、 臺北市道路交通事故斑點圖、 臺北市娛樂營業場所噪音告發案件點位資訊、 臺北市非營業用卡拉OK噪音告發案件點位資訊、 臺北市營建工程噪音告發案件點位資訊等， 5.1.1 讀取檔案 規劃比較完善的開放資料平台會提供API給程式設計者存取，例如臺北資料大平台或內政部開放資料平台。但我們這邊用下載CSV（Common Separated Value）檔的方式來讀取這筆資料，以理解CSV這種檔案型態如何儲存資料。首先要至臺北資料大平台上查詢「住宅竊盜」，可以找到臺北市住宅竊盜點位資訊。將該CSV檔下載至個人本機端，置入data 資料夾中，便可以用read.csv()讀取該檔案。或可用tidyverse系列套件中的readr::read_csv()來直接讀取該網址所指到的檔案。 我習慣在Console視窗中用??read_csv()查詢到這些函式的用法。 read.csv() to read csv and convert it to a data.frame readr::read_csv() to read csv or read a csv by an url 如果知道這個套件是readr的話，也可以到右下方的工作區塊找到「Packages」工作視窗，裡面有列出現在載入的所有的套件，也有套件中的所有函式。偶而看一看會發現一些自己平常忽略的好用工具。 library(knitr) library(kableExtra) library(tidyverse) df &lt;- read.csv(&quot;data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv&quot;) head(df) ## 編號 案類 發生日期 發生時段 發生地點 ## 1 1 住宅竊盜 1030623 08~10 臺北市中正區廈門街91~120號 ## 2 2 住宅竊盜 1040101 00~02 臺北市文山區萬美里萬寧街1~30號 ## 3 3 住宅竊盜 1040101 00~02 臺北市信義區富台里忠孝東路5段295巷6弄1~30號 ## 4 4 住宅竊盜 1040101 06~08 臺北市中山區新生北路1段91~120號 ## 5 5 住宅竊盜 1040101 10~12 臺北市文山區明興里興隆路4段1~30號 ## 6 6 住宅竊盜 1040102 00~02 臺北市士林區天福里1鄰忠誠路2段130巷1~30號 用read_csv()來讀取。除了 base套件的read.csv()外，也可使用readr套件的read_csv()函式來讀取，該套件屬於tidyverse套件系的其中一個套件，如果已經有用install.packages(\"tidyverse\")安裝過，只要用library(tidyverse)就可以使用read_csv()函式。在此鼓勵各位使用tidyverse系列套件。普遍來說，read_csv() 的功能和效果都會比read.csv()好，該函式還會自動猜測每個變數的變數型態並直接進行轉換（尤其是有時間欄位的時候，會非常方便）。 萬一遇到中文檔案會有讀檔編碼問題時，有可能該檔案是用big5來儲存的，可以在read_csv()中設定locale來指定讀取的編碼方法。如read_csv(url, locale = locale(encoding = \"Big5\")) z library(readr) df &lt;- read_csv(&quot;data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv&quot;) # df &lt;- read_csv(&quot;data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv&quot;, locale = locale(encoding = &quot;Big5&quot;)) head(df) ## # A tibble: 6 × 5 ## 編號 案類 發生日期 發生時段 發生地點 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 住宅竊盜 1030623 08~10 臺北市中正區廈門街91~120號 ## 2 2 住宅竊盜 1040101 00~02 臺北市文山區萬美里萬寧街1~30號 ## 3 3 住宅竊盜 1040101 00~02 臺北市信義區富台里忠孝東路5段295巷6弄1~30號 ## 4 4 住宅竊盜 1040101 06~08 臺北市中山區新生北路1段91~120號 ## 5 5 住宅竊盜 1040101 10~12 臺北市文山區明興里興隆路4段1~30號 ## 6 6 住宅竊盜 1040102 00~02 臺北市士林區天福里1鄰忠誠路2段130巷1~30號 5.1.1.1 觀察變數 names(df) 列出所有變數名稱 df$發生地點 顯示該變數內容 df$發生時段 顯示該變數內容 length(df$發生時段) 顯示該變數的長度（相當於有幾個） 5.1.2 萃取所需新變項 該data.frame包含編號、案類、發生日期、發生時段、發生地點五個變項。其中比較有意義的應該是發生日期、發生時段和發生地點。然而，發生地點幾乎是完整地址，除非要繪製發生的地圖點位地圖，才會需要近乎完整的地址。假設我們的目標是抽取出台北市的「行政區」，發生地點的格式還蠻一致的如「臺北市中正區廈門街91~120號」。因此，我們只要抽出發生地點的第4至6個字即可。 從一個字串中抽取出第n個字到第m個字，要用substr()或stringr套件的str_sub()。可以用?substr或?str_sub查詢help中的相關用法。在此 我將中文變數現在時間的資料指給一個新的英文變項time。 從變數發生地點，用substr()取出行政區（region） 或用stringr::str_sub() ?substr查詢其用法和意義。相當於getting sub string since x to y。 # Get substring of var &quot;發生時段&quot; and assign to a new time var df$time &lt;- df$發生時段 # Get substring of var &quot;發生地點&quot; and assign to a new region var df$region &lt;- substr(df$發生地點, 4, 5) head(df) ## # A tibble: 6 × 7 ## 編號 案類 發生日期 發生時段 發生地點 time region ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 住宅竊盜 1030623 08~10 臺北市中正區廈門街91~120號 08~10 中正 ## 2 2 住宅竊盜 1040101 00~02 臺北市文山區萬美里萬寧街1~30號 00~02 文山 ## 3 3 住宅竊盜 1040101 00~02 臺北市信義區富台里忠孝東路5段29… 00~02 信義 ## 4 4 住宅竊盜 1040101 06~08 臺北市中山區新生北路1段91~120號 06~08 中山 ## 5 5 住宅竊盜 1040101 10~12 臺北市文山區明興里興隆路4段1~30… 10~12 文山 ## 6 6 住宅竊盜 1040102 00~02 臺北市士林區天福里1鄰忠誠路2段1… 00~02 士林 5.1.3 使用table()計數 清理完資料後，我們要回答的第一個數據問題通常是「那XXX的案例有幾個？」例如：大安區有多少竊盜案？10~12這個時段有多少案例。 table()函式可以對Vector中的值進行計數（Counting）。table(df$time) 相當於去計數不同的時間區間出現多少起案例；table(df$region) 相當於去計數不同地區各出現多少起案例。 提示：可以用class(tb_1) 觀察用table() 計數後所產生的資料型態（table）。 ## table # counting the frequency of region variable (table(df$region)) ## ## 中山 中正 信義 內湖 北投 南港 士林 大同 大安 文山 松山 萬華 ## 438 263 214 303 318 181 373 172 311 204 220 350 # counting the frequency of time variable (tb_1 &lt;- table(df$time)) ## ## 00~02 02~04 03~05 04~06 05~07 06~08 08~10 09~11 10~12 11~03 11~13 12~14 12~15 ## 272 214 8 156 23 191 305 6 338 1 26 338 2 ## 14~16 15~17 15~18 16~18 17~19 18~20 18~21 19~21 20~22 21~23 21~24 22~24 23~01 ## 342 3 1 246 21 314 1 4 303 5 1 206 20 class(tb_1) ## [1] &quot;table&quot; 5.1.4 依變數值篩選資料 該項竊盜案資料整理時經常不慎用不同的時間區間來標記，有時候也會不小心把新北市的資料給那進來，所以需要做資料篩選。從各個時間區間的竊盜案出現次數來觀察，有少數的案件出現在奇數的時間區間如09~11或12~15等等需要篩除；從各個行政區的竊盜案出現次數來觀察，確實都是台北市的竊盜案。 接下來要用base套件的R，根據某個變數值（例如上述的時間）來篩出符合條件的資料，或者篩去不符合條件的資料。其語法是要在df[ , ]逗號前加上篩選的條件，也就是對資料列進行篩選，篩出或篩除都是以整列為單位。在此的條件是df$time在00~02、02~04、…之間；或者是df$time不在03~05、05~07、…之間。表示法分別如下： df$time %in% c(&quot;00~02&quot;, &quot;02~04&quot;, &quot;04~6&quot;,...) !df$time %in% c(&quot;03~05&quot;, &quot;05~07&quot;, ...) %in% 表示的是左方df$time的值是否是右方Vector中的其中一個 如果要表示不包含，就在df%time加一個NOT，也就是!。 依照各組時間的案例個數統計後，篩除資料未足100的時間區間如下，最後再用table(df$time) 計算一次，發現每個時段都兩三、百個案例，且涵蓋整日的時間。清理後沒有重疊的時間區間，做類別資料分析會比較準確。 # filter out irrelevant timestamp df &lt;- df[!df$time %in% c(&quot;03~05&quot;, &quot;05~07&quot;, &quot;09~11&quot;, &quot;11~13&quot;, &quot;11~03&quot;, &quot;12~15&quot;, &quot;15~17&quot;, &quot;15~18&quot;, &quot;17~19&quot;, &quot;18~21&quot;, &quot;19~21&quot;, &quot;21~23&quot;, &quot;21~24&quot;, &quot;23~01&quot;), ] table(df$time) ## ## 00~02 02~04 04~06 06~08 08~10 10~12 12~14 14~16 16~18 18~20 20~22 22~24 ## 272 214 156 191 305 338 338 342 246 314 303 206 # filter out irrelevant region(area) # df &lt;- df[!df$region %in% c(&quot;三重&quot;, &quot;中和&quot;, &quot;淡水&quot;, &quot;板橋&quot;), ] 5.1.5 做雙變數樞紐分析：table() 類別變項分析通常是要考驗兩個變項間的關係，從上述的計數中，我可以看見不同行政區或者不同時間的竊盜案數量，但我進一步想知道，那不同行政區的竊盜案常發生時間是否不同？這時後就要做時間和行政區的交叉分析。我們同樣可以用table()和tapply()來做兩個變項的交叉分析，寫法如下。 用table()來交叉分析的結果如下，所得到的結果之變數型態仍是table型態。 # Tabulating time and region variables (res_table &lt;- table(df$time, df$region)) ## ## 中山 中正 信義 內湖 北投 南港 士林 大同 大安 文山 松山 萬華 ## 00~02 62 15 27 20 24 19 28 15 24 17 4 17 ## 02~04 26 22 12 15 17 12 29 10 15 14 13 29 ## 04~06 22 7 11 15 17 6 14 15 14 8 5 22 ## 06~08 20 19 13 16 24 13 17 9 19 9 11 21 ## 08~10 45 27 20 27 22 16 24 17 31 18 24 34 ## 10~12 38 20 18 33 35 19 35 12 34 18 35 41 ## 12~14 30 25 20 26 34 15 46 12 49 25 23 33 ## 14~16 43 19 18 39 32 20 40 26 32 19 22 32 ## 16~18 21 19 8 24 33 11 30 13 25 16 20 26 ## 18~20 39 42 23 22 40 18 31 13 23 23 17 23 ## 20~22 40 13 22 34 17 20 41 13 26 15 25 37 ## 22~24 33 20 16 18 15 9 23 9 12 17 14 20 # Checking it class and its content class(res_table) ## [1] &quot;table&quot; ## [1] &quot;table&quot; 5.1.6 繪圖 通常這種類別資料交叉分析最常用的圖表型態之一便是Mosaic Plot（但事實上Mosaic Plot不見能夠被一眼就了解）。我們可以把交叉分析後的變項res_table直接用MosaicPlot來繪圖。 # mosaicplot() to plot 2-dim categorical vars. mosaicplot(res_table) # Add argument main (figure title) mosaicplot(res_table, main=&quot;mosaic plot&quot;) 5.1.6.1 解決圖表無法顯示中文 大部分的視覺化套件都無法順利顯示中文，除非特別指定所要用的中文字型。這方面網路上可以找到很多的說明，但非常討厭的是，幾乎每換一套視覺化工具，換一套語言，就有不同的中文字體指定方式。例如用base的plot()來繪圖或用ggplot()的中文字型指定方法便不同，且軸上面有中文、圖標有中文、或者圖內有中文都要分開指定，非常討人厭。 Mosaic Plot屬於base R的plot()，其中文指定方法要指定在繪圖前的par()函式中（par為parameter的意思），指定方法為par(family=('Heiti TC Light'))，Heiti TC Light為字體名稱，為OSX上在用的黑體細字，STKaiti則為標楷體。然後，par()和mosaicplot()兩個函式要「同時執行」，也就是請你直接用shift-cmd(ctrl)-Enter執行整個code-cell，或者將該兩個函式選起來一次執行。 par(family=(&#39;STKaiti&#39;)) # par(family=(&#39;Heiti TC Light&#39;)) mosaicplot(res_table, main=&quot;mosaic plot&quot;, color=T) 5.1.6.2 自訂顏色 目前顏色實在過醜，你可以自訂顏色指給mosaicplot()。例如我底下便產製了12種顏色後，將其作為mosaicplot()的參數 # Set up color by yourself. colors &lt;- c(&#39;#D0104C&#39;, &#39;#DB4D6D&#39;, &#39;#E83015&#39;, &#39;#F75C2F&#39;, &#39;#E79460&#39;, &#39;#E98B2A&#39;, &#39;#9B6E23&#39;, &#39;#F7C242&#39;, &#39;#BEC23F&#39;, &#39;#90B44B&#39;, &#39;#66BAB7&#39;, &#39;#1E88A8&#39;) # par(family=(&#39;STKaiti&#39;)) par(family=(&#39;Heiti TC Light&#39;)) mosaicplot(res_table, color=colors, border=0, off = 3, main=&quot;Theft rate of Taipei city (region by hour)&quot;) 5.1.7 Practices 5.1.7.1 萃取月份作為新變項month 除了時間和地區可能會有差別外，那月份會不會竊盜案的數量也有差異呢？會不會冬天小偷也都在家休息了，夏天多呢？請嘗試從發生日期萃取出竊盜案發生的月份，並儲存為一個新的變項month。 5.1.7.2 使用count()來計數 請練習看看如果用count()來計數單一變項，如前述的region、time或前面練習中新產生的month。 5.1.7.3 分週末與週間計算 使用lubridate套件可以將文字表示的日期轉換為R的時間物件，進而可以用lubridate的wday()函式求取該日期是週幾，便可以計算，週間和週末的竊盜率有何差別。可以先計算看看，週一到週日分別有什麼差別，再去計算週間與週末的平均會有什麼差別（要注意，週末和週間天數並不同） 5.2 Read online files 方法一：直接依資料網址讀取檔案。現在的程式語言所設計的讀取檔案函式通常會允許使用者直接讀取資料所在的URL。所以，我們可以直接從網路上載入台北市竊盜案資料。首先要至臺北資料大平台上查詢「住宅竊盜」，可以找到臺北市住宅竊盜點位資訊，點選後對右上方的下載按右鍵可取得鏈結到該資料的URL（如https://data.taipei/api/getDatasetInfo/downloadResource?id=68785231-d6c5-47a1-b001-77eec70bec02&amp;rid=93d9bc2d-af08-4db7-a56b-9f0a49226fa3）。 由於該資料網址似非永久網址，故本範例並未執行以下程式碼，僅提供範例程式碼讓個人替換網址來做測試。 方法二：用R程式將該網址的檔案抓回本機端儲存。部分Mac電腦無法使用read.csv()從網路上取得資料又轉為data.frame，一個可行的辦法是先用GET(url,write_disk(\"data/tptheft.csv\"))將其取回並命名為data/tptheft.csv，之後再用df &lt;- read.csv(\"data/tptheft.csv\")直接讀取該檔案。 GET(url, write_disk(&quot;data/tptheft.csv&quot;, overwrite = TRUE)) df &lt;- read.csv(&quot;data/tptheft.csv&quot;) 5.3 Counting Review 5.3.1 tapply() 我們也可用tapply() 函式來達到一樣的目的。Apply家族的函式都是，針對某個資料，將某個函式套用到某個物件上。tapply() 即是用來做計數的，tapply(df$編號, df$time, length)有三個輸入，第一個輸入為整體物件，第二個輸入為要據以彙整的變項，在此為df$time，第三個是要用來彙整的函式，因為這裡要做計數，所以要用length函式。 註：同樣用class()來觀察彙整後的資料型態為array，和前者的table資料型態不同。 5.3.2 tapply() two variables 用tapply()來做兩個變數交叉分析的語法如下，必須要把兩個Vector包在一個list()中。其他不變。兩個變項用tapply()交叉分析後的結果，變數型態會變成matrix。前者用table()來交叉分析的仍是table型態。 res_tapply ## 中山 中正 信義 內湖 北投 南港 士林 大同 大安 文山 松山 萬華 ## 00~02 62 15 27 20 24 19 28 15 24 17 4 17 ## 02~04 26 22 12 15 17 12 29 10 15 14 13 29 ## 04~06 22 7 11 15 17 6 14 15 14 8 5 22 ## 06~08 20 19 13 16 24 13 17 9 19 9 11 21 ## 08~10 45 27 20 27 22 16 24 17 31 18 24 34 ## 10~12 38 20 18 33 35 19 35 12 34 18 35 41 ## 12~14 30 25 20 26 34 15 46 12 49 25 23 33 ## 14~16 43 19 18 39 32 20 40 26 32 19 22 32 ## 16~18 21 19 8 24 33 11 30 13 25 16 20 26 ## 18~20 39 42 23 22 40 18 31 13 23 23 17 23 ## 20~22 40 13 22 34 17 20 41 13 26 15 25 37 ## 22~24 33 20 16 18 15 9 23 9 12 17 14 20 # View(res) 5.3.3 dplyr::count() two variables 這邊多介紹一個用dplyr套件的count()函式來做交叉分析的方法（未來會常用這個方法，因為dplyr是tidyverse系列套件的核心套件。dplyr的函式第一個參數永遠是該data.frame， 例如count()；後面time與region則是這個data.frame中的兩個變項。不像tapply()或table()的結果一樣，欄與列分別為time與region，count()出來的結果會有兩個變項分別是指定要計數的time與region ，且會新增一個變項n，代表這組數據（time x region）共有幾個。這種表達型態通常稱為long-table（長表）、而tapply()或table() 的結果通常稱為wide-table（寬表）為典型的交叉分析表。 目前大部分的類別資料分析還是會採用交叉分析表的型態，但未來我們要用tidyverse系列套件做大量的數據彙整或視覺化時，都會盡可能想辦法轉為Long-table型態，讓每一欄剛好就是一個變項。只要是tidyverse系列套件所計算出來的資料型態幾乎都是類似data.frame的型態，例如觀察count的結果便是\"tbl_df\" \"tbl\" \"data.frame\"。 5.4 Pivoting long-wide tables 5.4.1 long-to-wide 那長表列可以轉為寬表嗎？可以，tidyverse系列套件中的tidyr套件有個函式spread()可以接著把某個變項展開為欄。例如原本上述的列是時間與行政區的交叉組合，但我可以把行政區展開為欄、或者把時間展開為欄 。如下例，spread(res_count, region, n, fill = 0) 有四個參數，遵循tidyverse系列套件的規則，第一個位置為data.frame，第二個參數則是要被展開至欄的變項這裡為region，第三個參數則是因應region被展開後，那中間交叉分析的數值就是n，最後一個參數是避免spread時有些交叉組是沒有資料的，因此fill=0可以指定，如果某個time x region的交叉組別是沒資料的，就填上0，也有可能是用fill=NA填上NA。以下的例子中也提供了將time 展開至欄的寫法供參考。 現在spread()函式已經被新的函式取代，為pivot_wider()。spread(res_count, region, n, fill = 0) 在此需要改寫為pivot_wider(res_count, names_from = region, values_from = n, values_fill = 0)。大致上和spread()用法是一樣的，只是要寫清楚，哪個變數要給哪一個參數。 展開後的資料型態和前者計數後的資料型態一樣，都是\"tbl_df\" \"tbl\" \"data.frame\"。這是為什麼tidyverse系列的套件逐漸變成R的顯學的原因之一。 library(tidyr) # spreading the region into columns # (res_count_spread &lt;- spread(res_count, region, n, fill = 0)) res_count_spread &lt;- pivot_wider(res_count, names_from = region, values_from = n, values_fill = 0) class(res_count_spread) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; # spreading the time into columns # res_count_spread &lt;- spread(res_count, time, n, fill = 0) res_count_spread ## # A tibble: 12 × 13 ## time 中山 中正 信義 內湖 北投 南港 士林 大同 大安 文山 松山 萬華 ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 00~02 62 15 27 20 24 19 28 15 24 17 4 17 ## 2 02~04 26 22 12 15 17 12 29 10 15 14 13 29 ## 3 04~06 22 7 11 15 17 6 14 15 14 8 5 22 ## 4 06~08 20 19 13 16 24 13 17 9 19 9 11 21 ## 5 08~10 45 27 20 27 22 16 24 17 31 18 24 34 ## 6 10~12 38 20 18 33 35 19 35 12 34 18 35 41 ## 7 12~14 30 25 20 26 34 15 46 12 49 25 23 33 ## 8 14~16 43 19 18 39 32 20 40 26 32 19 22 32 ## 9 16~18 21 19 8 24 33 11 30 13 25 16 20 26 ## 10 18~20 39 42 23 22 40 18 31 13 23 23 17 23 ## 11 20~22 40 13 22 34 17 20 41 13 26 15 25 37 ## 12 22~24 33 20 16 18 15 9 23 9 12 17 14 20 # ??dplyr::count 5.4.2 Wide-to-long 寬表格亦可用tidyr的gather()函式轉回長表格型態。但gather()近期也已經被新的函式pivot_longer()取代。原先的gather(res_count_spread, region, n, -time)應取代為pivot_longer(res_count_spread, -time, names_to = \"region\", values_to = \"n\")。 # (long_table &lt;- tidyr::gather(res_count_spread, region, n, -time)) long_table &lt;- pivot_longer(res_count_spread, -time, names_to = &quot;region&quot;, values_to = &quot;n&quot;) 5.5 Residuals analysis mosaicplot()有幾個參數可以用，包含off與shade可用於呈現殘差分析。 off: vector of offsets to determine percentage spacing at each level of the mosaic (appropriate values are between 0 and 20, and the default is 20 times the number of splits for 2-dimensional tables, and 10 otherwise). Rescaled to maximally 50, and recycled if necessary. shade: a logical indicating whether to produce extended mosaic plots, or a numeric vector of at most 5 distinct positive numbers giving the absolute values of the cut points for the residuals. By default, shade is FALSE, and simple mosaics are created. Using shade = TRUE cuts absolute values at 2 and 4. # par(family=(&#39;STKaiti&#39;)) par(family=(&#39;Heiti TC Light&#39;)) mosaicplot(res_table, color=T, shade = T, border=0, off = 3, main=&quot;Theft rate of Taipei city (region by hour)&quot;) "],["from-base-r-to-dplyr.html", "Chapter 6 From base R to dplyr 6.1 dplyr 6.2 Taipie Theft Count (base to dplyr) 6.3 Paid Maternity Leave", " Chapter 6 From base R to dplyr From base to tidyverse style 相較於R base的較為傳統的R編程風格，tidyverse style的R programming具有以下幾個特點： 基於tidy data理念：tidyverse style的R programming基於tidy data理念，即資料應該以規律的方式組織，以方便分析和視覺化。tidyverse style的R程式庫提供了一些工具和函數，用於處理和轉換tidy data格式的資料，如dplyr、tidyr等。 使用管道操作符：tidyverse style的R programming通常使用管道操作符（%&gt;%），將資料通過多個函數連接起來，形成一個清晰和易於理解的資料處理流程。使用管道操作符可以簡化程式碼並提高程式的可讀性。 強調函數庫的一致性：tidyverse style的R programming強調函數庫之間的一致性，即不同函數庫之間使用相似的函數名稱、參數名稱和返回值等，以方便使用者的學習和使用。 使用簡潔的命名方式：tidyverse style的R programming通常使用簡潔和易於理解的變數和函數命名方式，例如使用動詞表示操作，使用名詞表示資料，以方便使用者理解程式碼的含義。 提供高級的視覺化工具：tidyverse style的R programming提供了一些高級的視覺化工具，如ggplot2、gganimate等，可以幫助使用者更加輕鬆地進行資料視覺化和探索。 6.1 dplyr dplyr是一個tidyverse風格的R程式庫，用於對資料進行快速、一致、直觀的操作和轉換。dplyr提供了一些高效能的函數和工具，如filter、select、mutate、group_by和summarize等，用於對資料進行選擇、篩選、轉換、分組和摘要等操作。 以下是dplyr常用的函數： filter：用於選擇符合特定條件的資料列。 select：用於選擇特定的欄位。 mutate：用於新增或修改欄位。 group_by：用於按照特定欄位進行分組。 summarize：用於對分組後的資料進行摘要統計。 arrange：用於按照欄位的特定順序進行排序。 dplyr具有以下優點： 簡潔而直觀的語法：dplyr的函數名稱和語法都十分簡潔而直觀，易於使用和理解，尤其對於新手來說更加友好。 高效的運行速度：dplyr的設計考慮了資料處理的效率，使用C++實現了部分函數，因此dplyr在處理大型資料集時運行速度較快。 與tidyverse相容：dplyr與其他tidyverse程式庫，如ggplot2和tidyr，可以很好地相容，並且能夠與其他常用的R程式庫進行集成，提供更加全面和高效的資料分析和可視化工具。 6.2 Taipie Theft Count (base to dplyr) library(tidyverse) # options(stringsAsFactors = F) # default options in R ver.&gt; 4.0 6.2.1 Reading data # Read by read_csv() # Will raise error # Error in make.names(x) : invalid multibyte string at &#39;&lt;bd&gt;s&lt;b8&gt;&lt;b9&gt;&#39; # df &lt;- read_csv(&quot;data/tp_theft.csv&quot;) # read_csv() with locale = locale(encoding = &quot;Big5&quot;) library(readr) df &lt;- read_csv(&quot;data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv&quot;) 6.2.2 Cleaning data I Renaming variables by select() Generating variable year Generating variable month Retrieving area library(stringr) selected_df &lt;- df %&gt;% select(id = 編號, cat = 案類, date = `發生日期`, time = `發生時段`, location = `發生地點`) %&gt;% mutate(year = date %/% 10000) %&gt;% mutate(month = date %/% 100 %% 100) %&gt;% mutate(area = str_sub(location, 4, 6)) %&gt;% mutate(county = str_sub(location, 1, 3)) 6.2.3 Cleaning data II Filtering out irrelevant data records # readr::guess_encoding(&quot;data/tp_theft.csv&quot;) filtered_df &lt;- selected_df %&gt;% # count(year) %&gt;% View filter(county == &quot;臺北市&quot;) %&gt;% filter(year &gt;= 104) %&gt;% # count(time) %&gt;% View # count(location) %&gt;% filter(!area %in% c(&quot;中和市&quot;, &quot;板橋市&quot;)) 6.2.4 Long to wide form count() two variables pivot_wider() spread one variable as columns to wide form # count() then pivot_wider() df.wide &lt;- filtered_df %&gt;% count(time, area) %&gt;% pivot_wider(names_from = area, values_from = n, values_fill = 0) ??pivot_wider 6.2.5 Setting time as row.name for mosaicplot row.names(df.wide) &lt;- df.wide$time df.wide$time &lt;- NULL # Specify fonts for Chinese # par(family=(&#39;STKaiti&#39;)) par(family=(&#39;Heiti TC Light&#39;)) # for mac # Specify colors colors &lt;- c(&#39;#D0104C&#39;, &#39;#DB4D6D&#39;, &#39;#E83015&#39;, &#39;#F75C2F&#39;, &#39;#E79460&#39;, &#39;#E98B2A&#39;, &#39;#9B6E23&#39;, &#39;#F7C242&#39;, &#39;#BEC23F&#39;, &#39;#90B44B&#39;, &#39;#66BAB7&#39;, &#39;#1E88A8&#39;) # mosaicplot() mosaicplot(df.wide, color=colors, border=0, off = 3, main=&quot;Theft rate of Taipei city (region by hour)&quot;) 6.2.6 Clean version library(readr) # options(stringsAsFactors = F) df &lt;- read_csv(&quot;data/臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv&quot;) selected_df &lt;- df %&gt;% select(id = 編號, cat = 案類, date = `發生日期`, time = `發生時段`, location = `發生地點`) %&gt;% mutate(year = date %/% 10000) %&gt;% mutate(month = date %/% 100 %% 100) %&gt;% mutate(area = stringr::str_sub(location, 4, 6)) %&gt;% mutate(county = stringr::str_sub(location, 1, 3)) selected_df %&gt;% count(year) ## # A tibble: 9 × 2 ## year n ## &lt;dbl&gt; &lt;int&gt; ## 1 103 1 ## 2 104 687 ## 3 105 663 ## 4 106 560 ## 5 107 501 ## 6 108 411 ## 7 109 304 ## 8 110 189 ## 9 111 31 selected_df %&gt;% count(time) %&gt;% head(10) ## # A tibble: 10 × 2 ## time n ## &lt;chr&gt; &lt;int&gt; ## 1 00~02 272 ## 2 02~04 214 ## 3 03~05 8 ## 4 04~06 156 ## 5 05~07 23 ## 6 06~08 191 ## 7 08~10 305 ## 8 09~11 6 ## 9 10~12 338 ## 10 11~03 1 selected_df %&gt;% arrange(time) %&gt;% head(10) ## # A tibble: 10 × 9 ## id cat date time location year month area county ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2 住宅竊盜 1040101 00~02 臺北市文山區萬美里萬寧… 104 1 文山… 臺北市 ## 2 3 住宅竊盜 1040101 00~02 臺北市信義區富台里忠孝… 104 1 信義… 臺北市 ## 3 6 住宅竊盜 1040102 00~02 臺北市士林區天福里1鄰… 104 1 士林… 臺北市 ## 4 12 住宅竊盜 1040105 00~02 臺北市中山區南京東路3… 104 1 中山… 臺北市 ## 5 33 住宅竊盜 1040115 00~02 臺北市松山區饒河街181~… 104 1 松山… 臺北市 ## 6 74 住宅竊盜 1040131 00~02 臺北市南港區重陽路57巷… 104 1 南港… 臺北市 ## 7 75 住宅竊盜 1040201 00~02 臺北市北投區中心里中和… 104 2 北投… 臺北市 ## 8 92 住宅竊盜 1040210 00~02 臺北市北投區大同路200… 104 2 北投… 臺北市 ## 9 95 住宅竊盜 1040212 00~02 臺北市萬華區萬大路493… 104 2 萬華… 臺北市 ## 10 106 住宅竊盜 1040216 00~02 臺北市信義區吳興街269… 104 2 信義… 臺北市 filtered_df &lt;- selected_df %&gt;% # count(year) %&gt;% View filter(year &gt;= 104) %&gt;% filter(!time %in% c(&quot;03~05&quot;, &quot;05~07&quot;, &quot;09~11&quot;, &quot;11~13&quot;, &quot;15~17&quot;, &quot;17~19&quot;, &quot;18~21&quot;, &quot;21~23&quot;, &quot;23~01&quot;)) # count(time) %&gt;% View # count(location) %&gt;% # filter(!area %in% c(&quot;中和市&quot;, &quot;板橋市&quot;)) df.wide &lt;- filtered_df %&gt;% count(time, area) %&gt;% pivot_wider(names_from = area, values_from = n, values_fill = 0) %&gt;% as.data.frame() row.names(df.wide) &lt;- df.wide$time df.wide$time &lt;- NULL par(family=(&#39;Heiti TC Light&#39;)) # for mac # Specify colors colors &lt;- c(&#39;#D0104C&#39;, &#39;#DB4D6D&#39;, &#39;#E83015&#39;, &#39;#F75C2F&#39;, &#39;#E79460&#39;, &#39;#E98B2A&#39;, &#39;#9B6E23&#39;, &#39;#F7C242&#39;, &#39;#BEC23F&#39;, &#39;#90B44B&#39;, &#39;#66BAB7&#39;, &#39;#1E88A8&#39;) # mosaicplot() mosaicplot(df.wide, color=colors, border=0, off = 3, main=&quot;Theft rate of Taipei city (region by hour)&quot;) 6.3 Paid Maternity Leave 6.3.1 Visual Strategies 這個例子之所以有趣在於記者選定了「美國沒有產假支薪」作為新聞的賣點。在呈現的時候，就必須要盡可能地凸顯這樣的情形。一般來說，會繪製世界地圖來呈現美國是目前少數沒有產假支薪的國家之一（在本資料197個國家中僅有9國目前沒有給付產假薪水。其實該筆來自Word Policy Analysis Center資料含有自1995年至2003年共19年的資料（本案例即就是下載該中心所分享的調查資料，不用申請帳號）。於是該專題的作者便構思利用過去到現在的資料來凸顯美國在這方面一直沒有改變。 但要處理197個國家的在19年間的變化相當不易。例如若為每年繪製一張世界地圖，然後以動畫或動態卷軸來凸顯這19年間美國的變化，也會因為國家數過多而難以聚焦在作者想突顯的美國。 而這便是作者在視覺化上相當具有巧思的地方。由於產假給付程度在該調查中分為五個等級，包含0週、0-14週、14-25週、26-51週、52週以上等。作者便從給付程度最高的層級開始做長條圖，共五個階層的子圖。而每個階層的子圖，作者又將該層級的圖分為「保持不變（Stay Same）」和「持續增加（Increase）」兩組。經過這樣的分組，會得到9個子圖。分別為等級5（保持不變、持續增加）、等級4（保持不變、持續增加）、…、等級1（保持不變）。讀者在看的時候，會依次看到給付程度最高到最低的國家，也可以看到哪些國家在這19年間制度有所變化（通常是增加）。但看到最後的時候，便會看到美國的情形，即是無產假給付。 6.3.2 Code by dplyr 首先，程式碼使用 filter() 函數篩選出符合條件的列，其中 matleave_13 和 matleave_95 兩欄都必須等於 5。接著，pivot_longer() 函數將資料框轉換成長格式（long format），將從第二欄到第二十欄的資料整合到兩個欄位 year 和 degree 中。這裡 names_to 參數指定新欄位 year 的名稱，values_to 參數指定新欄位 degree 的名稱，cols 參數指定要整合的欄位範圍。 接下來，replace_na() 函數將 degree 欄位中的 NA 值替換為 0。然後，mutate() 函數使用 as.POSIXct() 函數將 year 欄位中的字串轉換為日期時間格式，再使用 year() 函數從日期時間中提取年份，最終將年份資訊存儲回 year 欄位中。其中 “matleave_%y” 是日期時間格式字串，其中 “%y” 表示兩位數的年份（例如 “13”）。這樣就將 “matleave_13”、“matleave_14” 等字串轉換成了對應的日期時間。 ggplot() 函數創建了一個空的 ggplot2 圖形物件，使用 aes() 函數定義了 x 軸 year 和 y 軸 degree 的變數名稱。geom_col() 函數指定用長條圖呈現資料，設置了顏色和填充顏色。ylim() 函數限制了 y 軸的範圍，將其設置為 0 到 5，無論y軸資料有沒有到5或者是否超過5，都會限定在0到5之間。facet_wrap() 函數則根據 iso3 欄位生成多個子圖。最後，theme_void() 函數將圖形主題設置為空白，不帶任何邊框或背景。 library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.0 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.1.8 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors options(scipen = 999) library(readxl) matleave &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) %&gt;% select(iso3, 6:24) matleave %&gt;% filter(matleave_13 == 5, matleave_95 == 5) %&gt;% pivot_longer(names_to = &quot;year&quot;, values_to = &quot;degree&quot;, cols = 2:20) %&gt;% replace_na(list(degree = 0)) %&gt;% mutate(year = year(as.POSIXct(strptime(year, &quot;matleave_%y&quot;)))) %&gt;% ggplot() + aes(year, degree) + geom_col(color = &quot;royalblue&quot;, fill = &quot;royalblue&quot;) + ylim(0, 5) + facet_wrap(~ iso3) + theme_void() 6.3.3 Generating each 在 R 中，函式是一個可重複使用的程式碼塊，可以接受輸入參數，並返回計算結果。函式可以簡化程式碼，使其更易於維護和修改。為了不要重複相同的程式碼，以下程式碼將視覺化的部分改用「函式」來進行撰寫，再輸入不同子圖所要使用的資料來進行繪圖。 在這個程式碼中，generating_plot() 是一個自定義的函式，它接受一個資料框 df 作為輸入參數。成對大括號內部為該函式所執行的步驟，包含pivot_longer()、replace_na()等。輸出則是一個 ggplot2 圖形物件，其中包含了將這些資料轉換為長條圖的視覺化表示。 在 R 中，創建一個函式需要使用 function() 關鍵字。一個最簡單的函式可能只包含一個輸入參數和一個返回值，例如：my_function &lt;- function(x) {return(x^2)}。在這個例子中，函式名稱是 my_function，它有一個輸入參數 x，函式主體是 x^2，表示將輸入的 x 參數平方。函式主體的執行結果通過 return() 函數返回，並可以存儲到變數中，例如：result &lt;- my_function(3)。函式的定義亦可包含多個輸入參數，可以用數字、list、或Data.Frame等當成輸入參數。 library(tidyverse) options(scipen = 999) library(readxl) matleave &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) %&gt;% select(iso3, 6:24) generating_plot &lt;- function(df){ df %&gt;% pivot_longer(names_to = &quot;year&quot;, values_to = &quot;degree&quot;, cols = 2:20) %&gt;% replace_na(list(degree = 0)) %&gt;% mutate(year = year(as.POSIXct(strptime(year, &quot;matleave_%y&quot;)))) %&gt;% ggplot() + aes(year, degree) + geom_col(color = &quot;royalblue&quot;, fill = &quot;royalblue&quot;) + ylim(0, 5) + facet_wrap(~ iso3) + theme_void() + theme(strip.text = element_text(size = 14, face = &quot;bold&quot;, vjust=0.5), strip.placement = &quot;inside&quot; ) } matleave %&gt;% filter(matleave_13 == 5, matleave_95 == 5) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 5, matleave_95 != 5) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 4, matleave_95 == 4) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 4, matleave_95 != 4) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 3, matleave_95 == 3) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 3, matleave_95 != 3) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 2, matleave_95 == 2) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 2, matleave_95 != 2) %&gt;% generating_plot() matleave %&gt;% filter(matleave_13 == 1) %&gt;% generating_plot() 6.3.4 Gathering subplots by cowplot 這段程式碼的作用是將多個 ggplot2 圖形物件組合成一個網格，然後將這個網格圖形儲存為一個圖像文件。首先，這段程式碼定義了多個變數，如 plot_row1、plot_row2、plot_row3 等，每個變數都是一個網格圖形。這些變數通過 plot_grid() 函數來創建，這個函數可以將多個 ggplot2 圖形物件組合成一個網格。在 plot_grid() 函數中，可以設置 labels 參數來為每個子圖添加標籤。 然後，這些變數通過 plot_grid() 函數再次組合，形成一個更大的網格圖形。這裡使用 ncol = 1 參數將多個網格排列成一列。最後，使用 ggsave() 函數將這個網格圖形儲存為一個圖像文件。在這個例子中，圖像文件的名稱是 “test.png”，大小為 10 英寸 x 30 英寸，分辨率為 300 DPI。 總的來說，這段程式碼的作用是將多個 ggplot2 圖形物件組合成一個網格，並將這個網格圖形儲存為一個圖像文件。這樣做可以方便地進行圖像導出和共享，並且可以將多個圖形合併在一起進行比較和分析。 library(cowplot) plot55 &lt;- matleave %&gt;% filter(matleave_13 == 5, matleave_95 == 5) %&gt;% generating_plot() plot05 &lt;- matleave %&gt;% filter(matleave_13 == 5, matleave_95 != 5) %&gt;% generating_plot() plot44 &lt;- matleave %&gt;% filter(matleave_13 == 4, matleave_95 == 4) %&gt;% generating_plot() plot04 &lt;- matleave %&gt;% filter(matleave_13 == 4, matleave_95 != 4) %&gt;% generating_plot() plot33 &lt;- matleave %&gt;% filter(matleave_13 == 3, matleave_95 == 3) %&gt;% generating_plot() plot03 &lt;- matleave %&gt;% filter(matleave_13 == 3, matleave_95 != 3) %&gt;% generating_plot() plot22 &lt;- matleave %&gt;% filter(matleave_13 == 2, matleave_95 == 2) %&gt;% generating_plot() plot02 &lt;- matleave %&gt;% filter(matleave_13 == 2, matleave_95 != 2) %&gt;% generating_plot() plot11 &lt;- matleave %&gt;% filter(matleave_13 == 1) %&gt;% generating_plot() plot_row1 &lt;- plot_grid(plot55, plot05, labels = c(&#39;STAY 5&#39;, &#39;INCREASE TO 5&#39;)) plot_row2 &lt;- plot_grid(plot44, plot04, labels = c(&#39;STAY 4&#39;, &#39;INCREASE TO 4&#39;)) plot_row3 &lt;- plot_grid(plot33, plot03, labels = c(&#39;STAY 3&#39;, &#39;INCREASE TO 3&#39;)) plot_row4 &lt;- plot_grid(plot22, plot02, labels = c(&#39;STAY 2&#39;, &#39;INCREASE TO 2&#39;)) final_plot &lt;- plot_grid( plot_row1, plot_row2, plot_row3, plot_row4, plot11, ncol = 1 ) ggsave(&quot;test.png&quot;, final_plot, width=10, height=30, dpi=300) "],["data-manipultaiton-join-data.html", "Chapter 7 Data manipultaiton: Join data 7.1 讀取內政部人口統計資料 7.2 讀取公投資料", " Chapter 7 Data manipultaiton: Join data 7.1 讀取內政部人口統計資料 先使用slice(-1)減去第一行中文欄位名稱。再來，目前縣市鄉鎮市區（site_id）和村里（village）分別是兩個變項，由於不同的鄉鎮市可能會有相同的村里名，所以把site_id與village粘接起來成為完整的村里名vname。 這邊我多加了一行程式碼讓vname可以排到前面一點的變項欄，可以用select()達到這個目的，我之後的變項欄的還要寶劉，所以我多打一個everything()就可以把剩下的變項欄都擺放在後面。因此這個重排變項欄的完整程式碼為select(vname, everything())。 raw &lt;- read_csv(&quot;data/opendata107Y030.csv&quot;) %&gt;% slice(-1) %&gt;% mutate(vname = str_c(site_id, village)) %&gt;% select(vname, everything()) raw %&gt;% head ## # A tibble: 6 × 157 ## vname statistic_yyy district_code site_id village single_age_15down_m ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 新北市板橋區… 107 65000010001 新北市… 留侯里 118 ## 2 新北市板橋區… 107 65000010002 新北市… 流芳里 119 ## 3 新北市板橋區… 107 65000010003 新北市… 赤松里 60 ## 4 新北市板橋區… 107 65000010004 新北市… 黃石里 113 ## 5 新北市板橋區… 107 65000010005 新北市… 挹秀里 123 ## 6 新北市板橋區… 107 65000010006 新北市… 湳興里 351 ## # ℹ 151 more variables: single_age_15_19_m &lt;chr&gt;, single_age_20_24_m &lt;chr&gt;, ## # single_age_25_29_m &lt;chr&gt;, single_age_30_34_m &lt;chr&gt;, ## # single_age_35_39_m &lt;chr&gt;, single_age_40_44_m &lt;chr&gt;, ## # single_age_45_49_m &lt;chr&gt;, single_age_50_54_m &lt;chr&gt;, ## # single_age_55_59_m &lt;chr&gt;, single_age_60_64_m &lt;chr&gt;, ## # single_age_65_69_m &lt;chr&gt;, single_age_70_74_m &lt;chr&gt;, ## # single_age_75_79_m &lt;chr&gt;, single_age_80_84_m &lt;chr&gt;, … # raw %&gt;% glimpse() 7.1.1 分析規劃 建立各鄉鎮市區的老年人口比例 建立各鄉鎮市區的年齡中位數 讀取所有（某一）公投案的結果 視覺化年齡與公投結果間的相關性 7.1.2 清理資料 我們之前在談資料的「觀察、統計、和二維表格」三種型態時，曾經談到統計型態和二維表格型態間的差異。當時所提到的「統計型態」，也就是每個變項欄恰好是我們所認知的單一變項（如每一個變項欄恰是人口統計變項的年齡、性別、教育程度、數量），會有助於進行統計分析，也就是tidy型態的資料。相較之下，上述的表格是把資料攤成二維的型態，每一個變項是某個年齡層的某種性別的某種婚姻狀況，包含了三個人口統計變項，是方便一般大眾讀的，但不是適合進行統計的tidy型態。 這類的資料tidyverse的相關套件把它稱為tidy form。遵守tidy form形式的資料是，每一個欄恰好一個變項。例如在內政部開放資料「15歲以上現住人口按性別、年齡、婚姻狀況及教育程度分」中，每個變數（年齡、婚姻狀況、教育程度、人口數等等）均各自為一個欄上的變項。 15歲以上現住人口按性別、年齡、婚姻狀況及教育程度分 | 政府資料開放平臺 (data.gov.tw) 接下來，我要把表格型態的資料轉為tidy型態資料。原本的資料是這樣的型態。 我要將後方的數值變項欄（single_age_15down_m等）轉為單一變項key的值，再把其所對應到的資料值，也轉為單一變項value。請注意看上圖和程式碼後方結果圖的顏色區塊。南投縣中寮鄉中寮村（綠色）被複製且展開為多列。而原本多個年齡層和資料的變數項（紅色）變成一個變項欄的資料，分別對應到其原本對應的數值（藍色）。 tidy_data &lt;- raw %&gt;% pivot_longer(names_to = &quot;key&quot;, values_to = &quot;value&quot;, cols = 6:ncol(.)) 相對於pivot_wider()把變項展開成欄，pivot_longer()函式可以收合被展開的變項，在此將要收合的變數名稱統一稱為key，並將該變數所對應到的數值稱為value。並且我用6:ncol(.)來指定我要收合哪些變項欄。 ncol(.)的「.」代表從前面%&gt;% pipe進來的那個data.frame。 pivot_longer()後資料列從7760增加至1,179,520列。（灰底部分用來觀察結果用） 由於每一列恰好是一種婚姻狀態、一個年齡層和一個性別，所以，我們可以把key中的婚姻狀態、年齡層和性別切割出來做為變數。觀察key欄位發現其格式有一些規律性，主要是婚姻狀態_年齡下界_年齡上界_性別的形式。標準的範例如married_15_10_m或widowed_25_29_f，但有一些並非這種形式，例如： single_age_15_19_m：其中single_age之間多了一個底線，所以把single_age取代為single就好。 married_15down_m：因為是15down少了一個底線，所以取代為0_14。 married_100up_f：因為100up少了一個底線，所以取代為100_105。 之後，我使用tidyr::separate()函式將key切成四個變項，分別為married、ageLower、ageUpper、gender。 separate()有一個參數是remove=T（預設值），意思是說，當把key變項切割為四個變項後，預設把key變項給丟棄；但如果未來你還會用到key變項的話，你可以把remove改為FALSE，代表切割完後，還保留key變項。 tidyr::separate()：Given either regular expression or a vector of character positions, separate() turns a single character column into multiple columns. 此時我清理出來的資料大致如下： 最後就剩零星的操作，包含轉換資料為數值型態、或者你也可以在這裡建立新的指標（例如年齡平均）。最後加上一個arrange(vname)讓他按照村里的全名排序。 tidy_data &lt;- raw %&gt;% pivot_longer(names_to = &quot;key&quot;, values_to = &quot;value&quot;, cols = 6:ncol(.)) %&gt;% mutate(key = str_replace(key, &quot;_age&quot;, &quot;&quot;)) %&gt;% mutate(key = str_replace(key, &quot;100up&quot;, &quot;100_110&quot;)) %&gt;% mutate(key = str_replace(key, &quot;15down&quot;, &quot;0_15&quot;)) %&gt;% separate(key, c(&quot;married&quot;, &quot;ageLower&quot;, &quot;ageUpper&quot;, &quot;gender&quot;)) %&gt;% mutate(ageLower = as.numeric(ageLower), # age = str(ageLower, ageUpper), ageUpper = as.numeric(ageUpper), value = as.numeric(value)) %&gt;% select(-statistic_yyy) %&gt;% arrange(vname) 7.1.3 進階：運用rowwise() raw %&gt;% mutate_at(vars(6:157), as.numeric) %&gt;% replace(is.na(.), 0) %&gt;% rowwise() %&gt;% mutate(married = sum(c_across(matches(&quot;widowed|divorced|married&quot;)), na.rm = T)) %&gt;% mutate(lt65 = sum(c_across(matches(&quot;65|70|75|80|85|90|95|100&quot;)), na.rm = T)) %&gt;% select(vname, married, lt65) %&gt;% head ## # A tibble: 6 × 3 ## # Rowwise: ## vname married lt65 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 新北市板橋區留侯里 920 272 ## 2 新北市板橋區流芳里 826 280 ## 3 新北市板橋區赤松里 463 149 ## 4 新北市板橋區黃石里 632 210 ## 5 新北市板橋區挹秀里 1061 365 ## 6 新北市板橋區湳興里 3157 838 7.1.4 建立鄉鎮市區與村里指標 7.1.4.1 使用group_by()建立村里指標 將資料轉換為tidy型態後，接下來要做的事情是建立村里、鄉鎮市區、縣市的分級指標。針對每個村里，我希望計算出總人口數people（原本依據年齡與性別、婚姻情形分割）、老年人總數elderSum、曾結婚人口總數marriedSum。之後再分別除以該村里的總人口數people，老年人的人口比例elderPerc以及結婚的人口比例marriedPerc。 因為一個村里的資料會根據不同性別、不同婚姻情形、不同年齡層被切割為不同的資料列，共2X4X19個資料列。因此，如果我想知道一個村里的總人口數或相關統計資料，就不需彙整這些資料列。dplyr有非常強大的group_by()可以根據群組來進行運算，我用村里代號（district_code）來做群組運算，所以是group_by(district_code)或用我們所產生的vname作為群組基準來運算group_by(vname)。 語法上，通常group_by()之後經常會跟著summarise()，跟mutate()的語法有點像，都會產生新變數，但因為這邊用group_by()針對某個或某幾個變數做彙整，相當於base套件的apply()函式，因此會根據每個不同的群組做組內的數值彙整運算。比方說，在以下的程式碼中，我用sum(num)計算了該群組內的總人數，然後同樣累計了年齡大於等於65歲的總人數，以及婚姻狀態不為single的總人數。 簡單地說，相當於按照不同的村里（district_code）各別做value的加總（該村里的總人口數）、篩選出年齡65歲以上的人口組別進行加總、篩選出不是單身者的人口組別進行加總。之後會加一個ungroup()解開群組。 最後一行left_join(raw %&gt;% select(vname, site_id), by = \"vname\")是由於group_by()後會讓其他變數消失（例如鄉鎮市區名site_id），所以我希望將原本資料raw中的site_id給併回來。我可以抽取出raw中的vname和site_id兩個變項，然後以vname為key，用left_join()將site_id給併回來。 筆記：當group_by()、summarize()後不參與的變項會消失，但可以透過left_join()的方式將原有的變項併回來。 village_stat &lt;- tidy_data %&gt;% filter(ageLower &gt;= 20) %&gt;% group_by(vname) %&gt;% summarise(legalPopulation = sum(value), elderSum = sum(value[ageLower &gt;= 65]), marriedSum = sum(value[married %in% c(&quot;married&quot;, &quot;divorced&quot;, &quot;widowed&quot;)]), womenSum = sum(value[gender == &quot;f&quot;])) %&gt;% ungroup() %&gt;% left_join(raw %&gt;% select(vname, site_id), by = &quot;vname&quot;) 測試 7.1.4.2 將村里指標匯總為鄉鎮市區指標 剛剛是根據村里（village）來建立指標，現在要根據鄉鎮市區來建立指標。走過前方的邏輯後，我們只需要把原本用來做group_by()的村里變項vname改為鄉鎮市區的變項site_id，就可以完成這件事，其他都一樣，你發現沒？ 不過這邊我要多做一件事。因為三民區和鳳山區兩個區非常的大（我猜），所以內政資料中的鄉鎮市區資料有分「三民一」、「三民二」、「鳳山一」、「鳳山二」。我們只要在彙整資料前，將site_id的這四類值取代好，便可以在鄉鎮市區的指標中一併彙整。以下我一共彙整出四種資料，分別為該區人口數（legalPopulation）、老年人口數（elderSum）、曾婚人口數（marriedSum）、女性人口數（womenSum）。不難想像接下來可以計算出各鄉鎮市區的老年人口比例、曾婚比例、女性比例等。 town_stat &lt;- village_stat %&gt;% # mutate(site_id = str_sub(vname, 1, 6)) %&gt;% mutate(site_id = str_replace(site_id, &quot;三民一|三民二&quot;, &quot;三民區&quot;)) %&gt;% mutate(site_id = str_replace(site_id, &quot;鳳山一|鳳山二&quot;, &quot;鳳山區&quot;)) %&gt;% group_by(site_id) %&gt;% summarize(legalPopulation = sum(legalPopulation), elderSum = sum(elderSum), marriedSum = sum(marriedSum), womenSum = sum(womenSum) )%&gt;% ungroup() 7.1.5 視覺化測試（老年人口數 x 曾婚人口數） town_stat %&gt;% mutate(marriedPerc = marriedSum / legalPopulation) %&gt;% mutate(womenPerc = womenSum / legalPopulation) %&gt;% mutate(elderPerc = elderSum / legalPopulation) %&gt;% ggplot() + aes(marriedPerc, elderPerc) + geom_point(alpha = 0.3) # geom_jitter(alpha = 0.3) 7.2 讀取公投資料 首先，先讀取資料並重新命名每個變項。由於我們要連結公投資料和前面的內政部人口統計資料，所以要注意兩筆資料間是否有共通的key（資料庫稱為鍵值）。town_stat的是以site_id鄉鎮市區名為主鍵，所以公投資料這邊也產生一個同名的鄉鎮市區變項site_id。 ref10 &lt;- read_csv(&quot;data/ref10.csv&quot;) %&gt;% select(county = 縣市, town = 鄉鎮市區, agree = 同意票數, disagree = 不同意票數, legalVote = 有效票數, illegalVote = 無效票數, vote = 投票數, legalPopulation = 投票權人數) %&gt;% mutate(site_id = str_c(county, town)) %&gt;% drop_na(site_id) names(ref10) ## [1] &quot;county&quot; &quot;town&quot; &quot;agree&quot; &quot;disagree&quot; ## [5] &quot;legalVote&quot; &quot;illegalVote&quot; &quot;vote&quot; &quot;legalPopulation&quot; ## [9] &quot;site_id&quot; 合併資料測試，注意，由於兩邊都有legalPopulation，所以town_stat中的legalPopulation增生為legalPopulation.x，而ref10中的legalPopulation則重新命名為legalPopulation.y。 town_stat %&gt;% left_join(ref10, by = &quot;site_id&quot;) ## # A tibble: 368 × 13 ## site_id legalPopulation.x elderSum marriedSum womenSum county town agree ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 南投縣中寮… 12791 3272 9553 5824 南投縣 中寮… 5748 ## 2 南投縣仁愛… 12172 1713 9078 5899 南投縣 仁愛… 5702 ## 3 南投縣信義… 12860 1847 9050 5938 南投縣 信義… 6891 ## 4 南投縣南投… 81874 15855 57042 41343 南投縣 南投… 37547 ## 5 南投縣名間… 32388 7106 23375 15304 南投縣 名間… 14533 ## 6 南投縣國姓… 16196 3744 11826 7434 南投縣 國姓… 7089 ## 7 南投縣埔里… 66699 13411 46316 33718 南投縣 埔里… 29571 ## 8 南投縣水里… 15023 3644 10850 7106 南投縣 水里… 6392 ## 9 南投縣竹山… 45629 10154 33201 22244 南投縣 竹山… 19254 ## 10 南投縣草屯… 80426 15141 56384 40008 南投縣 草屯… 35215 ## # ℹ 358 more rows ## # ℹ 5 more variables: disagree &lt;dbl&gt;, legalVote &lt;dbl&gt;, illegalVote &lt;dbl&gt;, ## # vote &lt;dbl&gt;, legalPopulation.y &lt;dbl&gt; 7.2.1 合併公投資料並視覺化 由於人口統計資料中的鄉鎮市區若只有兩個字如「東區」中間有一全形空白「東 區」，但公投資料中並沒有這樣的空白，所以為了兩者要能夠正確合併，需要先做好取代。可以逐一取代，或者，直接取代掉該全形空白為空字串即可。 town_stat %&gt;% mutate(site_id = str_replace(site_id, &quot; &quot;, &quot;&quot;)) %&gt;% # mutate(site_id = str_replace(site_id, &quot;東 區&quot;, &quot;東區&quot;), # site_id = str_replace(site_id, &quot;西 區&quot;, &quot;西區&quot;), # site_id = str_replace(site_id, &quot;南 區&quot;, &quot;南區&quot;), # site_id = str_replace(site_id, &quot;北 區&quot;, &quot;北區&quot;), # site_id = str_replace(site_id, &quot;中 區&quot;, &quot;中區&quot;)) %&gt;% left_join(ref10, by = &quot;site_id&quot;) %&gt;% mutate(agreeRate = agree / legalVote, marriedPerc = marriedSum / legalPopulation.x) %&gt;% # select(site_id, agree, legalVote, marriedSum, legalPopulation.x) %&gt;% ggplot() + aes(agreeRate, marriedPerc) + geom_point(alpha = 0.5, color = &quot;royalblue&quot;) + theme_light() "],["categorical-data-analysis.html", "Chapter 8 Categorical Data Analysis 8.1 Factorizing data 8.2 Order-to-factor 8.3 Cross-tabulating", " Chapter 8 Categorical Data Analysis 這個範例涵括了在做問卷分析時常用的處理步驟。最核心的步驟是將文字陳述的類別資料轉換為便於後續運算的factor或數值資料。如果類別數量過多的時候，在這個過程會順便進行重新分組。例如依照年齡組把填答者分為老年、中壯年、青少年、兒童四組。 raw &lt;- read_rds(&quot;data/tfc_survey.rds&quot;) 8.1 Factorizing data 通常問卷會分為兩種類型的資料，一種是人口統計用的基本資料（如性別、年齡組、教育程度）、另一種是問卷本身要問的題項。以下是常見的問卷型態，包含把年齡從20歲開始每五年作為一組，70歲以上則歸類為一組，共會有十一組。而教育程度則常分為五至六組，但在問卷設計的時候，通常會需要增加「拒答」的選項。如果問卷中包含政黨意識形態，就必須要決定要以黨派作為類別變項，或者以意識形態做順序尺度。以下即為一個順序尺度的案例，從「非常接近泛綠」到「非常接近泛藍」共五個等第，但另增「拒答」選項。 dt &lt;- raw %&gt;% mutate(QA3 = ordered(QA3, levels=c(&quot;20-24&quot;, &quot;25-29&quot;, &quot;30-34&quot;, &quot;35-39&quot;, &quot;40-44&quot;, &quot;45-49&quot;, &quot;50-54&quot;, &quot;55-59&quot;, &quot;60-64&quot;, &quot;65-69&quot;, &quot;70及以上&quot;))) %&gt;% mutate(QA3_lv = ordered(QA3, levels=c(&quot;20-24&quot;, &quot;25-29&quot;, &quot;30-34&quot;, &quot;35-39&quot;, &quot;40-44&quot;, &quot;45-49&quot;, &quot;50-54&quot;, &quot;55-59&quot;, &quot;60-64&quot;, &quot;65-69&quot;, &quot;70及以上&quot;), labels = c(&quot;青年&quot;, &quot;青年&quot;, &quot;壯年&quot;, &quot;壯年&quot;, &quot;壯年&quot;, &quot;中年&quot;, &quot;中年&quot;, &quot;中年&quot;, &quot;中年&quot;, &quot;老年&quot;, &quot;老年&quot;))) %&gt;% mutate(QA4 = ordered(QA4, levels=c(&quot;拒答&quot;, &quot;國小及以下&quot;, &quot;初中、國中&quot;, &quot;高中、高職&quot;, &quot;大專（專科與大學）&quot;, &quot;研究所及以上&quot;), labels=c(&quot;拒答&quot;, &quot;國小以下&quot;, &quot;國中&quot;, &quot;高中職&quot;, &quot;大專&quot;, &quot;研究所以上&quot;))) %&gt;% mutate(QASide=ordered(QASide, exclude=&quot;拒答&quot;, levels=c(&quot;非常接近泛綠&quot;, &quot;接近泛綠&quot;, &quot;都不接近&quot;, &quot;接近泛藍&quot;, &quot;非常接近泛藍&quot;))) 8.1.1 factor-to-order 在一開始清理資料的時候，會建議先把類別變數（通常是文字型態）轉為factor型態。常用的函式是用mutate()搭配ordered()來改變變數型態。ordered()會照類別順序來標定該factor所對應到的數字。可以用as.integer()將factor轉為整數後就可以看到各類別的順序。 dt$QA3[1:10] ## [1] 25-29 35-39 35-39 20-24 45-49 25-29 30-34 20-24 20-24 55-59 ## 11 Levels: 20-24 &lt; 25-29 &lt; 30-34 &lt; 35-39 &lt; 40-44 &lt; 45-49 &lt; 50-54 &lt; ... &lt; 70及以上 as.integer(dt$QA3[1:10]) ## [1] 2 4 4 1 6 2 3 1 1 8 8.1.2 Excluding 如果有某些類別變數的值（如「拒答」）不想被編入factor，可以在reorder()中加入exclude的參數指定不想被編入類別值。 dt$QASide[1:10] ## [1] 非常接近泛綠 接近泛藍 接近泛綠 接近泛綠 非常接近泛綠 ## [6] 非常接近泛藍 接近泛綠 接近泛綠 接近泛藍 接近泛綠 ## Levels: 非常接近泛綠 &lt; 接近泛綠 &lt; 都不接近 &lt; 接近泛藍 &lt; 非常接近泛藍 as.integer(dt$QASide[1:10]) ## [1] 1 4 2 2 1 5 2 2 4 2 8.1.3 Grouping-up 如果有某些類別變數的類別過多，希望再次群組化為較少的組別，如重新群組各年齡層為青年、壯年、中年與老年四個尺度。此時除了levels參數外，可以另外加入labels的參數，指定每個類別變數值所要對應到的群組。以下為群組後的結果，仔細觀察剩下多少個尺度。 dt$QA3[1:10] ## [1] 25-29 35-39 35-39 20-24 45-49 25-29 30-34 20-24 20-24 55-59 ## 11 Levels: 20-24 &lt; 25-29 &lt; 30-34 &lt; 35-39 &lt; 40-44 &lt; 45-49 &lt; 50-54 &lt; ... &lt; 70及以上 as.integer(dt$QA3[1:10]) ## [1] 2 4 4 1 6 2 3 1 1 8 dt$QA3_lv[1:10] ## [1] 青年 壯年 壯年 青年 中年 青年 壯年 青年 青年 中年 ## Levels: 青年 &lt; 壯年 &lt; 中年 &lt; 老年 8.2 Order-to-factor Q7 請問您會不會受到假消息影響？ Q8 請問您認為其他人會不會受到假消息的影響？ 對於Q7、Q8的問題是詢問填答者認為自己或他人會不會受到假消息影響，並從「一點也不會」、「不會」、「會」到「絕對會」共分四個等第。Q7分別是「81, 446, 650, 39」、Q8分別是「5, 58, 803, 350」。相較於Q7，Q8的分佈略為左傾，亦即傾向於認為其他人較容易受影響。此時如果想要分析Q7和Q8間的關係，由於各有四個等第，其交叉分析表會有16個項目，相當難以分析。 dt2 &lt;- dt %&gt;% mutate(Q7 = ordered(Q7, levels=c(&quot;一點也不會&quot;, &quot;不會&quot;, &quot;會&quot;, &quot;絕對會&quot;))) %&gt;% mutate(Q8 = ordered(Q8, levels=c(&quot;一點也不會&quot;, &quot;不會&quot;, &quot;會&quot;, &quot;絕對會&quot;))) %&gt;% mutate(Q7_3rd = as.numeric(Q8)-as.numeric(Q7)) %&gt;% mutate(Q7_3rd_lv = ifelse(Q7 %in% c(&quot;一點也不會&quot;, &quot;不會&quot;) &amp; Q8 %in% c(&quot;會&quot;, &quot;絕對會&quot;), &quot;高&quot;, &quot;低&quot;)) %&gt;% mutate(Q7_3rd_lv = ordered(Q7_3rd_lv, levels=c(&quot;低&quot;, &quot;高&quot;))) 這時候一種策略是把這兩題視為順序尺度變數，然後把兩題的分數相減。相減後的分數從「-1, 0, 1, 2, 3」各有「12, 482, 600, 103, 19」，不難猜到會是一個較為集中的分佈，後續僅能當作順序尺度或連續變項來分析，不適合找一個閾值轉類別變項。 另一種策略是，分別先把Q7與Q8的「一點也不會」和「不會」群組為「不會」、再把「會」與「絕對會」群組為「會」，這樣Q7與Q8的交叉分析表會變成2X2的分析表，雖然群組數量比較少，但別忘記Q7的填答結果集中在會與不會、而Q8為一個較為偏右的分佈，集中在「會」和「絕對會」。Q8勢必會造成比例不均的分組。 dt2 %&gt;% count(as.integer(Q8)-as.integer(Q7)) ## # A tibble: 5 × 2 ## `as.integer(Q8) - as.integer(Q7)` n ## &lt;int&gt; &lt;int&gt; ## 1 -1 12 ## 2 0 482 ## 3 1 600 ## 4 2 103 ## 5 3 19 最後這題所採行的策略是，做高、低第三人效果分組，也就是根據認為自己「一點也不會」、「不會」受影響，而他人「會」或「絕對會」受影響的重新群組為「高第三人效果組」，其他則為「低第三人效果組」。亦即，分組的一句是在對自己與他人的認知上，無模糊空間的分組方法（也就是認為自己至少不會，和認為別人應該會）。 dt2 %&gt;% count(Q7_3rd_lv) ## # A tibble: 2 × 2 ## Q7_3rd_lv n ## &lt;ord&gt; &lt;int&gt; ## 1 低 746 ## 2 高 470 8.3 Cross-tabulating (xtb &lt;- xtabs(~QA3_lv + Q7_3rd_lv, data=dt2)) ## Q7_3rd_lv ## QA3_lv 低 高 ## 青年 178 110 ## 壯年 370 199 ## 中年 157 134 ## 老年 41 27 (chi2 &lt;- chisq.test(xtb)) ## ## Pearson&#39;s Chi-squared test ## ## data: xtb ## X-squared = 10.017, df = 3, p-value = 0.01842 vcd::assocstats(xtb) ## X^2 df P(&gt; X^2) ## Likelihood Ratio 9.9301 3 0.01917 ## Pearson 10.0173 3 0.01842 ## ## Phi-Coefficient : NA ## Contingency Coeff.: 0.09 ## Cramer&#39;s V : 0.091 print(round(chi2$observed, 2)) ## Q7_3rd_lv ## QA3_lv 低 高 ## 青年 178 110 ## 壯年 370 199 ## 中年 157 134 ## 老年 41 27 print(round(chi2$expected, 2)) ## Q7_3rd_lv ## QA3_lv 低 高 ## 青年 176.68 111.32 ## 壯年 349.07 219.93 ## 中年 178.52 112.48 ## 老年 41.72 26.28 print(round(chi2$residuals, 2)) ## Q7_3rd_lv ## QA3_lv 低 高 ## 青年 0.10 -0.12 ## 壯年 1.12 -1.41 ## 中年 -1.61 2.03 ## 老年 -0.11 0.14 par(family=&quot;Heiti TC Light&quot;) gplots::balloonplot(t(xtb), xlab=&quot;第三人效果&quot;, ylab=&quot;年齡組&quot;, main=&quot;&quot;, dotsize=4/max(strwidth(40),strheight(40)), text.size=1.5,label.size=2, rowmar=1, colmar=1) par(family=&quot;Heiti TC Light&quot;) corrplot::corrplot(chi2$residuals, is.corr = F) xtb %&gt;% as_tibble() %&gt;% group_by(QA3_lv) %&gt;% mutate(fill = if_else(n == max(n), &quot;orangered&quot;, &quot;skyblue&quot;)) %&gt;% ungroup() %&gt;% mutate(QA3_lv = ordered(QA3_lv, levels=c(&quot;青年&quot;, &quot;壯年&quot;, &quot;中年&quot;, &quot;老年&quot;))) %&gt;% arrange(desc(QA3_lv)) %&gt;% ggplot() + aes(y = QA3_lv, x=Q7_3rd_lv, color = fill, size = n) + scale_size_area(max_size=70, guide = &quot;none&quot;) + geom_point(alpha=0.7) + scale_color_manual(values = c(&quot;orangered&quot;, &quot;skyblue&quot;), guide = &quot;none&quot;) + geom_text(aes( label=n, vjust=1.3, size=10 ), color=&quot;black&quot;,) + theme_minimal() + theme(text = element_text(family=&quot;Heiti TC Light&quot;), title = element_text(family=&quot;Heiti TC Light&quot;)) "],["timeline.html", "Chapter 9 Processing Timeline 9.1 char-to-timestamp 9.2 Density plot along time 9.3 Freq by month 9.4 Freq-by-date (good) 9.5 Freq-by-hour", " Chapter 9 Processing Timeline 現今網路上有許多開放資料可以供使用者下載或查詢，其中很多資料都包含了時間相關的訊息，例如訂單成立時間、氣象觀測時間、股價報價時間等等。這些時間資訊通常會以字串的方式儲存，但若要在程式中進行時間相關的運算，例如計算時間差、建立時間序列等，就必須先將其轉換為時間物件。在 R 裡面，常用的時間物件有 POSIXct 與 POSIXlt 兩種，我們可以使用 as.POSIXct() 或 as.POSIXlt() 函數將字串轉換為對應的時間物件。轉換完成後，我們就可以方便地進行時間相關的運算，例如計算兩個時間點之間的時間差、將時間轉換為不同的時區、擷取時間序列中的某個時間區間等等。這些時間相關的運算在很多領域都很常見，例如金融、氣象、交通等，因此學習如何使用時間物件進行運算是非常重要的一環。 POSIXct 以自從 1970 年 1 月 1 日 00:00:00 UTC 開始經過的秒數來表示一個時間點，而 POSIXlt 則是以結構化的列表方式來表示，其中包含了年、月、日、時、分、秒等元素。兩者最大的不同在於 POSIXct 更適合用於一些計算，而 POSIXlt 則更容易人類閱讀。我們可以使用 as.POSIXct() 或 as.POSIXlt() 函數來將一個字串轉換為對應的時間物件，也可以使用 Sys.time() 函數來取得當前的時間點。使用這些時間物件，我們可以方便地進行日期與時間的計算，例如算出兩個時間點之間的時間差，或是在時間序列上進行操作等。 9.1 char-to-timestamp 在 R 裡面，我們可以使用 strptime() 函數將字串轉換為時間物件，其中 %Y、%m、%d、%H、%M、%S 等是用來表示時間的格式碼。在這段程式碼中，我們使用 strptime() 函數將 ptime 這個字串轉換為一個時間物件，其中 %Y-%m-%dT%H:%M:%SZ 是該字串的時間格式，也就是說這個字串是以 ISO 8601 的格式表示的時間，例如 2022-03-31T14:30:00Z。tz = \"ASIA/Taipeiw\" 則是指定時間所在的時區，這裡指定的是台灣時間。轉換完成後，我們使用 as.POSIXct() 函數將 strptime() 轉換出來的時間物件再轉換為 POSIXct 時間物件，並將其存入 ptime 這個欄位中。這段程式碼的作用是將一個 ISO 8601 格式的字串轉換為 POSIXct 時間物件，並指定時區為台灣，方便之後進行時間相關的運算。 在 strptime() 函數中，可以使用不同的格式碼來指定時間的格式。以下是常用的幾種格式碼及其意義： %Y：四位數的年份，例如 2022。 %m：兩位數的月份，範圍是 01 到 12。 %d：兩位數的日期，範圍是 01 到 31。 %H：兩位數的小時，範圍是 00 到 23。 %M：兩位數的分鐘，範圍是 00 到 59。 %S：兩位數的秒數，範圍是 00 到 59。 %b：縮寫形式的月份名稱，例如 Jan。 %B：完整形式的月份名稱，例如 January。 %a：縮寫形式的星期幾名稱，例如 Mon。 %A：完整形式的星期幾名稱，例如 Monday。 %p：AM 或 PM，例如 AM。 在 strptime() 函數中，你可以使用這些格式碼來指定一個字串的時間格式，以便將其轉換為時間物件。例如，如果一個字串的格式是 2022-03-31 14:30:00，那麼可以使用 %Y-%m-%d %H:%M:%S 這個時間格式來將其轉換為一個時間物件。 # Reading from url # ptturl &lt;- &quot;https://github.com/P4CSS/R4CSSData/raw/main/ptt_hang_posts.csv&quot; # raw &lt;- read.csv(url(ptturl)) # read_csv() won&#39;t convert timestamp to POSIXct automatically # raw &lt;- read.csv(&quot;data/ptt_hang_posts.csv&quot;) # clean &lt;- raw %&gt;% # mutate(ptime = as.POSIXct(strptime(ptime, &quot;%Y-%m-%dT%H:%M:%SZ&quot;))) # read_csv() will convert timestamp to POSIXct automatically clean &lt;- read_csv(&quot;data/ptt_hang_posts.csv&quot;) t &lt;- &quot;2019-04-12T00:48:19Z&quot; class(t) ## [1] &quot;character&quot; ?strptime t1 &lt;- strptime(t, &quot;%Y-%m-%dT%H:%M:%SZ&quot;) raw %&gt;% glimpse() ## function (length = 0L) 9.2 Density plot along time 在資料分析的過程中，我們經常需要對資料進行分布分析，以了解資料的特性。ggplot2 套件提供了 geom_density() 函數，可以用來繪製密度圖（density plot）。密度圖顯示了一個連續變量的概率密度函數的近似值，可以用來了解該變量的分佈情況。密度圖與直方圖類似，但它是基於核密度估計方法繪製的，所以在某些情況下可以提供更好的分佈近似。它將一個連續變量區間劃分為若干個小區間，然後對每個小區間的密度進行估計，再將這些小區間的密度估計值連接起來，形成一條平滑曲線，用以描述變量的分佈情況。 在 ggplot2 中，使用 geom_density() 函數可以很方便地繪製密度圖。我們只需要指定變量名稱，即可繪製出該變量的密度圖。此外，我們也可以使用 stat_density() 函數來繪製密度圖，這個函數允許我們對密度圖進行更多的自定義設置，例如指定核函數、調整帶寬等。繪製密度圖可以讓我們更直觀地了解變量的分佈情況，進而對資料進行更深入的分析和探索。 clean %&gt;% ggplot() + aes(ptime) + geom_density() 9.3 Freq by month 如果想要詳細觀察逐年逐月的變化，使用密度圖可能不夠直觀，此時可以考慮使用直方圖來呈現資料。直方圖可以將資料劃分為若干個等寬的區間，並計算每個區間內資料的頻率，然後將這些頻率顯示為長方形柱，以反映資料的分佈情況。對於時間序列資料，我們可以將其劃分為月、週等時間單位，然後計算每個時間單位內資料的出現次數，再使用 ggplot2 中的 geom_col() 函數繪製直方圖。 以上程式碼中，我們使用 mutate() 函數將 ptime 欄位轉換為月份 m，然後使用 count() 函數計算每個月份出現的次數。接著使用 ggplot() 函數初始化一個 ggplot 對象，指定 aes() 函數的 x 軸為月份 m，y 軸為出現次數 n，然後使用 geom_col() 函數繪製直方圖。這樣可以很直觀地看到每個月份資料的出現次數，進而觀察到逐年逐月的變化趨勢。如果需要更詳細的觀察，可以將資料劃分為更小的時間單位，例如週，然後使用類似的方法繪製直方圖。 ?lubridate clean %&gt;% mutate(m = month(ptime)) %&gt;% count(m) %&gt;% ggplot() + aes(m, n) + geom_col() 9.4 Freq-by-date (good) 在處理時間序列資料時，我們常常需要將資料劃分為不同的時間單位，例如月、週、日等，以便進行更精細的分析和視覺化。然而，如果只是單純地提取出時間序列資料中的某一個時間單位，例如月份，就會失去時間軸在年的特性，因此需要採取一些方法來保留日期（如年）的特性。 以上程式碼中，我們使用 filter() 函數選取了時間範圍為 2019 年 3 月 18 日到 4 月 1 日的資料，然後使用 floor_date() 函數將每個時間點取整為當天的起始時間，以保留日期（如年）的特性。這樣可以確保同一天的資料都被歸到同一個時間單位中，進而保留時間軸在年的特性。接著使用 count() 函數計算每個時間單位內資料的出現次數，再使用 ggplot() 函數和 geom_col() 函數繪製直方圖，可以看到在時間軸上的年份特性被保留了下來。 總之，當我們需要從時間序列資料中提取某一個時間單位時，應該採用能夠保留日期（如年）特性的方法，例如使用 floor_date() 函數，以便進行更加精細的分析和視覺化。 clean %&gt;% filter(ptime &gt;= as_date(&quot;2019-03-18&quot;) &amp; ptime &lt; as_date(&quot;2019-04-01&quot;)) %&gt;% mutate(m = floor_date(ptime, unit = &quot;day&quot;)) %&gt;% count(m) %&gt;% ggplot() + aes(m, n) + geom_col() 9.5 Freq-by-hour 透過觀察資料在週末和週間的變化，可以幫助我們了解不同時間段的資料分佈情況。以下是一個範例程式碼，可以根據每天的時間點和文章數來觀察資料在週末和週間的變化。相較於將資料分為週間和週末，這個範例程式碼使用 X 軸作為 24 小時的時間點，而 Y 軸為不同日期的文章量，使用分組的方式，針對不同日期繪製折線圖，最後使用 facet_wrap() 函數將資料分成週末和週間兩個子圖來進行比較。 首先，我們使用 filter() 函數選取時間範圍為 2019 年 3 月 25 日到 4 月 1 日的資料。接著，使用 floor_date() 函數將每個時間點取整為當天的起始時間，以便進行統計。然後，使用 hour() 函數取出每個時間點的小時數，以及使用 count() 函數計算每個時間點和日期的文章數。接著，使用 wday() 函數取出每個日期的星期幾，並使用 ifelse() 函數將週末和週間的日期標記為不同的類別。最後，使用 ggplot() 函數初始化一個 ggplot 對象，指定 aes() 函數的 x 軸為小時數 h，y 軸為文章數 n，以及日期 d 的類別 color。然後，使用 geom_line() 函數繪製折線圖，並使用 facet_wrap() 函數將資料分為週末和週間兩個子圖。 透過這樣的方式，我們可以很清楚地看到週末和週間的文章量變化趨勢，從而對資料進行更深入的分析和探索。 clean %&gt;% filter(ptime &gt;= as_datetime(&quot;2019-03-25&quot;) &amp; ptime &lt; as_datetime(&quot;2019-04-01&quot;)) %&gt;% mutate(d = floor_date(ptime, unit = &quot;day&quot;)) %&gt;% mutate(h = hour(ptime)) %&gt;% count(d, h) %&gt;% mutate(wd = wday(d, label = F, locale = Sys.getlocale(&quot;LC_TIME&quot;))) %&gt;% mutate(isweekend = ifelse(wd &gt;= 6, &quot;weekend&quot;, &quot;weekday&quot;)) %&gt;% ggplot() + aes(h, n, color = as.character(d)) + geom_line() + facet_wrap(~isweekend) ?ifelse "],["na.html", "Chapter 10 NA Processing 10.1 Cleaning Gov Annual Budget 10.2 Case: Vaccinating Proportion by Countries", " Chapter 10 NA Processing 許多統計資料都會有不同程度的NA（缺失值、遺漏值）。缺失值產生的原因不一，可能有以下原因： 資料運算的時候產生的填空值。例如spread()和pivot_wider()經常會產生NA，也經常會指定值（例如0）來取代可能產生的NA。 資料紀錄的時候遺漏某些時間點的資料。 開放資料在開放時已經被整理成階層化、易於展示、一般人易懂的表格型態。此時，若將其讀入也會產生非常大量的NA。例如本章節所要提到的政府各部會預算比例。 紀錄資料筆數非常龐大、來源眾多、紀錄時間不一時，雖然有很多紀錄，但這些紀錄必須要被對齊、刪減，才能夠獲得有意義的可計算資料。例如本章節會提到的世界各國疫苗注射資料。 10.1 Cleaning Gov Annual Budget raw &lt;- readxl::read_excel(&quot;data/111B歲出政事別預算表.xls&quot;, skip=3, col_names = F) raw %&gt;% head(10) ## # A tibble: 10 × 9 ## ...1 ...2 ...3 ...4 ...5 ...6 ...7 ...8 ...9 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 科 … &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 本年… 上年… 前年… &quot;本… ## 2 款 項 目 節 &quot;名 … &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;\\n… 2262… 2135… 2039… &quot;126… ## 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;\\n(… 2101… 2026… 1907… &quot;750… ## 5 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &quot;310… 1210… 1186… 1176… &quot;233… ## 6 &lt;NA&gt; 1 &lt;NA&gt; &lt;NA&gt; &quot;310… 1004… 9789… 9973… &quot;258… ## 7 &lt;NA&gt; &lt;NA&gt; 1 &lt;NA&gt; &quot;310… 9205… 8963… 8821… &quot;241… ## 8 &lt;NA&gt; &lt;NA&gt; 2 &lt;NA&gt; &quot;310… 30000 30000 2999… &quot;-&quot; ## 9 &lt;NA&gt; &lt;NA&gt; 3 &lt;NA&gt; &quot;310… 15760 15760 4557… &quot;-&quot; ## 10 &lt;NA&gt; &lt;NA&gt; 4 &lt;NA&gt; &quot;310… 5332 5332 6720… &quot;-&quot; 10.1.1 Basic Cleaning 重新命名欄位名稱 刪去被當成表格標題的多於列（通常是前兩三列）slice(-(1:2))。 觀察資料，「款」可以說是支出大類的代號，例如總統府、行政支出、立法支出、軍事支出、教育支出等。「科」為該單位底下的部門或者項目，例如「行政支出」下有行政院、主計總處支出等。更底下的細類「目」並非本例的分析對象，所以可以刪除。所以，如果款、科均為空值的話，代表其為更細的「目」。因此篩去款科為空值的所有項目。filter(!is.na(款) | !is.na(科)) 將機構id和機構名稱切分開來，視覺化的時候只會用到機構名稱。separate(機構, c(\"oid\", \"org\"), sep=\"\\n\") names(raw) &lt;- c(&quot;款&quot;, &quot;科&quot;, &quot;目&quot;, &quot;節&quot;, &quot;機構&quot;, &quot;本年度預算&quot;, &quot;上年度預算&quot;, &quot;上年度決算&quot;, &quot;預算差&quot;) cleaned &lt;- raw %&gt;% slice(-(1:2)) %&gt;% filter(!is.na(款) | !is.na(科)) %&gt;% select(-目, -節) %&gt;% separate(機構, c(&quot;oid&quot;, &quot;org&quot;), sep=&quot;\\n&quot;) cleaned %&gt;% head(10) ## # A tibble: 10 × 8 ## 款 科 oid org 本年度預算 上年度預算 上年度…¹ 預算差 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; 3100000000 國務支出 1210301 1186955 1176955… 23346 ## 2 &lt;NA&gt; 1 3102010000 總統府 1004797 978916 997305.… 25881 ## 3 &lt;NA&gt; 2 3102100000 國家安全會議 205504 208039 179649.… -2535 ## 4 2 &lt;NA&gt; 3200000000 行政支出 6134276 5836481 5477154… 297795 ## 5 &lt;NA&gt; 1 3203010000 行政院 1256043 1286646 1268295… -30603 ## 6 &lt;NA&gt; 2 3203100000 主計總處 1604967 1478173 1578781… 126794 ## 7 &lt;NA&gt; 3 3203300000 人事行政總處 555363 573447 489516.… -18084 ## 8 &lt;NA&gt; 4 3203340000 公務人力發展學院 244346 239453 229852.… 4893 ## 9 &lt;NA&gt; 5 3203420000 檔案管理局 787429 646081 443133.… 141348 ## 10 &lt;NA&gt; 6 3203900000 大陸委員會 900896 900866 792491.… 30 ## # … with abbreviated variable name ¹​上年度決算 10.1.2 Processing NA 觀察一下現在的資料，發現，行政院、主計總處等均屬於行政支出，但行政支出卻自有一列。依照長表格的格式來說，應嘗試把「款」作為機構的變項。所以將款的數字取代為「行政支出」等支出類別的名稱。 cleaned %&gt;% mutate(款 = ifelse(!is.na(款), org, 款)) %&gt;% head(10) ## # A tibble: 10 × 8 ## 款 科 oid org 本年度預算 上年度…¹ 上年…² 預算差 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 國務支出 &lt;NA&gt; 3100000000 國務支出 1210301 1186955 117695… 23346 ## 2 &lt;NA&gt; 1 3102010000 總統府 1004797 978916 997305… 25881 ## 3 &lt;NA&gt; 2 3102100000 國家安全會議 205504 208039 179649… -2535 ## 4 行政支出 &lt;NA&gt; 3200000000 行政支出 6134276 5836481 547715… 297795 ## 5 &lt;NA&gt; 1 3203010000 行政院 1256043 1286646 126829… -30603 ## 6 &lt;NA&gt; 2 3203100000 主計總處 1604967 1478173 157878… 126794 ## 7 &lt;NA&gt; 3 3203300000 人事行政總處 555363 573447 489516… -18084 ## 8 &lt;NA&gt; 4 3203340000 公務人力發展學院 244346 239453 229852… 4893 ## 9 &lt;NA&gt; 5 3203420000 檔案管理局 787429 646081 443133… 141348 ## 10 &lt;NA&gt; 6 3203900000 大陸委員會 900896 900866 792491… 30 ## # … with abbreviated variable names ¹​上年度預算, ²​上年度決算 接下來，希望能夠在「款==NA」的地方填入該欄的「前一個值」例如行政支出。查詢一下（關鍵字如「Fill in NA column values with the last value that was not NA」）還真的有這樣的函式可以操作。 library(zoo) cleaned %&gt;% mutate(款 = ifelse(!is.na(款), org, 款)) %&gt;% mutate(款 = zoo::na.locf(款)) %&gt;% head(10) ## # A tibble: 10 × 8 ## 款 科 oid org 本年度預算 上年度…¹ 上年…² 預算差 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 國務支出 &lt;NA&gt; 3100000000 國務支出 1210301 1186955 117695… 23346 ## 2 國務支出 1 3102010000 總統府 1004797 978916 997305… 25881 ## 3 國務支出 2 3102100000 國家安全會議 205504 208039 179649… -2535 ## 4 行政支出 &lt;NA&gt; 3200000000 行政支出 6134276 5836481 547715… 297795 ## 5 行政支出 1 3203010000 行政院 1256043 1286646 126829… -30603 ## 6 行政支出 2 3203100000 主計總處 1604967 1478173 157878… 126794 ## 7 行政支出 3 3203300000 人事行政總處 555363 573447 489516… -18084 ## 8 行政支出 4 3203340000 公務人力發展學院 244346 239453 229852… 4893 ## 9 行政支出 5 3203420000 檔案管理局 787429 646081 443133… 141348 ## 10 行政支出 6 3203900000 大陸委員會 900896 900866 792491… 30 ## # … with abbreviated variable names ¹​上年度預算, ²​上年度決算 太神奇了！看見沒！接下來只要把「科 is NA」的那些該大類支出總數的紀錄給刪除，資料就乾淨了。最後就只會剩下一些資料清理的功伕。完整程式碼可以看下一節。 10.1.3 Complete Code library(zoo) # raw &lt;- readxl::read_excel(&quot;data/111B歲出政事別預算總表.xls&quot;) raw &lt;- readxl::read_excel(&quot;data/111B歲出政事別預算表.xls&quot;, skip=3, col_names = F) names(raw) &lt;- c(&quot;款&quot;, &quot;科&quot;, &quot;目&quot;, &quot;節&quot;, &quot;機構&quot;, &quot;本年度預算&quot;, &quot;上年度預算&quot;, &quot;上年度決算&quot;, &quot;預算差&quot;) # raw$款 &lt;- na.locf(raw$款) cleaned &lt;- raw %&gt;% filter(!is.na(款) | !is.na(科)) %&gt;% slice(-(1:2)) %&gt;% select(-目, -節) %&gt;% separate(機構, c(&quot;oid&quot;, &quot;org&quot;), sep=&quot;\\n&quot;) %&gt;% mutate(款 = ifelse(!is.na(款), org, 款)) %&gt;% mutate(款 = zoo::na.locf(款)) %&gt;% filter(!is.na(科)) %&gt;% select(-科) %&gt;% type_convert() %&gt;% mutate(上年度預算 = as.numeric(上年度預算), 上年度決算 = as.integer(上年度決算), 預算差 = as.numeric(預算差)) %&gt;% replace_na(list(上年度預算 = 0, 上年度決算 = 0)) %&gt;% mutate(預算差 = 本年度預算 - 上年度預算) 10.2 Case: Vaccinating Proportion by Countries https://ourworldindata.org/covid-vaccinations - https://github.com/owid/covid-19-data/tree/master/public/data/vaccinations 評估資料概況後可發現這個資料集每一列就是某一個國家某一天所上傳的紀錄。所以，一個國家會有很多列。乍聽之下不難處理，但事實上每個國家不會每天上傳、也不會固定某一天上傳、哪一週、哪一個月開始上傳也不一定，也有可能會漏掉一些月份或週次。所以，制定出一個時間單位（例如週、月）、然後延著時間軸將資料「對齊」，讓每個國家在每個時間單位都有資料。但每個國家疫情發展程度不一，所以也不可能有一個完美的對齊，所以通常會建議就所要觀察的國家進行對齊即可。至於想刪除的那些資料列，幾乎都可以當成是所謂的缺失值。 raw &lt;- read_csv(&quot;data/vaccinations.csv&quot;) dim(raw) ## [1] 99442 16 raw %&gt;% head(20) ## # A tibble: 20 × 16 ## location iso_c…¹ date total…² peopl…³ peopl…⁴ total…⁵ daily…⁶ daily…⁷ ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanist… AFG 2021-02-22 0 0 NA NA NA NA ## 2 Afghanist… AFG 2021-02-23 NA NA NA NA NA 1367 ## 3 Afghanist… AFG 2021-02-24 NA NA NA NA NA 1367 ## 4 Afghanist… AFG 2021-02-25 NA NA NA NA NA 1367 ## 5 Afghanist… AFG 2021-02-26 NA NA NA NA NA 1367 ## 6 Afghanist… AFG 2021-02-27 NA NA NA NA NA 1367 ## 7 Afghanist… AFG 2021-02-28 8200 8200 NA NA NA 1367 ## 8 Afghanist… AFG 2021-03-01 NA NA NA NA NA 1580 ## 9 Afghanist… AFG 2021-03-02 NA NA NA NA NA 1794 ## 10 Afghanist… AFG 2021-03-03 NA NA NA NA NA 2008 ## 11 Afghanist… AFG 2021-03-04 NA NA NA NA NA 2221 ## 12 Afghanist… AFG 2021-03-05 NA NA NA NA NA 2435 ## 13 Afghanist… AFG 2021-03-06 NA NA NA NA NA 2649 ## 14 Afghanist… AFG 2021-03-07 NA NA NA NA NA 2862 ## 15 Afghanist… AFG 2021-03-08 NA NA NA NA NA 2862 ## 16 Afghanist… AFG 2021-03-09 NA NA NA NA NA 2862 ## 17 Afghanist… AFG 2021-03-10 NA NA NA NA NA 2862 ## 18 Afghanist… AFG 2021-03-11 NA NA NA NA NA 2862 ## 19 Afghanist… AFG 2021-03-12 NA NA NA NA NA 2862 ## 20 Afghanist… AFG 2021-03-13 NA NA NA NA NA 2862 ## # … with 7 more variables: total_vaccinations_per_hundred &lt;dbl&gt;, ## # people_vaccinated_per_hundred &lt;dbl&gt;, ## # people_fully_vaccinated_per_hundred &lt;dbl&gt;, ## # total_boosters_per_hundred &lt;dbl&gt;, daily_vaccinations_per_million &lt;dbl&gt;, ## # daily_people_vaccinated &lt;dbl&gt;, daily_people_vaccinated_per_hundred &lt;dbl&gt;, ## # and abbreviated variable names ¹​iso_code, ²​total_vaccinations, ## # ³​people_vaccinated, ⁴​people_fully_vaccinated, ⁵​total_boosters, … 10.2.1 按月對齊資料 首先要挑選要拿來做視覺化的資料欄位。這邊所選擇的是people_fully_vaccinated_per_hundred，也就是每百人接種二劑疫苗的人數，相當於接種二劑疫苗的百分比。 接下來便是空值處理，如果這個欄位沒有數值的就直接用drop_na()篩除即可。 這個範例希望把該資料視覺化為Y軸為年、X軸為時間的熱區圖。但整個疫情資料橫亙二年多，如果以週為彙整單位的話，那勢必X軸會有近百個資料點。所以打算以「月」為單位來彙整這些資料，因為且資料中也有不少國家缺數週的資料，所以以月為彙整單位是一個權衡後的選擇（仍可以嘗試用週作為彙整單位試試看）。所以，運用了lubridate::floor_date()來將日期資料轉換為月，例如2022-03-12和2022-03-14都會被轉換為2022-03-01。 依照國家與時間群組彙整資料。接下來就依照各國的月份來做彙整（注意，此時會有不少資料同屬於某個月的資料）。彙整的方法是，經過對「日期」（不是對月）做排序後，僅留下第一筆資料，也就是僅留下最接近月份開頭的資料。經由這樣的操作，會使得各國在每個月剛好留下一筆資料，如下面程式的範例輸出。 library(lubridate) fullvaccinated &lt;- raw %&gt;% select(country = location, date, people_fully_vaccinated_per_hundred) %&gt;% drop_na(people_fully_vaccinated_per_hundred) %&gt;% mutate(m = floor_date(date, unit = &quot;month&quot;)) %&gt;% group_by(country, m) %&gt;% arrange(date) %&gt;% slice(1) %&gt;% ungroup() %&gt;% select(-date) fullvaccinated %&gt;% head(10) ## # A tibble: 10 × 3 ## country people_fully_vaccinated_per_hundred m ## &lt;chr&gt; &lt;dbl&gt; &lt;date&gt; ## 1 Afghanistan 0.14 2021-05-01 ## 2 Afghanistan 0.36 2021-06-01 ## 3 Afghanistan 0.48 2021-07-01 ## 4 Afghanistan 1.08 2021-08-01 ## 5 Afghanistan 8 2021-11-01 ## 6 Afghanistan 9.42 2021-12-01 ## 7 Afghanistan 9.56 2022-01-01 ## 8 Afghanistan 9.82 2022-02-01 ## 9 Afghanistan 10.8 2022-03-01 ## 10 Afghanistan 11.4 2022-04-01 10.2.2 處理遺漏資料的月份 接下來要處理的是資料紀錄的缺漏值。每個國家登錄資料的時間是很不一致的，某些國家會缺某些月份，或者某些國家是在某年某月以後才開始登記，或者最近沒在登記。但這個範例所要視覺化的資料是接種疫苗的比例，所以即使是現在沒在登記了，但接種比例應列計最後一次資料紀錄的接種比例。 首先我要讓每個國家都有所有月份，這裡應會有某個函式可以做到這件事，但我沒查到這個函式。不過我可以很技巧性地用pivot_wider()（spread()）和pivot_longer()（gather()）來完成這件事。spread()在展開時對於缺少的資料項可以自動補NA。所以我就只要把資料的月份展開後再gather()回來後，就可以自動讓每個國家所擁有的月份資料一致。以下為spread()後的結果，可以觀察到每一列是一個國家，每一欄是個月份，如果當月都沒資料紀錄，那該月的值就會是空值。可以看見空值是相當多的，也就是在那段時間都沒有資料紀錄。 fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% head(10) ## # A tibble: 10 × 19 ## country 2020-…¹ 2021-…² 2021-…³ 2021-…⁴ 2021-…⁵ 2021-…⁶ 2021-…⁷ 2021-…⁸ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan NA NA NA NA NA 0.14 0.36 0.48 ## 2 Africa NA NA 0 0.02 0.3 0.36 0.63 1.15 ## 3 Albania NA NA 0 NA NA 6.32 10.2 14.2 ## 4 Algeria NA NA NA NA NA NA NA NA ## 5 Andorra NA NA NA 1.52 5.8 6.07 14.1 34.9 ## 6 Angola NA NA NA NA NA 0.12 1.11 1.66 ## 7 Anguilla NA NA NA NA 5.18 29.2 36.4 47.3 ## 8 Antigua and … NA NA NA NA NA 2.61 18.4 28.2 ## 9 Argentina 0 0 0.26 0.69 1.56 2.24 6.68 9.71 ## 10 Armenia NA NA NA NA NA NA 0.4 1.03 ## # … with 10 more variables: `2021-08-01` &lt;dbl&gt;, `2021-09-01` &lt;dbl&gt;, ## # `2021-10-01` &lt;dbl&gt;, `2021-11-01` &lt;dbl&gt;, `2021-12-01` &lt;dbl&gt;, ## # `2022-01-01` &lt;dbl&gt;, `2022-02-01` &lt;dbl&gt;, `2022-03-01` &lt;dbl&gt;, ## # `2022-04-01` &lt;dbl&gt;, `2022-05-01` &lt;dbl&gt;, and abbreviated variable names ## # ¹​`2020-12-01`, ²​`2021-01-01`, ³​`2021-02-01`, ⁴​`2021-03-01`, ⁵​`2021-04-01`, ## # ⁶​`2021-05-01`, ⁷​`2021-06-01`, ⁸​`2021-07-01` 在以下的範例輸出可以看到gather()後的結果。注意，需要照國家和月份來排序後才便於觀察。 fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% gather(month, perc, -country) %&gt;% arrange(country, month) %&gt;% head(20) ## # A tibble: 20 × 3 ## country month perc ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-12-01 NA ## 2 Afghanistan 2021-01-01 NA ## 3 Afghanistan 2021-02-01 NA ## 4 Afghanistan 2021-03-01 NA ## 5 Afghanistan 2021-04-01 NA ## 6 Afghanistan 2021-05-01 0.14 ## 7 Afghanistan 2021-06-01 0.36 ## 8 Afghanistan 2021-07-01 0.48 ## 9 Afghanistan 2021-08-01 1.08 ## 10 Afghanistan 2021-09-01 NA ## 11 Afghanistan 2021-10-01 NA ## 12 Afghanistan 2021-11-01 8 ## 13 Afghanistan 2021-12-01 9.42 ## 14 Afghanistan 2022-01-01 9.56 ## 15 Afghanistan 2022-02-01 9.82 ## 16 Afghanistan 2022-03-01 10.8 ## 17 Afghanistan 2022-04-01 11.4 ## 18 Afghanistan 2022-05-01 NA ## 19 Africa 2020-12-01 NA ## 20 Africa 2021-01-01 NA 接下來是最技巧性的部分。就接種比例而言是個遞增數列，所以如果這個月有紀錄，但下個月沒紀錄（NA），那下個月的資料應以這個月的資料來替代。此時可以用zoo套件的na.locf()來填NA值，其填NA值的規則是用最後一筆非NA值的資料來替代NA值。但要注意的是，因為資料紀錄可能到第六個月或第七個月才開始紀錄，但在前面的月份都沒資料紀錄，也就是說那些NA值沒有更早的資料紀錄權充填充值。原本na.locf()會把這些找不到參考對象的NA值直接刪除，但我們可以在裡面加一個參數使其不會被刪除（na.locf(perc, na.rm = F)）。 最後，就把這些沒被刪除也沒得參考的早期資料項，用replace_na()填上0即可。 fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% gather(month, perc, -country) %&gt;% arrange(country, month) %&gt;% group_by(country) %&gt;% arrange(month) %&gt;% mutate(perc = zoo::na.locf(perc, na.rm = F)) %&gt;% ungroup() %&gt;% arrange(country, month) %&gt;% head(10) ## # A tibble: 10 × 3 ## country month perc ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-12-01 NA ## 2 Afghanistan 2021-01-01 NA ## 3 Afghanistan 2021-02-01 NA ## 4 Afghanistan 2021-03-01 NA ## 5 Afghanistan 2021-04-01 NA ## 6 Afghanistan 2021-05-01 0.14 ## 7 Afghanistan 2021-06-01 0.36 ## 8 Afghanistan 2021-07-01 0.48 ## 9 Afghanistan 2021-08-01 1.08 ## 10 Afghanistan 2021-09-01 1.08 最後，就把這些沒被刪除也沒得參考的早期資料項，用replace_na()填上0即可。大功告成。 fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% gather(month, perc, -country) %&gt;% arrange(country, month) %&gt;% group_by(country) %&gt;% arrange(month) %&gt;% mutate(perc = zoo::na.locf(perc, na.rm = F)) %&gt;% ungroup() %&gt;% arrange(country, month) %&gt;% replace_na(list(perc=0)) %&gt;% arrange(country, month) %&gt;% head(10) ## # A tibble: 10 × 3 ## country month perc ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan 2020-12-01 0 ## 2 Afghanistan 2021-01-01 0 ## 3 Afghanistan 2021-02-01 0 ## 4 Afghanistan 2021-03-01 0 ## 5 Afghanistan 2021-04-01 0 ## 6 Afghanistan 2021-05-01 0.14 ## 7 Afghanistan 2021-06-01 0.36 ## 8 Afghanistan 2021-07-01 0.48 ## 9 Afghanistan 2021-08-01 1.08 ## 10 Afghanistan 2021-09-01 1.08 10.2.3 完整程式碼 library(lubridate) raw &lt;- read_csv(&quot;data/vaccinations.csv&quot;) fullvaccinated &lt;- raw %&gt;% select(country = location, date, people_fully_vaccinated_per_hundred) %&gt;% drop_na(people_fully_vaccinated_per_hundred) %&gt;% mutate(m = floor_date(date, unit = &quot;month&quot;)) %&gt;% group_by(country, m) %&gt;% arrange(date) %&gt;% slice(1) %&gt;% ungroup() %&gt;% select(-date) vperc_by_month &lt;- fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% gather(month, perc, -country) %&gt;% arrange(country, month) %&gt;% group_by(country) %&gt;% arrange(month) %&gt;% mutate(perc = zoo::na.locf(perc, na.rm = F)) %&gt;% ungroup() %&gt;% arrange(country, month) %&gt;% replace_na(list(perc=0)) "],["text-processing.html", "Chapter 11 Text Processing", " Chapter 11 Text Processing "],["trumps-tweets.html", "Chapter 12 Trump’s tweets 12.1 Loading data 12.2 Cleaning data 12.3 Visual Exploring 12.4 Keyness", " Chapter 12 Trump’s tweets 本範例取材自David Robinson的blog文章「Text analysis of Trump’s tweets confirms he writes only the (angrier) Android half」。David Robinson是「Text Mining with R」的共同作者， 可參考該書籍上的範例「7 Case study: comparing Twitter archives | Text Mining with R (tidytextmining.com)」。 這篇文章探討了美國前總統川普（Donald Trump）的推特帳號。有一個假設聲稱，當川普在推特上祝福奧運會選手好運時，他使用的是 iPhone ；當他侮辱競爭對手時，他通常是用 Android 來發推。文章作者想要透過數據分析來探討這個假設的真實性。 作者使用了文字探勘和情感分析等技術，從川普的推特內容入手，分析了不同時間和使用不同手機所發的推文。結果顯示，Android 和 iPhone 所發的推文顯然是由不同的人所發，他們在使用標籤、連結和轉推的方式上也不同。此外，Android 的推文更加憤怒和負面，而 iPhone 的推文則傾向於發佈善意的公告和圖片。整體而言，這些分析讓我們能夠區分出競選團隊所發佈的推文（iPhone）和川普自己所發佈的推文（Android）。 這個教學案例涵蓋了使用 R 語言進行社群輿論資料（tweets）的探索性分析的各種技術和工具。除了使用常見的資料處理套件 dplyr 和視覺化套件 ggplot 外，還使用了文字處理套件 stringr 和時間處理套件 lubridate，以及關鍵字分析技術 keyness。 透過這個教學案例，學習者可以掌握如何： 使用 dplyr 和 ggplot 進行資料處理和視覺化。 使用 stringr 和 extract() 進行文字處理，例如從文本中提取關鍵字。 使用 lubridate 進行時間處理，例如轉換時間格式和提取時間戳記。 學習關鍵字分析技術 keyness，以找出在不同文本之間對彼此相對突出的關鍵字。 這段程式碼是用來設計 ggplot2 的主題風格。作者首先定義了一個名為 th 的自訂主題，基於 ggplot2 的 theme_minimal() 主題，並設置了不同元素的字型、大小和樣式等屬性。接著，作者定義了一個名為 new_style() 的函數，用於更精細的主題風格設置，包括圖表標題、圖例、軸標籤和刻度標籤等。透過這些設置，可以讓 ggplot2 圖表更具有視覺吸引力，並強調重要的圖形元素，使圖表更加清晰易懂。這兩種方式都可以用來定義主題 library(tidyverse) # library(lubridate) # has been included in tidyverse options(scipen = 999) # Self-designed theme th &lt;- theme_minimal() + theme(plot.title = element_text(size=24, face=&quot;bold&quot;), legend.title = element_text(size=18, face=&quot;bold&quot;), legend.text = element_text(size=18), axis.title = element_text(hjust=0.5, size=18, face=&quot;italic&quot;), axis.text = element_text(size=18) ) # more settings new_style &lt;- function() { font &lt;- &quot;Helvetica&quot; theme( plot.title = element_text(family=font, size=28, face=&quot;bold&quot;), plot.subtitle = element_text(family=font, size=22, margin=margin(9,0,9,0)), plot.caption = element_blank(), legend.position = &quot;top&quot;, legend.text.align = 0, legend.background = element_blank(), # legend.title = element_blank(), legend.key = element_blank(), legend.text = element_text(family=font, size=18, color=&quot;#222222&quot;), axis.text = element_text(family=font, size=18, color=&quot;#222222&quot;), axis.text.x = element_text(margin=margin(5, b = 10)), axis.ticks = element_blank(), axis.line = element_blank(), panel.grid.minor = element_blank(), panel.grid.major.y = element_line(color=&quot;#cbcbcb&quot;), panel.grid.major.x = element_blank(), panel.background = element_blank(), strip.background = element_rect(fill=&quot;white&quot;), strip.text = element_text(size = 22, hjust = 0) ) } 12.1 Loading data load(url(&quot;http://varianceexplained.org/files/trump_tweets_df.rda&quot;)) dim(trump_tweets_df) ## [1] 1512 16 names(trump_tweets_df) ## [1] &quot;text&quot; &quot;favorited&quot; &quot;favoriteCount&quot; &quot;replyToSN&quot; ## [5] &quot;created&quot; &quot;truncated&quot; &quot;replyToSID&quot; &quot;id&quot; ## [9] &quot;replyToUID&quot; &quot;statusSource&quot; &quot;screenName&quot; &quot;retweetCount&quot; ## [13] &quot;isRetweet&quot; &quot;retweeted&quot; &quot;longitude&quot; &quot;latitude&quot; trump_tweets_df %&gt;% select(id, text, created, favoriteCount, retweetCount, statusSource) %&gt;% head(10) ## # A tibble: 10 × 6 ## id text created favor…¹ retwe…² statu…³ ## &lt;chr&gt; &lt;chr&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 762669882571980801 &quot;My economic … 2016-08-08 15:20:44 9214 3107 &quot;&lt;a hr… ## 2 762641595439190016 &quot;Join me in F… 2016-08-08 13:28:20 6981 2390 &quot;&lt;a hr… ## 3 762439658911338496 &quot;#ICYMI: \\&quot;Wi… 2016-08-08 00:05:54 15724 6691 &quot;&lt;a hr… ## 4 762425371874557952 &quot;Michael More… 2016-08-07 23:09:08 19837 6402 &quot;&lt;a hr… ## 5 762400869858115588 &quot;The media is… 2016-08-07 21:31:46 34051 11717 &quot;&lt;a hr… ## 6 762284533341417472 &quot;I see where … 2016-08-07 13:49:29 29831 9892 &quot;&lt;a hr… ## 7 762110918721310721 &quot;Thank you Wi… 2016-08-07 02:19:37 19223 5784 &quot;&lt;a hr… ## 8 762106904436961280 &quot;.@Larry_Kudl… 2016-08-07 02:03:39 19543 7930 &quot;&lt;a hr… ## 9 762104411707568128 &quot;I am not jus… 2016-08-07 01:53:45 75488 24663 &quot;&lt;a hr… ## 10 762016426102296576 &quot;#CrookedHill… 2016-08-06 20:04:08 23661 7903 &quot;&lt;a hr… ## # … with abbreviated variable names ¹​favoriteCount, ²​retweetCount, ## # ³​statusSource 12.2 Cleaning data 這段程式碼的目的是從一個叫做trump_tweets_df的data.frame中，選擇幾個欄位並且進行過濾和轉換，最後將結果存儲在一個名為tweets的新data.frame中。 extract()函數用於從statusSource欄位中提取出一個新欄位source，該欄位包含了statusSource中的Twitter for iPhone和Twitter for Android這兩種可能的字串。這裡使用了一個正則表達式Twitter for (.*?)&lt;，該表達式表示提取出以Twitter for開頭，且在&lt;符號之前的任意字元序列，並將結果存儲在名為source的新欄位中。 最後，filter()函數用於過濾出source欄位中值為iPhone或Android的記錄，並將過濾結果存儲在tweets資料框中。 # tidyr::extract() # stringr::str_replace trump_tweets_df$statusSource[1] ## [1] &quot;&lt;a href=\\&quot;http://twitter.com/download/android\\&quot; rel=\\&quot;nofollow\\&quot;&gt;Twitter for Android&lt;/a&gt;&quot; tweets &lt;- trump_tweets_df %&gt;% select(id, statusSource, text, created) %&gt;% # mutate(source = str_replace(statusSource, # &quot;.*Twitter for (.*?)&lt;.*&quot;, &quot;\\\\1&quot;)) %&gt;% # mutate(source = str_extract(statusSource, &#39;Twitter for (.*?)&lt;&#39;)) %&gt;% View extract(statusSource, &quot;source&quot;, &quot;Twitter for (.*?)&lt;&quot;) %&gt;% filter(source %in% c(&quot;iPhone&quot;, &quot;Android&quot;)) # Using stringr::str_replace() to mutate a new source variable, replacing tidyr:: # str(tweets) Practice. 有時候我們會希望避免用太多種套件來寫程式，例如上面的extract()便屬於tidyr的函式。事實上我們可以用stringr::str_replace()來達到這個目的。嘗試寫寫看？或者嘗試問ChatGPT看看？ Prompt. 我如果希望用stringr::str_replace來達到extract(statusSource, \"source\", \"Twitter for (.*?)&lt;\") %&gt;%的功能，我該怎麼寫？ mutate(source = stringr::str_replace(statusSource, \".*Twitter for (.*?)&lt;.*\", \"\\\\1\")) %&gt;% 12.3 Visual Exploring 12.3.1 Productivity by time hour = hour(with_tz(created, \"EST\"))這段程式碼使用了with_tz()函數將created欄位的時區轉換為\"EST\"所對應的時區，然後使用hour()函數提取出該日期時間對應的小時數，並將結果存儲在hour變數中。該程式碼會將例如\"2023-04-12 12:30:00\"轉換為美國東部標準時間對應的小時數，即12（因為12點30分所在的小時是12點）。他所取出的並非某日的12時，他就只是取出是12時。 toplot1和toplot2的差異在於對source欄位的分組處理不同。具體來說，toplot1中沒有對source欄位進行分組，而是在後面使用mutate()函數將計數結果中的n列和sum(n)相除，得到了百分比列percent。這導致計算的是整個資料集中的hour和source的計數和百分比。相反，toplot2中使用了group_by()函數將source欄位進行分組處理，並在後面使用mutate()函數和ungroup()函數計算了每個source和hour的計數和百分比，即分別計算了iPhone和Android的計數和百分比。因此，toplot1和toplot2的計算結果是不同的，前者的計算結果中包含了整個資料集的計數和百分比，而後者的計算結果則分別對iPhone和Android進行了計數和百分比的計算。 程式碼使用了ggplot()函數創建了一個ggplot2物件，並使用aes()函數設置了hour和percent欄位作為X軸和Y軸的變數，並且設置color = source表示以source欄位的值作為不同群組（iPhone vs. Android）折線的顏色。接著，程式碼使用geom_line()函數添加折線到圖中，設置了折線的粗細為1。使用scale_color_manual()函數設置了圖例的名稱為Phone System，標籤依照分組指定為為Android和iPhone，顏色分別為royalblue和gold，並使用scale_y_continuous()函數設置了Y軸刻度標籤的格式為百分比形式，即0%到100%之間的數值。注意：percent_format()並非ggplot2既有的函式，要另外安裝並匯入library(scales)。 library(scales) # for percent_format() # lubridate::hour() # lubridate::with_tz() # scales::percent_format() toplot1 &lt;- tweets %&gt;% count(source, hour = hour(with_tz(created, &quot;EST&quot;))) %&gt;% # group_by(source) %&gt;% mutate(percent = n / sum(n)) # ungroup() %&gt;% toplot2 &lt;- tweets %&gt;% count(source, hour = hour(with_tz(created, &quot;EST&quot;))) %&gt;% group_by(source) %&gt;% mutate(percent = n / sum(n)) %&gt;% ungroup() p1 &lt;- toplot1 %&gt;% ggplot() + aes(hour, percent, color = source) + geom_line(linewidth = 1) + scale_color_manual(name = &quot;Phone System&quot;, labels = c(&quot;Android&quot;, &quot;iPhone&quot;), values = c(&quot;royalblue&quot;, &quot;gold&quot;)) + scale_y_continuous(labels = percent_format()) + labs(x = &quot;Hour of day (EST)&quot;, y = &quot;% of tweets&quot;, color = &quot;&quot;) + theme_minimal() p2 &lt;- toplot2 %&gt;% ggplot() + aes(hour, percent, color = source) + geom_line(linewidth = 1) + scale_color_manual(name = &quot;Phone System&quot;, labels = c(&quot;Android&quot;, &quot;iPhone&quot;), values = c(&quot;royalblue&quot;, &quot;gold&quot;)) + scale_y_continuous(labels = percent_format()) + labs(x = &quot;Hour of day (EST)&quot;, y = &quot;% of tweets&quot;, color = &quot;&quot;) + theme_minimal() cowplot::plot_grid( p1, NULL, p2, labels = c(&quot;(a) Normalized by all&quot;, &quot;&quot;, &quot;(b) Normalized in group&quot;), nrow = 1, rel_widths = c(1, 0.1, 1) ) 12.3.2 Tweeting with figures 首先，filter()函數用於從tweets資料框中過濾出不以\"字符開頭的推文，即過濾掉引號開頭的推文。這裡使用了!str_detect(text, '^\"')表示將text欄位中以\"字符開頭的推文過濾掉，即保留那些不以引號開頭的推文。'^\"'是一個正規表示式（Regular Expression），'^'符號代表字串的開頭。 接著，mutate()函數用於在tweets資料框中添加一個新欄位picture，該欄位根據推文中是否包含t.co字串來判斷推文中是否包含圖片或者連結。具體來說，這裡使用了if_else()函數，如果text欄位中包含t.co字串，則將picture欄位設置為\"Picture/link\"，否則設置為\"No picture/link\"。 最後，使用count()函數計算tweets資料框中每個source和picture的記錄數，並將結果存儲在toplot資料框中。最終的結果是一個展示tweets資料框中source和picture的記錄數的資料框，其中picture欄位表示推文中是否包含圖片或連結。 p1和p2的主要區別在於barplot的呈現方式不同。具體來說： p1中使用了position=\"stack\"的參數，表示將不同分組的bar疊加在一起，以展示每個source的總推文數量，並且bar的寬度設置為0.5（使用width參數），使得bar之間有一定的間隔。這種方式可以方便地比較不同source的總推文數量，並且可以看到每個source中有多少推文包含圖片或連結。 p2中使用了position=\"dodge\"的參數，表示將不同分組的bar並排放置，以便比較不同source中包含或不包含圖片或連結的推文數量。這種方式可以顯示出每個source中有多少推文包含或不包含圖片或連結，並且可以清楚地比較不同source之間的差異。 toplot &lt;- tweets %&gt;% filter(!str_detect(text, &#39;^&quot;&#39;)) %&gt;% mutate(picture = if_else(str_detect(text, &quot;t.co&quot;), &quot;Picture/link&quot;, &quot;No picture/link&quot;)) %&gt;% count(source, picture) p1 &lt;- toplot %&gt;% ggplot() + aes(source, n, fill = picture) + geom_col(position=&quot;stack&quot;, width = 0.5) + scale_fill_manual(name = &quot;With Picture/link?&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;), values = c(&quot;gold&quot;, &quot;royalblue&quot;)) + labs(x = &quot;&quot;, y = &quot;Number of tweets&quot;, fill = &quot;&quot;) + theme_minimal() p2 &lt;- toplot %&gt;% ggplot() + aes(source, n, fill = picture) + geom_col(position=&quot;dodge&quot;) + scale_fill_manual(name = &quot;With Picture/link?&quot;, labels = c(&quot;No&quot;, &quot;Yes&quot;), values = c(&quot;gold&quot;, &quot;royalblue&quot;)) + labs(x = &quot;&quot;, y = &quot;Number of tweets&quot;, fill = &quot;&quot;) + theme_minimal() cowplot::plot_grid( p1, NULL, p2, labels = c(&quot;(a) Stacked&quot;, &quot;&quot;, &quot;(b) Dodged&quot;), nrow = 1, rel_widths = c(1, 0.1, 1) ) 12.4 Keyness Keyness是一種文本分析方法，用於比較兩個文本集合中某些詞彙的使用頻率（例如我們要比較用iPhone和Android兩支手機所發表的內容是否有文字上的差異），以評估這些詞彙在不同文本集合中的重要性或關鍵程度。Keyness分析通常用於比較兩個文本集合，其中一個是目標文本集合，另一個是參照文本集合，並且通常會將這些文本集合中的單詞或詞彙按照出現頻率排序。 使用filter()函數過濾出不以\"字符開頭的推文，即過濾掉引號開頭的推文，將結果存儲在tweets資料框中。 使用mutate()函數將推文中的URL和&amp;amp;字符替換為空白字符，即將推文中的網址和HTML實體轉換為正常的字符，方便後續的文本處理。 使用mutate()函數將tweets資料框中的text欄位拆分為單詞序列，存儲在word欄位中。這裡使用了str_split()函數將每個推文按照空格進行拆分，得到一個由單詞序列組成的列表，然後將這個列表存儲在word欄位中。 使用select()函數選擇需要的欄位，包括tweets資料框中的id、text和word欄位，以及tweets資料框中的所有其他欄位。 使用unnest()函數將word欄位中的單詞序列展開成一個單詞資料框，每個單詞對應一行記錄。 使用filter()函數過濾掉停用詞和非英文字符，其中停用詞（stop words）列表存儲在stop_words資料框中，通過!word %in% stop_words$word條件過濾掉停用詞，並且通過str_detect(word, \"[a-z]\")條件過濾掉不包含英文字母的單詞。最終，將結果存儲在tweets資料框中。 停用詞（stop words）指的是在文本中出現頻率非常高，但對於文本的內容和意義貢獻不大的詞彙。這些詞彙通常是一些常見的介詞、連詞、代詞、冠詞、助動詞等，例如”the”、“and”、“a”、“in”等。在文本分析中，停用詞通常被過濾掉，以便更好地捕捉文本中的主題和意義。在中文文本分析中，常見的停用詞包括一些虛詞、代詞、介詞、助詞等，例如”的”、“是”、“在”、“和”、“了”、“一”等。這些詞在中文文本中出現的頻率非常高，但對於文本的內容和意義貢獻不大，因此在文本分析中通常被過濾掉。 停用詞的列表通常是由人為構建的，根據具體的文本分析任務和文本的特徵來決定。在自然語言處理中，通常會使用預先定義好的停用詞列表，例如英文中的NLTK（Natural Language Toolkit）庫中就包含了一個預先定義好的停用詞列表。 在進行文本分析時，過濾掉停用詞可以幫助減少文本資料的雜訊和冗余訊息，提高分析的準確性和效率。但是，在某些特定的文本分析任務中，停用詞可能具有一定的重要性，例如情感分析中的否定詞（如”not”）可能對情感分析的結果產生重要的影響，因此需要特殊處理。如果進行的是網絡舆情分析，那麼一些特定的網絡用語和表情符號可能也需要被加入停用詞列表中，以避免對分析結果產生干擾。 unnest_tokens()和mutate()函數都可以用於將文本data.frame中的文本數據進行分詞處理，但它們的實現方式有所不同。mutate()函數使用str_split()函數將每個文本按照指定的分隔符（如上述程式碼即以空白\" \"做為分隔符號）進行拆分，得到一個由單詞序列組成的list。這樣做的缺點是無法同時將文本中的標點符號、空格、停用詞等過濾掉，因此在進行文本分析時需要額外進行過濾處理。 unnest_tokens()函數則使用更靈活的正則表達式（regex）來指定單詞的分割方式，可以將文本中的單詞、標點符號、空格等都分割開來，並且可以通過指定特定的正則表達式來過濾停用詞、非英文字符等。unnest_tokens()函數還可以將分割後的單詞list展開成一個單詞data.frame，每個單詞對應一行記錄，這樣更容易進行後續的文本分析和可視化。在unnest_tokens(word, text, token = \"regex\", pattern = \"[^A-Za-z\\\\d#@']\") %&gt;%中，word表示新建的單詞欄位的名稱，text表示原始文本欄位的名稱，token表示使用的分割方式，這裡指定為正則表達式；pattern則是指定的正則表達式，其中[^A-Za-z\\\\d#@']表示匹配不屬於字母、數字、@、#、’的任意字符，即過濾掉非英文字符和一些標點符號。 library(tidytext) # unnest_tokens() library(stringr) # str_detect(), str_replace_all() # View(test) # stop_words$word tweet_words &lt;- tweets %&gt;% filter(!str_detect(text, &#39;^&quot;&#39;)) %&gt;% mutate(text = str_replace_all(text, &quot;https://t.co/[A-Za-z\\\\d]+|&amp;amp;&quot;, &quot;&quot;)) %&gt;% # unnest_tokens(word, text) %&gt;% # unnest_tokens(word, text, token = &quot;regex&quot;, pattern = &quot;[^A-Za-z\\\\d#@&#39;]&quot;) %&gt;% mutate(word = str_split(text, &quot; &quot;)) %&gt;% select(id, text, word, everything()) %&gt;% unnest(word) %&gt;% filter(!word %in% stop_words$word, str_detect(word, &quot;[a-z]&quot;)) # View(tweet_words) 這段程式碼用於分析文本數據中出現頻率最高的單詞（word），並使用barplot進行視覺化呈現。具體來說，這段程式碼實現了以下幾個步驟： 使用count()函數對data.frame中的單詞word進行計數，得到每個單詞出現的次數，並按照次數降序排列。 使用head()函數選擇出現次數最高的前20個單詞，並用mutate()函數將這20個單詞按照出現次數重新排序（注意reorder()的寫法）。 geom_col()函數用於繪製barplot，coord_flip()函數用於將x軸和y軸互換，以便更好地顯示barplot。 tweet_words %&gt;% count(word, sort = TRUE) %&gt;% head(20) %&gt;% mutate(word = reorder(word, n)) %&gt;% ggplot(aes(word, n)) + geom_col(fill = &quot;royalblue&quot;) + ylab(&quot;Occurrences&quot;) + coord_flip() + theme_minimal() + theme(axis.text = element_text(size=10)) 12.4.1 Log-likelihood ratio word_by_source的程式碼用於將單詞按照來源（source）進行分類，並統計每個來源中每個單詞出現的次數： 使用count()函數對單詞資料框中的單詞按照來源進行計數，並且將計數結果按照單詞和來源兩個變數進行分組。並使用filter()函數過濾掉在所有來源中出現次數少於5次的單詞。 使用pivot_wider()函數將分組後的資料框進行重構，將每個來源的單詞出現次數作為新欄（也就是把iPhone和Android展開成為欄位名稱），以便更方便地進行後續分析和可視化。這裡的names_from參數指定重構後的欄位名稱來自原來的source欄位，values_from參數指定要重構的值來自原來的count欄位，values_fill參數指定在重構後的資料框中缺失值的填充值，這裡設置為0。 android_iphone_ratios這段程式碼用於計算每個單詞在Android和iPhone兩個來源中的keyness的log likelihood ratio。具體來說，這段程式碼實現了以下幾個步驟： 從上一步驟得到的word_by_source資料框中，選擇了Android和iPhone兩個來源的單詞出現次數資訊。 對Android和iPhone兩個來源的單詞出現次數進行標準化處理，以便進行後續的keyness計算。具體來說，這裡使用了Laplace平滑處理（add-k smoothing），將每個來源的所有單詞出現次數都增加1，然後再將這些出現次數除以各自來源的總次數加1，得到每個單詞在Android和iPhone兩個來源中的出現概率。 對Android和iPhone兩個來源中的每個單詞，分別計算其在Android和iPhone兩個來源中的keyness log ratio。這裡使用了常見的對數比值（log ratio）方法，計算Android來源中單詞出現概率和iPhone來源中單詞出現概率的比值的對數，以此來衡量單詞在Android和iPhone兩個來源中的關鍵性差異。 將計算得到的log ratio值按照降序排列，以便進一步進行分析和可視化。 test &lt;- tweet_words %&gt;% count(word, source) %&gt;% filter(n &gt;= 5) %&gt;% pivot_wider(names_from = source, values_from = n, values_fill = 0) # View(test) word_by_source &lt;- tweet_words %&gt;% count(word, source) %&gt;% filter(n &gt;= 5) %&gt;% pivot_wider(names_from = source, values_from = n, values_fill = 0) %&gt;% # spread(source, n, fill = 0) %&gt;% ungroup() sum(word_by_source$iPhone) ## [1] 1383 sum(word_by_source$Android) ## [1] 2132 android_iphone_ratios &lt;- word_by_source %&gt;% mutate(iPhone = (iPhone+1)/sum(iPhone+1)) %&gt;% mutate(Android = (Android+1)/sum(Android+1)) %&gt;% # mutate_at(.cols = vars(iPhone, Android), # .funs = funs((. + 1) / sum(. + 1))) %&gt;% mutate(logratio = log2(Android / iPhone)) %&gt;% arrange(desc(logratio)) 這兩行分子分母加1的處理稱為拉普拉斯平滑。mutate(iPhone = (iPhone+1)/sum(iPhone+1)) %&gt;% 拉普拉斯平滑（add-k smoothing）是一種用於處理計數資料中零值問題的技巧，其主要目的是將出現次數為零的類別在計算機率時賦予一個非零的機率值，以避免出現無限大的情況，從而影響後續的計算結果。 在這段程式碼中，拉普拉斯平滑的目的是對每個單詞在Android和iPhone兩個來源中的出現次數進行標準化處理，以便進行後續的keyness計算。這是因為在標準化的計算中，如果某個來源中出現次數為0的單詞，則計算出來的概率值會為0，而這樣的結果可能會產生一些問題，例如無法取log或分母為零的情形。因此，為了避免這種問題，需要對每個單詞在Android和iPhone兩個來源中的出現次數進行拉普拉斯平滑處理，使得每個單詞在Android和iPhone兩個來源中的出現概率都能夠有一個非零的值，從而進行後續的計算和分析。 12.4.2 Plotting keyness 這段程式碼是用來繪製Android和iPhone兩個來源中關鍵性差異最大的單詞的keyness log ratio的條形圖。在繪製條形圖時，使用了fill = logratio &lt; 0的參數設置，這是一個布林值，當單詞在Android和iPhone兩個來源中的log ratio小於0時，填充的顏色是gold，否則填充的顏色是royalblue。 這種設計原理的目的是將Android和iPhone兩個來源中關鍵性不同的單詞進行區分，並用不同的填充顏色來表示。當單詞在Android來源中的出現概率高於在iPhone來源中的出現概率時，其log ratio值會為正，此時填充的顏色為royalblue；反之，當單詞在Android來源中的出現概率低於在iPhone來源中的出現概率時，其log ratio值會為負，此時填充的顏色為gold。 android_iphone_ratios %&gt;% group_by(logratio &gt; 0) %&gt;% top_n(15, abs(logratio)) %&gt;% ungroup() %&gt;% mutate(word = reorder(word, logratio)) %&gt;% ggplot(aes(word, logratio, fill = logratio &lt; 0)) + geom_col() + coord_flip() + ylab(&quot;Android / iPhone log ratio&quot;) + scale_fill_manual(name = &quot;&quot;, labels = c(&quot;Android&quot;, &quot;iPhone&quot;), values = c(&quot;royalblue&quot;, &quot;gold&quot;)) + theme_minimal() + theme(axis.text = element_text(size=14)) "],["introduction-to-web-scraping.html", "Chapter 13 Introduction to Web Scraping 13.1 Using Web API 13.2 Webpage Scraping 13.3 Using Chrome DevTools", " Chapter 13 Introduction to Web Scraping 爬蟲主要分為兩大類：一類是使用網站所提供的 API，另一類則是需要寫網頁爬蟲來剖析網頁。 第一類是使用網站所提供的 API，API 是指應用程式介面，是網站提供的一種接口，用戶可以通過 API 向網站發送請求，獲取網站數據。API 可以是 RESTful API、SOAP API、XML-RPC API 等等，使用 API 的好處是可以直接獲取需要的數據，且數據格式結構化，易於處理。不過使用 API 需要瞭解 API 的調用方式和接口參數等細節，而且不是所有網站都提供 API。常見且提供API讓客戶端來取用資料的社群網站服務包含： Google Maps API：提供地圖、地理位置等相關的 API。 Twitter API：提供關於 Twitter 的相關數據，包括推文、用戶資訊等。 Facebook API：提供關於 Facebook 的相關數據，包括用戶資訊、頁面資訊等。 GitHub API：提供關於 GitHub 的相關數據，包括存儲庫資訊、用戶資訊等。 OpenWeatherMap API：提供天氣資訊的 API。 YouTube API：提供關於 YouTube 的相關數據，包括影片、頻道等。 Spotify API：提供關於音樂的相關數據，包括歌曲、歌手等。 第二類是需要寫網頁爬蟲來剖析網頁，這種方法通常使用一些開源的爬蟲框架，如 Python 的 Scrapy 和 Beautiful Soup、R 的 rvest 等等。網頁爬蟲是通過模擬瀏覽器的方式，向網站發送請求，獲取網頁的 HTML 源代碼，然後使用相應的庫對 HTML 進行解析和剖析，獲取需要的數據。網頁爬蟲需要考慮很多因素，如網站的反爬機制、網頁的動態載入、網頁的解析方式等等，需要編寫複雜的代碼來處理這些問題。例如爬取國內外報紙的搜尋結果大多需要直接剖析網頁來找到所需要的資料。 13.1 Using Web API 使用 Web API 需要瞭解 JSON 檔案格式，JSON 是一種輕量級的數據交換格式，可以被多種語言解析和生成，是目前 Web API 調用中使用最廣泛的數據格式之一。JSON 的全稱是 JavaScript Object Notation，為基於 JavaScript 對象的一種文本格式，可以被解析為不同的數據類型，如數字、布林代數、字串、數值組和物件等。JSON 與 XML 相比，具有更輕量級、更容易讀寫和解析等優勢，也因此在 Web API 中被廣泛應用。 JSON 格式的基本結構是一個鍵-值對應集合，其中每個鍵都是一個字串，每個值可以是數字、布爾值、字串、數組或對象等類型。例如，以下是一個簡單的 JSON 。在 JSON 中，可以使用大括號 {} 表示鍵值對應（Key-Value），使用中括號 [] 表示序列（類似R中的List），鍵和值之間用冒號 : 分隔以對應，不同的鍵值對之間用逗號 , 分隔。JSON可以是樹狀多階層的，即一個鍵的值可以是另一個 JSON物件的鍵值對應。 在 R 語言中讀取 JSON 檔案需要先將其轉換為 R 的物件。這可以使用 R 的 jsonlite 套件中的 fromJSON() 函數來實現。jsonlite 套件是一個方便解析 JSON 的工具，它提供了從 JSON 字符串到 R 物件之間的轉換功能。 { &quot;name&quot;: &quot;John&quot;, &quot;age&quot;: 30, &quot;isMarried&quot;: false, &quot;hobbies&quot;: [&quot;reading&quot;, &quot;music&quot;, &quot;movies&quot;], &quot;address&quot;: { &quot;street&quot;: &quot;123 Main St&quot;, &quot;city&quot;: &quot;Anytown&quot;, &quot;state&quot;: &quot;CA&quot; } } 13.2 Webpage Scraping 網頁爬蟲是一種自動化工具，可用於收集網頁上的資料。想要寫出高效能、穩定的爬蟲程式，需要掌握以下基礎知識： HTML 和 CSS：這些是用於設計和呈現網頁的標準技術。HTML 是網頁的基礎架構，而 CSS 用於設計和美化網頁的外觀。例如了解了解 HTML 標籤和屬性的基本語法和用法，以及網頁的基本結構，例如 head、body、div、span、table、a 等等。並瞭解了解 CSS 的基本語法和用法，包括如何設置元素的樣式、顏色、字體、大小、邊框等等，以及常用的選擇器和屬性。 XPath 和 CSS 選擇器：XPath 和 CSS 選擇器是用於定位 HTML 元素的語言。XPath 是 XML 語言的一部分，而 CSS 選擇器是 CSS 的一部分。Chrome 瀏覽器的 Inspector 是一個強大的工具，可以幫助我們查找 HTML 元素的 XPath 和 CSS 選擇器。 HTTP 協議：HTTP 協議是網絡通信協議，用於網頁服務器和瀏覽器之間的通信。理解 HTTP 協議可以幫助理解網頁如何工作。例如最常見的HTTP回應代碼有「401 Unauthorized：未經授權，無法訪問所需內容」以及「404 Not Found：所請求的內容不存在」。 防止反爬：由於網站經常會採取反爬蟲措施，因此開發者需要學習如何繞過這些措施，例如使用代理服務器、設置間隔時間、更換用戶代理等。 13.2.1 HTTP Status Code 回應代碼用於向客戶端通報伺服器對請求的處理狀態，以便客戶端根據不同的回應代碼進行相應的處理。例如，當客戶端發送一個請求到服務器時，如果服務器返回的回應代碼是 200 OK，這意味著該請求已經成功處理，服務器已經返回所需的內容，客戶端可以根據返回的內容進行下一步操作；如果服務器返回的是 404 Not Found，這意味著客戶端所請求的內容不存在，客戶端需要提示用戶請求的資源不存在。以下是 HTTP 協議中常見的一些代碼： 1xx（Informational）：這些代碼表示服務器已經接收到請求，但仍在處理中。 2xx（Successful）：這些代碼表示請求已經成功處理。 3xx（Redirection）：這些代碼表示客戶端需要採取進一步的操作才能完成請求。 4xx（Client Error）：這些代碼表示客戶端發生了錯誤，請求無法完成。 5xx（Server Error）：這些代碼表示服務器發生了錯誤，無法完成請求。 以下是常見的 HTTP 協議代碼： 200 OK：請求已經成功處理，並返回所需的內容。 301 Moved Permanently：請求的網頁已經永久轉移到新位置。 302 Found：請求的網頁暫時轉移到新位置。 400 Bad Request：請求的語法不正確。 401 Unauthorized：未經授權，無法訪問所需內容。 403 Forbidden：已經獲得授權，但仍無法訪問所需內容。 404 Not Found：所請求的內容不存在。 500 Internal Server Error：服務器內部錯誤，無法處理請求。 13.3 Using Chrome DevTools Chrome DevTools是一款由Google開發的網頁開發工具，可以幫助開發人員進行網頁測試、網頁性能分析、網頁設計等工作。DevTools提供了豐富的功能，包括元素查看器、Console、網絡監測器、源代碼編輯器等，可讓開發人員在開發過程中快速找到和解決問題。此外，DevTools還可以幫助開發人員模擬不同設備、網速，以及對網站進行性能分析和優化，提高網站的速度和使用體驗。 13.3.1 Observing web request 在開始網頁爬蟲之前，我們需要找到網頁中的JSON數據，以便進行後續的數據提取和處理。使用Chrome DevTools可以很容易地找到網頁背後的JSON檔案。以下是一些步驟： 打開Chrome瀏覽器，進入要爬取的網站。 按下F12鍵或右鍵點擊網頁上的任意位置並選擇「檢查」來開啟DevTools。 在DevTools中，選擇「Network」分頁。 在瀏覽器中執行您要查找JSON數據的操作，例如點擊一個按鈕或輸入一個查詢。 在DevTools的網絡監測器中，您可以看到所有網頁請求（Request）和回應（Response），包括我們感興趣的JSON檔案。如果您只想查看JSON請求，可以在過濾器中輸入「json」。 點選JSON請求，您可以查看Request和Response中的的詳細信息，包括URL、Headers、Request Payload和Response等。 在Response分頁中，您可以看到JSON數據的內容。如果JSON數據很大，您可以右鍵點擊JSON數據，然後選擇「Save Response As...」將其保存到本地檔案中。 "],["scraping-104.html", "Chapter 14 Scraping 104.com 14.1 Complete Code 14.2 Step-by-Step", " Chapter 14 Scraping 104.com 14.1 Complete Code 撰寫爬蟲時需要載入許多不同的函式庫，其中包括用於 HTTP 請求的httr，以及用於解析 JSON 數據的jsonlite。 httr：httr 庫是 R 語言中用於發送 HTTP 請求和處理 HTTP 響應的函式庫，它提供了一組簡單易用的函數，可以讓使用者方便地設置 HTTP 請求的各種參數，如 URL、HTTP 方法、HTTP 頭、HTTP 主體等，並處理 HTTP 響應的內容和狀態碼等。 jsonlite：jsonlite 庫是 R 語言中用於解析和生成 JSON 數據的函式庫，它提供了 fromJSON() 函數，可以將 JSON 字符串轉換為 R 物件，並提供 toJSON() 函數，可以將 R 物件轉換為 JSON 字符串。這個函式庫通常用於處理 API 回應數據中的 JSON 格式數據。 library(tidyverse) library(httr) library(jsonlite) # options(stringsAsFactors = F) all.df &lt;- tibble() refer_url &lt;- &quot;https://www.104.com.tw&quot; for(p in 1:10){ url &lt;- str_c(&#39;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8&amp;order=12&amp;asc=0&amp;page=&#39;, p, &quot;&amp;mode=s&amp;jobsource=2018indexpoc&quot;) print(p) res &lt;- GET(url, add_headers(&quot;referer&quot;=refer_url)) %&gt;% content(&quot;text&quot;) %&gt;% fromJSON() res$data$list$tags &lt;- NULL res$data$list$link &lt;- NULL all.df &lt;- bind_rows(all.df, res$data$list) } all.df$jobNo %&gt;% unique %&gt;% length 14.2 Step-by-Step 14.2.1 Get the first pages 這段程式碼是用於爬取104人力銀行網站上與「資料科學」相關的職缺資訊，並將其存儲到名為df2的Data.Frame中。首先，我們嘗試點選104人力銀行網站上的第1頁、第2頁和第3頁的職缺搜尋結果，並將這三個網址儲存為三個URL變量，應該不難觀察到，這三個網址有何差別？僅有page=1、page=2、page=3有所差別。接下來，我們使用R語言中的httr套件中的GET()函數，將URL作為參數傳入，從網站中獲取對應的數據，並使用fromJSON()函數將該JSON格式的內容轉換為R中的Data.Frame格式。下面程式在獲取第2頁數據時，使用了add_headers()函數設置了一個HTTP header，用於識別HTTP請求的來源。 這段程式碼使用了add_headers函數添加了一個名為「Referer」的HTTP header。這個header的作用是告訴104人力銀行網站，訪問這個頁面的用戶是從哪個網頁轉跳過來的，也就是告訴網站當前HTTP請求的來源。具體來說，這裡設置的「Referer」值為https://www.104.com.tw/，代表我們偽裝這個請求是來自於104人力銀行首頁。如果沒有這個Referer，該網站會認為你是一個可疑的爬取，從沒根據和不當的頁面或用不當的方式（例如爬蟲）連過來。 對的！人家網站不歡迎你爬它，所以我們應止於測試。 url1 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=1&amp;mode=s&amp;jobsource=2018indexpoc&quot; # Assigning the 2nd page data url to url2 url2 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8&amp;order=14&amp;asc=0&amp;page=2&amp;mode=s&amp;jobsource=2018indexpoc&quot; # Assigning the 3rd page data url to url3 url3 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=3&amp;mode=s&amp;jobsource=2018indexpoc&quot; # Getting back the url1 data, assigning to result1 res &lt;- GET(url2, config = add_headers(&quot;Referer&quot; = &quot;https://www.104.com.tw/&quot;)) res1 &lt;- content(res, &quot;text&quot;) %&gt;% fromJSON() result2 &lt;- fromJSON(content(GET(url2), &quot;text&quot;)) # Tracing variable result2 and finding the data.frame, assigning to df2 df2 &lt;- res1$data$list 14.2.2 Get the first page by modifying url # Guessing the 1st page data url to url1 url1 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=1&amp;mode=s&amp;jobsource=2018indexpoc&quot; # Getting back the 1st page data url1 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=1&amp;mode=s&amp;jobsource=2018indexpoc&quot; result1 &lt;- fromJSON(content(GET(url1), &quot;text&quot;)) df1 &lt;- result1$data$list 14.2.3 Combine two data with the same variables # all.df &lt;- bind_rows(df1, df2) # will raise error # Error in bind_rows_(x, .id) : # Argument 31 can&#39;t be a list containing data frames 14.2.4 Drop out hierarchical variables Preserving numeric or character, dropping list of data.frame by assigning NULL to the variable # Drop list and data.frame inside the data.frame df1$link &lt;- NULL df1$tags &lt;- NULL df2$link &lt;- NULL df2$tags &lt;- NULL # Re-binding two data.frame df1 and df2 all.df &lt;- bind_rows(df1, df2) 14.2.5 Dropping hierarchical variables by dplyr way # Getting the 1st page data and dropping variable tags and link # Assigning to df1 df1 &lt;- result1$data$list %&gt;% select(-tags, -link) # Getting the 2nd page data and dropping variable tags and link # Assigning to df2 df2 &lt;- result2$data$list %&gt;% select(-tags, -link) # binding df1 and df2 all.df &lt;- bind_rows(df1, df2) 14.2.6 Finding out the last page number # Tracing the number of pages in result1 last_page_num &lt;- result1$data$totalPage # Checking the availability of the last page # Examining if the last page data available by re-composing URL with paste0() url.last_page &lt;- paste0(&quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=&quot;, last_page_num, &quot;&amp;mode=s&amp;jobsource=2018indexpoc&quot;) # Getting back and parsing the last page data result.last_page &lt;- fromJSON(content(GET(url.last_page), &quot;text&quot;)) 14.2.7 Using for-loop to get all pages for(p in 1:last_page_num){ url &lt;- paste0(&quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=&quot;, p, &quot;&amp;mode=s&amp;jobsource=2018indexpoc&quot;) result &lt;- fromJSON(content(GET(url), &quot;text&quot;)) temp.df &lt;- select(result$data$list) print(paste(p, nrow(temp.df))) } 14.2.8 combine all data.frame # The 1st url of the query url1 &lt;- &quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=1&amp;mode=s&amp;jobsource=2018indexpoc&quot; # Getting back the 1st page data result1 &lt;- fromJSON(content(GET(url1), &quot;text&quot;)) # Tracing and getting total number of page last_page_num &lt;- result1$data$totalPage # Truncating hierarchical variables: link and tags all.df &lt;- select(result1$data$list, -link, -tags) # for-loop to getting back data and joining them for(p in 1:last_page_num){ url &lt;- paste0(&quot;https://www.104.com.tw/jobs/search/list?ro=0&amp;kwop=7&amp;keyword=%E7%88%AC%E8%9F%B2&amp;order=1&amp;asc=0&amp;page=&quot;, p, &quot;&amp;mode=s&amp;jobsource=2018indexpoc&quot;) result &lt;- fromJSON(content(GET(url), &quot;text&quot;)) temp.df &lt;- select(result$data$list) all.df &lt;- bind_rows(all.df, temp.df) print(paste(p, nrow(all.df))) } "],["html-parser.html", "Chapter 15 HTML Parser 15.1 Detecting Element Path", " Chapter 15 HTML Parser 15.1 Detecting Element Path Chrome DevTools的使用如下： 打開Chrome瀏覽器，進入要爬取的網站。 按下F12鍵或「右鍵」點擊網頁上的任意你感興趣的內容並選擇「檢查（Inspector）」來開啟DevTools。 在DevTools中，選擇「Elements」分頁。Elements分頁用於查看和修改網頁的HTML和CSS，以及網頁中的DOM元素。在Elements分頁中可以看到網頁中所有的HTML標籤和屬性，以及網頁中的DOM樹狀結構。程式寫作者可使用此功能來檢查和修改網頁元素，例如更改元素的文本、樣式或屬性，或者添加、刪除或重新排列元素。Elements分頁還提供了選擇元素和檢查元素屬性的工具，便於快速找到和解決網頁問題。此外，Elements分頁還具有許多有用的功能，例如網頁渲染性能分析、Box-Model、色彩選擇器等，可幫助使用者更好地理解和設計網頁。 在「Elements」分頁中找到你要查找的元素，例如一個按鈕或一個超連結。你可以輕點一下Elements中的任意元素，然後按「Ctrl/Cmd+F」就可以搜尋在Elements分頁中的內容。例如你感興趣的是網頁上的「下一頁」三個字，那你搜尋「下一頁」就可以找到相對應的元素。或者，你可以在「Elements」分頁開啟的狀況下，用右鍵輕點左側原始網頁中你感興趣的內容或元素，然後再次選擇「檢查（Inspector）」，此時「Elements」分頁就會自動跳到你感興趣的內容或元素。 在DevTools的選擇元素面板中，右鍵點擊選擇的元素，然後選擇「Copy」&gt;「Copy XPath」或「Copy」&gt;「Copy selector」。 將複製的XPath或CSS Selector粘貼到您的爬蟲程式中，以查找和提取相應的數據。 15.1.1 XPath XPath是一種用於定位和選擇XML文檔中元素的語言，也可以應用於HTML文檔。XPath使用路徑表達式來選擇文檔中的節點或節點集，這些路徑表達式可以是絕對的或相對的，可以根據元素名、屬性、節點位置等進行篩選。XPath提供了一種簡單而強大的方式來編寫網頁爬蟲，使得開發者能夠精確地定位需要提取的數據，進而進行數據清洗和分析。 以下是一個XPath的例子：考慮一個HTML文檔，其中有一個表格，表格中包含多個行和列，每一個單元格包含一些數據。如果我們想要提取表格中第一行第一列的數據，可使用//table/tr[1]/td[1]。這個XPath表達式由以下幾個部分組成： //table: 選擇文檔中的所有表格元素。 /tr[1]: 選擇表格中的第一行。 /td[1]: 選擇第一行中的第一列。 15.1.2 CSS Selector CSS Selector是一種用於定位和選擇HTML元素的語言，它可以根據元素的屬性、標籤名稱、類名稱等進行篩選和定位。CSS Selector同樣也是網頁爬蟲中經常使用的一種定位方式。和XPath相比，CSS Selector的寫法更加簡潔和直觀，因此在一些簡單的定位場景中，使用CSS Selector可以更加方便和快捷。但是，在一些複雜的定位場景中，XPath可能更加適合，因為它可以根據節點的位置等進行更加精確的篩選。 用CSS Selector如前面XPath的例子來選擇表格中第一行第一列：table tr:first-child td:first-child。這個CSS Selector由以下幾個部分組成： table: 選擇文檔中的所有表格元素。 tr:first-child: 選擇表格中的第一行。 td:first-child: 選擇第一行中的第一列。 "],["lebron.html", "Chapter 16 NYT: LeBron James Achievement 16.1 Get top250 players 16.2 Scraping live scores 16.3 Scrape life time scores 16.4 Cleaning data 16.5 Visualization 16.6 Scraping and cleaning 16.7 (More) Scraping all players", " Chapter 16 NYT: LeBron James Achievement 這個案例的靈感來自於紐約時報於2023年2月7日所發布的一篇新聞「How LeBron James Outscored Kareem Abdul-Jabbar and All the N.B.A. Greats」。該篇新聞的破題點在於LeBron James 打破 Kareem Abdul-Jabbar 的紀錄，成為 NBA 歷史上得分王，這是許多人認為無法達成的成就。今年 38 歲的 James，本季平均每場比賽可以攻下 30.2 分，以 38,390 分超越了 Abdul-Jabbar 的 38,387 分。Abdul-Jabbar 以 sky hook 聞名，而 James 則透過多種得分方式積累分數，包括近年來在聯盟中日益盛行的三分球。James 的長壽、創意、天賦和能力讓他達成了這個成就。但實際上，這篇新聞同時也凸顯了 NBA 在過去50年的演變。 這篇新聞中運用了NBA球員與球賽資料庫中250名頂尖球員的資料來繪製視覺圖表，頂尖球員援引該網站的定義，為歷年的每場平均得分（PTS）。其用了折線圖、長條圖、散佈圖等多種視覺呈現方法，並採用了多項指標來凸顯LeBron James的成就，包含年齡、累積得分數、場均得分數、三分球與二分球的比例等。 除了資料視覺化外，這個案例也是相當好的爬蟲練習，可用R語言的rvest套件來爬取https://www.basketball-reference.com/網站的球員資料，包含每個球季的比分，甚至著名球員每場的得分和進球數等等。該網站的網頁多為具有id的HTML表格，相對來說爬取難度較低，但如果要仿照該篇新聞來製作視覺圖表，需要爬取多個頁面的資料，反而是訓練學生從篩檢資料到產生新聞的一個好範例。 16.1 Get top250 players 事實上我是知道有NBA球員比分網站的，看到這則新聞時我就去線上查找了相關的網站https://www.basketball-reference.com。而且該網站的球員資料是表格形式，代表我們可以用一些比較方便的函式（html_table()）直接將該表格的內容轉為data.frame。 但目前（2023/04/01）的球員數共有五千多人，我們不可能將所有的球員通通繪製在圖上，反而會影響我們看到重要的訊息，因此要有效且有意義地減少要視覺化的資料量。這有幾種策略，一種是根據目的取出想要比較的球員、一種是直接設一個閥值（例如職涯超過15年的約90人），一種是看看該資料網站上有沒有列出一些頂尖球員名單。（猜想）紐約時報用的是該網站上的Top 250，因此第一個步驟要做的就是先把要分析的這250名球員的名冊爬取下來，之後再逐一爬取每個球員的資料紀錄。 這段程式碼的目的是從網站 “https://www.basketball-reference.com” 中提取出排名前幾位的籃球員生涯表現數據，以及每個球員的個人資料頁面連結。Top 250球員的頁面網址為https://www.basketball-reference.com/leaders/per_career.html。 現在，我們可以使用rvest套件中的read_html()函數讀取網頁的 HTML 內容，該。接著傳遞給下一個函數html_node()，並指定要選取的 HTML 元素 ID 為nba。這個 ID 代表了包含球員表現數據的表格。最後，使用html_table() 函數提取表格資料並將結果存入top_players變數中。 read_html(url) 函數是 rvest 套件中的一個函數，它可讀取指定網址的 HTML 內容，以轉換為R的物件。 html_node() 函數則可用於選擇 HTML 內容中的指定元素。指定元素的方法是使用XPath或CSS Selector，本範例採用的是CSS Selector。若所要選取的同類型元素大於一個，那就要使用html_nodes()，所取得的結果會存入一個由1開始編號的List。 如果前一個步驟所指定的元素恰巧是一個表格的話，那我們就可以使用html_table()直接將表格轉換為一個R的data.frame，但如果不是表格的話，就必須要搭配使用html_text()或html_attr()來取出指定元素中的所需內容。 做完html_table()後的dataframe存於top_players，該dataframe共有三個變項：Rk（Rank）、PER（每場平均得分）、Player（球員名）。但該dataframe中缺少球員資料頁面的連結，所以需要另外再爬取一次球員名中的連結。取得的方式還是那三個步驟 read_html()：取得該url的網頁內容並轉為R的物件。 html_node()/html_nodes()：選取所需的HTML元素。此時我們要娶的是#nba這個表格中每一列&lt;tr&gt;的第二欄&lt;td&gt;中的超鏈結&lt;a&gt;。 html_text()/html_attr()/html_table()：抽取所選取的HTML元素內容。此時要抽取的是&lt;a&gt;中的超鏈結，也就是&lt;a&gt;的href屬性（Attribute），所以要用html_attr(\"href\")。 抽取出來的連結往往是相對於主要連結的後半段，因此，最後要將所取得的連結黏接在主頁連結的後方，如str_c(url.base, .)。 url.base &lt;- &quot;https://www.basketball-reference.com&quot; url &lt;- &quot;https://www.basketball-reference.com/leaders/per_career.html&quot; top_players &lt;- read_html(url) %&gt;% html_node(&quot;#nba&quot;) %&gt;% html_table() top_players$plink &lt;- read_html(url) %&gt;% html_node(&quot;#nba&quot;) %&gt;% html_nodes(&quot;tr td:nth-child(2) a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% str_c(url.base, .) top_players 16.2 Scraping live scores 16.2.1 Testing url &lt;- &quot;https://www.basketball-reference.com/players/c/chambto01.html&quot; table2 &lt;- read_html(url) %&gt;% html_node(&quot;#per_game&quot;) %&gt;% html_table(convert=T) 16.3 Scrape life time scores # pinks &lt;- long_players$plink plinks &lt;- top_players$plink totals &lt;- tibble() for(i in 1:length(plinks)){ plink &lt;- plinks[i] message(sprintf(&quot;[%s] &quot;, i), plink) table &lt;- read_html(plink) %&gt;% html_node(&quot;#totals&quot;) %&gt;% html_table() table$plink &lt;- plink totals &lt;- bind_rows(totals, table) Sys.sleep(sample(1:2, 1)) } 16.4 Cleaning data top250 &lt;- totals %&gt;% filter(str_detect(Season, &quot;\\\\d{4}-\\\\d{2}&quot;)) %&gt;% left_join(top_players, by=&quot;plink&quot;) %&gt;% select(-(34:53)) %&gt;% select(-31) %&gt;% mutate(year = year(paste0(str_sub(Season, 1, 4), &quot;-01-01&quot;))) %&gt;% mutate(PERyear = PTS/G) %&gt;% group_by(plink) %&gt;% arrange(Age) %&gt;% mutate(cumPTS = cumsum(PTS)) %&gt;% ungroup() 16.5 Visualization load(&quot;data/nba_players.rda&quot;) 16.5.1 Line: Age x cumPTS library(gghighlight) selected_players &lt;- c(&quot;Michael Jordan*&quot;, &quot;LeBron James&quot;, &quot;Kobe Bryant*&quot;, &quot;Wilt Chamberlain*&quot;, &quot;Kareem Abdul-Jabbar*&quot;, &quot;Stephen Curry&quot;) top250 %&gt;% ggplot() + aes(Age, cumPTS, group=Player) + geom_line() + gghighlight(Player %in% selected_players) + theme_bw() + theme(legend.position = &quot;none&quot;) 16.5.2 Line: year x cumPTS top250 %&gt;% ggplot() + aes(year, cumPTS, group=Player) + geom_line() + gghighlight(Player %in% selected_players) + theme_bw() + theme(legend.position = &quot;none&quot;) 16.5.3 Line: Age x PER_by_year top250 %&gt;% ggplot() + aes(Age, PERyear, group=Player) + geom_line() + gghighlight(Player %in% selected_players) + theme_bw() + theme(legend.position = &quot;none&quot;) 16.5.4 Comparing LeBron James and Jabbar 16.6 Scraping and cleaning # plink &lt;- &quot;https://www.basketball-reference.com/players/j/jamesle01.html&quot; plink &lt;- &quot;https://www.basketball-reference.com/players/a/abdulka01.html&quot; loglinks &lt;- read_html(plink) %&gt;% html_node(&quot;#totals&quot;) %&gt;% html_nodes(&quot;tr th a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% paste0(url.base, .) logtable &lt;- tibble() for(link in loglinks){ table &lt;- read_html(link) %&gt;% html_node(&quot;#pgl_basic&quot;) %&gt;% html_table() logtable &lt;- bind_rows(logtable, table) message(nrow(logtable), link) } jabbar.log &lt;- logtable %&gt;% select(Rk, G, Date, FG, `3P`, FT, PTS) %&gt;% mutate(Rk = as.numeric(Rk), FG = as.numeric(FG), `3P` = as.numeric(`3P`), FT = as.numeric(FT), PTS = as.numeric(PTS)) %&gt;% filter(!is.na(PTS)) %&gt;% replace(is.na(.), 0) %&gt;% mutate(try = FG + `3P` + FT) %&gt;% mutate(FGperc = FG/try, P3perc = `3P`/try, FTperc = FT/try) %&gt;% mutate(gid = row_number()) 16.6.1 VIS LJames and jabbar james.log %&gt;% pivot_longer(names_to = &quot;type&quot;, cols = c(&quot;FGperc&quot;, &quot;P3perc&quot;, &quot;FTperc&quot;), values_to = &quot;perc&quot;) %&gt;% ggplot() + aes(gid, perc, fill = type) + geom_area() + theme_bw() jabbar.log %&gt;% pivot_longer(names_to = &quot;type&quot;, cols = c(&quot;FGperc&quot;, &quot;P3perc&quot;, &quot;FTperc&quot;), values_to = &quot;perc&quot;) %&gt;% ggplot() + aes(gid, perc, fill = type) + geom_area() + theme_bw() top250 %&gt;% group_by(Player) %&gt;% summarize(FGsum = sum(FG), FTsum = sum(FT), P3sum = sum(`3P`)) %&gt;% ungroup() %&gt;% replace(is.na(.), 0) %&gt;% mutate(trials = FGsum + FTsum + P3sum) %&gt;% mutate(FGperc = FGsum/trials, FTperc = FTsum/trials, P3perc = P3sum/trials) %&gt;% ggplot() + aes(FGperc, P3perc) + geom_point() + geom_text(aes(label = Player), hjust = -0.1) + gghighlight(Player %in% selected_players) + theme_bw() + theme(aspect.ratio = 2/3) save(jabbar.log, james.log, top_players, top250, totals, file=&quot;../data/nba_players.rda&quot;) 16.7 (More) Scraping all players 16.7.1 Testing url &lt;- &quot;https://www.basketball-reference.com/players/x/&quot; table.path &lt;- read_html(url) %&gt;% html_node(&quot;#players&quot;) table &lt;- table.path %&gt;% html_table() table$pid &lt;- table.path %&gt;% html_nodes(&quot;tbody th&quot;) %&gt;% html_attr(&quot;data-append-csv&quot;) table$plink &lt;- table.path %&gt;% html_nodes(&quot;tbody th a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% str_c(&quot;https://www.basketball-reference.com&quot;,.) 16.7.2 Scrape from a-z except x(no x) # letters[c(1:23, 25:26)] players &lt;- tibble() for(letter in letters[c(1:23, 25:26)]){ url &lt;- str_c(&quot;https://www.basketball-reference.com/players/&quot;, letter, &quot;/&quot;) print(url) table.path &lt;- read_html(url) %&gt;% html_node(&quot;#players&quot;) table &lt;- table.path %&gt;% html_table() table$pid &lt;- table.path %&gt;% html_nodes(&quot;tbody th&quot;) %&gt;% html_attr(&quot;data-append-csv&quot;) table$plink &lt;- table.path %&gt;% html_nodes(&quot;tbody th a&quot;) %&gt;% html_attr(&quot;href&quot;) %&gt;% str_c(&quot;https://www.basketball-reference.com&quot;,.) players &lt;- bind_rows(players, table) } "],["visualization-1.html", "Chapter 17 Visualization 17.1 ggplot2 17.2 VIS packages 17.3 ggplot簡介 17.4 繪圖基礎：折線圖 17.5 NYT: Inequality 17.6 Adjusting Chart 17.7 Highlighting &amp; Storytelling", " Chapter 17 Visualization 17.1 ggplot2 ggplot2和Python的matplotlib都是常用的視覺化套件，但在設計上有一些主要的差異。首先，ggplot2是基於grammar of graphics的設計原則，而matplotlib則是基於pyplot-style的設計風格。這意味著ggplot2更加著重於資料和視覺化之間的關係，並且提供了一個統一的語法來描述這些關係，而matplotlib則更加注重對於底層圖形物件的控制。其次，ggplot2支持更多的圖形屬性，例如數值變數、類別變數、時間序列等等，並且可以輕鬆地進行層疊圖、面積圖等高級視覺化技巧，而matplotlib則需要手動設置較多的屬性來達到類似的效果。此外，ggplot2在設計上更加注重美學和可讀性，因此預設的圖形風格更加美觀且易於閱讀，而matplotlib的預設風格則比較簡單，需要進行額外的設置才能達到類似的效果。 17.2 VIS packages 除了ggplot2本身之外，尚有相當多基於ggplot或tidyverse風格的視覺化套件，如： ggraph：ggraph是一個基於ggplot2的視覺化套件，專門用於網絡和關係圖的繪製，提供了多種佈局和美學風格的選擇。 ggmap：ggmap是一個基於ggplot2的地圖繪製套件，可以將Google Maps、OpenStreetMap等地圖數據與ggplot2圖形整合起來，方便進行地理位置相關的資料視覺化。 ggridge：ggridge是一個基於ggplot2的視覺化套件，專門用於繪製ridge plots，也就是密度圖的一種變形。它可以幫助使用者更好地展示數據的分佈和趨勢。Introduction to ggridges (r-project.org) ggthemes：ggthemes是一個基於ggplot2的視覺化套件，提供了多種高質量的主題風格和顏色調色板，可以讓使用者快速改善圖表的外觀和可讀性。 ggnatimate：ggnatimate用於將ggplot所產製的圖表多增加一個變量以轉製為動態圖表，支持多種動畫效果。 ggally：ggally是一個基於ggplot2的視覺化套件，提供了多種高級散點圖和數據矩陣的繪製方式，方便使用者進行多變量分析和資料探索。 ggrepel：ggrepel是一個基於ggplot2的視覺化套件，用於解決文字標籤重疊的問題，可以自動調整文字標籤的位置，使其更加易讀和美觀。 17.3 ggplot簡介 本節著重在介紹ggplot的基本概念與設定。 訣竅：可在一開始便透過knitr::opts_chunk$set(echo = TRUE, fig.width = 2, fig.asp = 0.4)來一次設定所有圖片。fig.width = 8與fig.height = 6 是以英吋（inches）為單位，或用fig.dim = c(8, 6)一次設定長寬1。echo = TRUE是設定knit出輸出格式（如html）時，也要包含程式碼。如果echo = FALSE的話，就只會輸出文字和圖形。 17.4 繪圖基礎：折線圖 17.4.1 繪圖三要素 用ggplot來繪製圖形有三個基本函式ggplot() + aes() + geom_圖表類型。 指定要進行繪圖ggplot()：用%&gt;%將資料（dataframe）pipe給ggplot()後，底下各增添的繪圖選項都用+的符號，類似不斷修正繪圖結果的意思。 指定X／Y軸與群組因子aes()：指定圖表的X/Y軸分別是什麼變數，有些圖表只需要單一個變數（例如Density-chart和Histogram），有些需要X/Y兩個變數（例如Scatter-chart）什麼的變數要做視覺化，Boxplot甚至可以直接指定最大、最小、Q1、Q3和Median等多個變數。 指定要繪製的圖表類型。例如Line-chart為geom_line()、Scatter-chart為geom_point()、Bar-chart為geom_col()或geom_bar()。查閱ggplot cheat sheet可以快速翻閱有哪些圖表類型（如截圖）。 ggplot-cheat-sheet 17.4.1.1 ggplot() 會秀出預備要繪製的繪圖區 tibble(a=1:5, b=5:1) %&gt;% ggplot() 17.4.1.2 指定X／Y軸與群組因子aes()：aes()會在繪圖區上繪製X與Y軸 tibble(a=1:5, b=5:1) %&gt;% ggplot() + aes(x=a, y=b) 17.4.1.3 指定要繪製的圖表類型。 例如折線圖為為geom_line()、X/Y散佈圖為geom_point()、長條圖我多會使用geom_col()。 tibble(a=1:5, b=5:1) %&gt;% ggplot() + aes(x=a, y=b) + geom_line() 亦可同時繪製兩種類型的圖表於同一張圖上。例如以下同時繪製了geom_line()與geom_plot()。 tibble(a=1:5, b=5:1) %&gt;% ggplot() + aes(x=a, y=b) + geom_line() + geom_point() 17.5 NYT: Inequality Teach About Inequality With These 28 New York Times Graphs - The New York Times (nytimes.com) ggplot是以變數為基礎的視覺化套件，也就是說，當準備好dataframe後，就可以在ggplot中指定要用哪些變數來繪圖。也因此，務必把dataframe整理為tidy型態，也就是長表格（long-form）的型態。整理完資料後，我會習慣地用names(plot)或glimpse(plot)來看一下該資料所有的變項，好可以在下一階段的繪圖做參考。 17.5.1 Visualizing NW &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(Category, year, Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% ungroup() ## Rows: 66 Columns: 37 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (1): Category ## dbl (36): year, Before_Tax_Income, Net_Worth, Assets, Financial_Assets, Tran... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. NW %&gt;% glimpse() ## Rows: 66 ## Columns: 3 ## $ Category &lt;chr&gt; &quot;Less than 35&quot;, &quot;35-44&quot;, &quot;45-54&quot;, &quot;55-64&quot;, &quot;65-74&quot;, &quot;75 or o… ## $ year &lt;dbl&gt; 1989, 1989, 1989, 1989, 1989, 1989, 1992, 1992, 1992, 1992, … ## $ Net_Worth &lt;dbl&gt; 16.17019, 112.47530, 195.11630, 195.25554, 154.34277, 144.29… 這是預期視覺化的結果。 先將year和Net_worth分別繪製在X與Y軸上，並用geom_line()繪製為折現圖。結果圖表中呈現鋸齒狀的折線，看似有問題，但其實是合理的。因為year是一個離散變數，而我們希望每個年齡層一條線的話，那就要照年齡層來分組。也因此，每一年都有有每個年齡層的資料，當我們把「年」作為X軸時，自然同一年就會有數筆不同年齡層的資料，因此才會是鋸齒狀的。 NW %&gt;% ggplot() + aes(x=year, y=Net_Worth) + geom_line() 不同的圖表類型是可以疊加在同一張圖上的。我們也可以把geom_point() 另一種圖表型態加入，也是可以的，兩者的X與Y不相衝突。geom_line()、geom_point()、geom_text()三者會經常伴隨出現。 NW %&gt;% ggplot() + aes(x=year, y=Net_Worth) + geom_line() + geom_point() 17.5.2 Grouping 上圖是我們把多個年齡層的逐年資料畫在同一條折線上，所以會呈現鋸齒狀折現的狀況。但這些年齡層並非在同一條線上呀？因此，我們要根據Category這個變數來做分組。 NW %&gt;% ggplot() + aes(x=year, y=Net_Worth, group=Category) + geom_line() + geom_point(stat=&quot;identity&quot;) 如希望不同線條上不一樣的色彩，應指定color=Category。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() 用color、fill或group來做分組？ geom_line()的色彩是在線，而不是在面上。如果色彩是在點（如geom_point()）或線（geom_line()）上，就是用color來指定顏色。 但如果是如類似下面的例子，用geom_area()來視覺化的話，因為顏色填的是面，所以要用fill=Category。以下範例甚至同時指定color=Category, fill=Category。但折線圖如果要用geom_area()來視覺化的話，最好要上顏色的不要超過二個，不然就會像底下這個例子一樣，即使設定alpha=0.2的半透明，仍然會看不懂哪些顏色疊在一起。 geom_area()預設應該是累積分佈圖（也就是不同的群組會在Y軸方向疊加），如果希望觀察兩個分布的差別，而不是希望看見整體趨勢的話，那要增加position=\"dodge\"的參數，並把alpha（半透明）設定為1以下的數值。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category, fill=Category) + geom_area(position=&quot;dodge&quot;, alpha=0.2) 17.6 Adjusting Chart 17.6.1 點線型態 下面的例子同時用了geom_line()和geom_point()，且分別設定了線寬（size=1）、點的大小(size=2)，折線型態（linetype=\"dashed\"）、半透明程度（alpha）。 ggplot2 line types : How to change line types of a graph in R software? - Easy Guides - Wiki - STHDA NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line(size=1, linetype = &quot;dashed&quot;, alpha=0.5) + geom_point(size=2, color=&quot;dimgrey&quot;, alpha=0.5) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. 17.6.2 Line Types See more from ggthemes https://github.com/BTJ01/ggthemes/tree/master/inst/examples library(ggthemes) rescale01 &lt;- function(x) { (x - min(x)) / diff(range(x)) } gather(economics, variable, value, -date) %&gt;% group_by(variable) %&gt;% mutate(value = rescale01(value)) %&gt;% ggplot(aes(x = date, y = value, linetype = variable)) + geom_line() + scale_linetype_stata() + theme_minimal() 17.6.3 標題、標籤與圖說 Titles, labels, and legend 設定標題與X／Y軸標題（法一）：以下設定了圖表的圖表標題、和X軸與Y軸的軸標題（xlab與ylab）。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + xlab(&quot;Year&quot;) + ylab(&quot;Net Worth&quot;) + ggtitle(&quot;Net Worth by year grouped by age groups&quot;) 設定標題與X／Y軸標題（法二）：這是一次設定圖表標題（title）、次標題（suttitle）、X軸與Y軸標題的方法。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, subtitle = &quot;Source from: ...&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) 調整X軸與Y軸標題位置的：必須要透過theme()來設定axis.title.x = element_text(hjust=1)。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) + theme(axis.title.x = element_text(hjust=1), axis.title.y = element_text(hjust=1)) 去除X／Y軸標題（不佳）：直接將空字串Assign給title、x、與y即可。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + labs(title = &quot;&quot;, x = &quot;&quot;, y = &quot;&quot;) 去除X／Y軸標題（較佳）：透過設定theme()來調整。可發現透過這種設定方法，原本標題和X／Y軸標題的邊界空間就會被釋放出來。 # No extra space for xlab, ylab and title NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line(show.legend = F) + theme_minimal() + theme(plot.title = element_blank(), axis.title.x = element_blank(), axis.title.y = element_blank()) 17.6.4 字體樣式 調整字型會建議都從theme()來做調整，所有圖面上看得到的字都有相對應的變數可以調整字型。例如以下的例子中，把標題的字型大小調整為14粗體、X與Y軸的字型則調整了向右對齊、10粗斜體、顏色為dimgrey。 NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) + theme(plot.title = element_text(size=14, face=&quot;bold&quot;), axis.title.x = element_text(hjust=1, size=10, color=&quot;dimgrey&quot;, face=&quot;bold.italic&quot;), axis.title.y = element_text(hjust=1, size=10, color=&quot;dimgrey&quot;, face=&quot;bold.italic&quot;) ) 17.6.5 圖表主題色調 ggplot也有其圖表主題色調。之前範例的灰色圖表背景就是預設的主題，ggplot中還有好幾個預設圖表主題可以選，例如theme_minimal()或theme_tw()等等。 Modify components of a theme — theme • ggplot2 (tidyverse.org) bbplot/bbc_style.R at master · bbc/bbplot (github.com) NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() 17.6.6 預設主題 如果希望所有的圖表都有一致的顏色和排版的調性，可以在一開始編輯Rmd的時候就設計好一套theme()並指給一個變數（例如以下的th）。 th &lt;- theme(plot.title = element_text(size=14, face=&quot;bold&quot;), axis.title.x = element_text(hjust=1, size=10, color=&quot;dimgrey&quot;, face=&quot;bold.italic&quot;), axis.title.y = element_text(hjust=1, size=10, color=&quot;dimgrey&quot;, face=&quot;bold.italic&quot;) ) NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line(linetype = &quot;dashed&quot;, alpha=0.5) + geom_point(size=2, color=&quot;dimgrey&quot;, alpha=0.5) + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) + th 17.6.7 顯示中文字體 Python和R這些程式語言的預設視覺化套件都沒辦法顯示中文，所以如果要顯示中文的話，就要指定圖表標題、X、Y軸標籤、圖說和各個部件的字型。因為我在Mac上繪圖，所以我將字型指定為Heiti TC Light。如果想知道自己的電腦上有什麼可以用，可以到電腦的字體簿上查找中文字體名稱，或者上網google「ggplot 中文字型選擇」。 county &lt;- read_csv(&quot;data/tw_population_opendata110N010.csv&quot;) %&gt;% slice(-1, -(370:375)) %&gt;% type_convert() %&gt;% mutate(county = str_sub(site_id, 1, 3)) %&gt;% group_by(county) %&gt;% summarize( area = sum(area), people_total = sum(people_total) ) %&gt;% ungroup() ## Rows: 375 Columns: 5 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (5): statistic_yyy, site_id, people_total, area, population_density ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ## ## ── Column specification ──────────────────────────────────────────────────────── ## cols( ## statistic_yyy = col_double(), ## site_id = col_character(), ## people_total = col_double(), ## area = col_double(), ## population_density = col_double() ## ) 下面這是一個長條圖的範例（barplot，不是histogram）。Barplot可以直接指定X軸為縣市（county）和Y軸為總人口數（people_total），但是要用geom_col()而非geom_bar()。除此之外，Bar的顏色有「面」的特徵，所以若要自訂整條bar的顏色，要用fill而非color，color只會是每條Bar的外框。 county %&gt;% arrange(desc(people_total)) %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;lightgrey&quot;, color=&quot;black&quot;) + theme_minimal() + theme(axis.text.x = element_text(family=&quot;Heiti TC Light&quot;)) 舉例來說，中文字型可以是標楷體（BiauKai）、宋體（Songti TC）、黑體（Heiti TC Light）、蘋方（PingFang TC）、Noto（Noto Sans CJK TC） th &lt;- theme(title = element_text(family=&quot;Heiti TC Light&quot;), text = element_text(family=&quot;Heiti TC Light&quot;), axis.text.y = element_text(family=&quot;PingFang TC&quot;), axis.text.x = element_text(family=&quot;Heiti TC Light&quot;), legend.text = element_text(family=&quot;Heiti TC Light&quot;), plot.title = element_text(family=&quot;Heiti TC Light&quot;) ) county %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;skyblue&quot;) + theme_minimal() + th + theme(axis.text.x = element_text(angle = 45)) 17.6.8 X/Y軸方向 調整圖表方向 county %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;skyblue&quot;) + coord_flip() + theme_minimal() + th + theme(axis.text.x = element_text(angle = 45)) 通常coord_flip()後往往會希望這些bar會是由上而下排序好的，但用arrange(desc(people_total)是無法解決問題的，因為Y軸原本會是照Y軸的刻度排列，而不是Y軸的數值。所以，要被排序的應該是Y軸的「文字」也就是那些縣市。因此，我們需要將該縣市轉為factor（1~n），並且讓這些縣市被安排的factor數值照people_total排列，因此要用mutate(county = reorder(county, people_total))。reorder()是一個將文字轉factor的函式，但在此特別指定照people_total的編排。 county %&gt;% # arrange(desc(people_total) %&gt;% mutate(county = reorder(county, people_total)) %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;skyblue&quot;) + coord_flip() + theme_minimal() + th 17.7 Highlighting &amp; Storytelling 「說故事」才是整則資料新聞的核心，在運用圖表來輔助敘事時，應搭配說理說服的內容來突顯（highlight）圖面上的特徵，而不是留待讀者自己觀察。以下有三種highlight圖表部分資料的方法。第一個方法是在繪圖時用+ scale_color_manual()或+ scale_fill_manual()指定顏色給不同群組；方法二是利用gghighlight這個套件來指定要上色的群組，而且gghighlight可以和fill與color相互搭配，仍然可以用scale_fill_manual和scale_color_manual來指定顏色。但會有個狀況是，如果原本沒群組那怎麼辦？就自己用mutate()打造群組就好。方法各有利弊與使用時機。 17.7.1 依群組指定顏色 scale_color_manual() 與scale_fill_manual() NW %&gt;% ggplot() + aes(year, Net_Worth, color = Category) + geom_line() + scale_color_manual( limits=c(&quot;65-74&quot;, &quot;35-44&quot;), # original chart group values=c(&quot;gold&quot;, &quot;skyblue&quot;), # map to color name=&quot;Age group&quot;, # legend title breaks=c(&quot;65-74&quot;, &quot;35-44&quot;), # original legend group labels labels=c(&quot;elder(65-74)&quot;,&quot;younger(35-44)&quot;), # map to new labels na.value = &quot;lightgrey&quot; # color for other groups ) + theme_minimal() 17.7.2 使用gghighlight套件 library(gghighlight) NW %&gt;% ggplot() + aes(year, Net_Worth, color = Category) + geom_line() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;35-44&quot;)) + theme_minimal() + scale_x_continuous(breaks = NULL) + theme(panel.background = element_rect(fill = &quot;whitesmoke&quot;, colour = &quot;whitesmoke&quot;, size = 0.5, linetype = &quot;solid&quot;)) 使用gghighlight仍能自己使用scale_color_manual()來指定顏色 NW %&gt;% ggplot() + aes(year, Net_Worth, color = Category) + geom_line() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;35-44&quot;)) + scale_color_manual( limits=c(&quot;65-74&quot;, &quot;35-44&quot;), # original chart group values=c(&quot;gold&quot;, &quot;skyblue&quot;)) + # map to color theme_minimal() ## Warning: Tried to calculate with group_by(), but the calculation failed. ## Falling back to ungrouped filter operation... ## label_key: Category 17.7.3 為視覺化建立群組 這個方法是在原本的資料並沒有可以作為color或fill的因子，所以自行創建一個要突顯的群組。 county %&gt;% mutate(group = if_else(county %in% c(&quot;新竹縣&quot;, &quot;新竹市&quot;), &quot;highlight&quot;, &quot;other&quot;)) %&gt;% mutate(county = reorder(county, people_total)) %&gt;% ggplot() + aes(county, people_total, fill=group) %&gt;% geom_col() + scale_fill_manual(values=c(&quot;highlight&quot;=&quot;Khaki&quot;, &quot;other&quot;=&quot;lightgrey&quot;)) + guides(fill=&quot;none&quot;) + coord_flip() + theme_minimal() + th 但事實上也可以用gghighlight直接達成 county %&gt;% mutate(county = reorder(county, people_total)) %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;deeppink&quot;) + gghighlight(county %in% c(&quot;新竹縣&quot;, &quot;新竹市&quot;)) + guides(fill=&quot;none&quot;) + coord_flip() + theme_minimal() + th 參考資料：5.4 Control the size of plots/images | R Markdown Cookbook (bookdown.org)↩︎ "],["coordinate.html", "Chapter 18 Coordinate 18.1 Order as axis 18.2 Log-scale 18.3 18.4 Square-root scale 18.5 座標軸從數值到增加值 18.6 等比例座標軸", " Chapter 18 Coordinate 本章節談論的是視覺化圖表的座標軸，本章節所涵蓋的概念可參考Claus O. Wilke所著之Fundamentals of Data Visualization的Chap3 Coordination &amp; Axis與Chapter 8 Visualizing distributions: Empirical cumulative distribution functions and q-q plots。 18.1 Order as axis 學術論文若要呈現一群數據的分佈時，最常用的是密度（分佈）函數、累積分佈函數，最常視覺化的方法是密度分佈圖（geom_density()）或直方圖（geom_histogram())。然而，對新聞等強調「說故事」的文體而言，說故事的技巧往往不是「那一群資源多或資源少的對象」，而經常要直指「那個對象」，要能夠看得見所敘述的對象在圖中的位置。此時，用密度分佈來呈現的話，只能看出，該對象在分佈的某個位置；但可以改用將資料對象根據某個數據來排序後，繪製折現圖的方式來表現。例如，若要繪製一個班級的成績分佈，通常X軸是分數（組），Y軸是獲得該分數（組）的人數；但其實可以將個體依照分數來做排序，Y軸不是某個分數（組）的個數，而是每個排序後的個體，而且以排序後的序號（Ranking）來表示。用折線圖繪製後，一樣可以看出分數的分佈，但卻能夠直接標記敘事中的某個對象是Y軸中得哪個點。 18.1.1 Figure 3.5: Population numbers of Texas counties relative to their median value. Select counties are highlighted by name. The dashed line indicates a ratio of 1, corresponding to a county with median population number. The most populous counties have approximately 100 times more inhabitants than the median county, and the least populous counties have approximately 100 times fewer inhabitants than the median county. Data source: 2010 Decennial U.S. Census. See What’s Going On in This Graph? | Vaccination by Country fromWhat Data Shows About Vaccine Supply and Demand in the Most Vulnerable Places - The New York Times (nytimes.com) The original chart is animated along the timeline.What Data Shows About Vaccine Supply and Demand in the Most Vulnerable Places - The New York Times (nytimes.com) 18.2 Log-scale raw &lt;- read_csv(&quot;data/opendata107Y020.csv&quot;, show_col_types = FALSE) %&gt;% slice(-1) %&gt;% type_convert() toplot &lt;- raw %&gt;% select(site_id, village, edu_age_15up_total) %&gt;% arrange(desc(edu_age_15up_total)) %&gt;% mutate(index = row_number()) %&gt;% mutate(label = ifelse(index &lt;= 5 | index &gt; n()-5, paste0(site_id, village), &quot;&quot;)) library(ggrepel) p2 &lt;- toplot %&gt;% ggplot() + aes(index, edu_age_15up_total) + geom_point(alpha=0.5, color=&quot;royalblue&quot;) + geom_text_repel(aes(label = label), point.padding = .4, color = &quot;black&quot;, min.segment.length = 0, family = &quot;Heiti TC Light&quot;) + theme(axis.text.x=element_blank()) + scale_y_log10(breaks = c(0, 1, 10, 100, 1000, 10000)) + theme_minimal() p1 &lt;- toplot %&gt;% ggplot() + aes(index, edu_age_15up_total) + geom_point(alpha=0.5, color=&quot;royalblue&quot;) + theme(axis.text.x=element_blank()) + theme_minimal() cowplot::plot_grid( p2, NULL, p1, labels = c(&quot;a&quot;, &quot;&quot;, &quot;b&quot;), nrow = 1, rel_widths = c(1, 0.1, 1) ) 18.2.1 NYT: Population Growth 紐時這篇報導「When Did the Anthropocene Start? Scientists Closer to Saying When. - The New York Times (nytimes.com)」討論了人類活動對地球所產生的深遠影響，並探討人類是否已經進入了一個新的地質時期，被稱為「人新世」。報導指出，人類的經濟活動、能源消耗和人口增長是人新世的主要因素，並且這些因素已經在地球上留下了不可磨滅的痕跡。報導也提到，地質學家已經發現了人新世的證據，包括核爆炸中的鈽同位素、肥料中的氮和發電廠的灰燼等。然而，報導也問道，人新世是否真的已經開始，以及它的開始點是否應該是農業革命、工業革命、核彈（77年前）或其他發展。 However, Package tabulizer cannot be installed in the current version of R. 18.2.1.1 Parsing table from pdf # install.packages(&quot;tabulizer&quot;) # if (!require(&quot;remotes&quot;)) { # install.packages(&quot;remotes&quot;) # } # remotes::install_github(c(&quot;ropensci/tabulizerjars&quot;, &quot;ropensci/tabulizer&quot;)) library(tidyverse) library(tabulizer) # Extract the table tables &lt;- extract_tables(&#39;data/world_population_change.pdf&#39;, pages = 1) # Extract the first element of the variable raw &lt;- as.data.frame(tables[[1]]) population_by_year &lt;- raw %&gt;% select(1, 2) %&gt;% slice(-c(1:4)) %&gt;% rename(years_to_2020 = V1, population = V2) # select(years_to_2020 = v1, population = v2) # mutate(years_to_2020 = v1, population = v2) 18.2.1.2 X and Y with log-scale library(cowplot) load(&quot;data/world_population_change.rda&quot;) toplot &lt;- population_by_year %&gt;% mutate(years_to_2020 = map(years_to_2020, ~(str_remove(., &quot;,&quot;)))) %&gt;% mutate(years_to_2020 = as.numeric(years_to_2020), population = as.numeric(population)) toplot %&gt;% head ## years_to_2020 population ## 1 11720 4 ## 2 10020 5 ## 3 8220 8 ## 4 7020 11 ## 5 6020 7 ## 6 5020 14 p1 &lt;- toplot %&gt;% ggplot() + aes(x=years_to_2020, y=population) + geom_point() + theme_bw() p2 &lt;- toplot %&gt;% ggplot() + aes(x=years_to_2020, y=population) + geom_point() + scale_x_log10() + scale_y_log10() + scale_x_reverse() + theme_bw() cowplot::plot_grid( p1, NULL, p2, labels = c(&quot;(a) Original Scale&quot;, &quot;&quot;, &quot;(b) Low-Scale&quot;), nrow = 1, rel_widths = c(1, 0.1, 1) ) library(tidyverse) library(gghighlight) 18.3 18.4 Square-root scale Chap3 Coordination &amp; Axis Fundamentals of Data Visualization (clauswilke.com) Figure 3.8: Areas of Northeastern U.S. states. (a) Areas shown on a linear scale. (b) Areas shown on a square-root scale. Data source: Google. 前面是視覺化了各村里大於十五歲以上人口的人口數分佈，採用對數尺度（log-scale）可以觀察到比較小的村里。那有什麼是適合用平方根尺度（sqrt-scale）的呢？是土地嗎？密度嗎？還是人口數？是村里等級嗎？鄉鎮市區等級嗎？還是縣市等級？ town &lt;- read_csv(&quot;data/tw_population_opendata110N010.csv&quot;) %&gt;% slice(-1, -(370:375)) %&gt;% type_convert() town %&gt;% arrange(desc(area)) %&gt;% mutate(index = row_number()) %&gt;% ggplot() + aes(index, area) %&gt;% geom_col(fill=&quot;skyblue&quot;) + scale_y_sqrt() + theme_minimal() Figure 18.1: (ref:population-area) county &lt;- town %&gt;% mutate(county = str_sub(site_id, 1, 3)) %&gt;% group_by(county) %&gt;% summarize( area = sum(area), people_total = sum(people_total) ) %&gt;% ungroup() p1 &lt;- county %&gt;% arrange(desc(people_total)) %&gt;% mutate(index = row_number()) %&gt;% ggplot() + aes(index, people_total) %&gt;% geom_col(fill=&quot;lightgrey&quot;) + # scale_y_sqrt() + theme_minimal() p2 &lt;- county %&gt;% arrange(desc(people_total)) %&gt;% mutate(index = row_number()) %&gt;% ggplot() + aes(index, people_total) %&gt;% geom_col(fill=&quot;khaki&quot;) + scale_y_sqrt(breaks=c(0, 250000, 500000, 1000000, 2000000, 4000000)) + theme_minimal() cowplot::plot_grid( p1, p2, labels = c(&quot;a&quot;, &quot;b&quot;), nrow = 1 ) Figure 18.2: (ref:population-area) 18.5 座標軸從數值到增加值 18.5.1 NYT: Net Worth by Age Group LEARNING NOTES Median for Inequality 這個教學案例來自紐約時報的「What’s going on in this gragh」系列資料視覺化教學之Teach About Inequality With These 28 New York Times Graphs - The New York Times (nytimes.com) 。該圖表呈現在不同年代、不同年齡層的人所擁有的淨資產（包含土地、存款、投資等減去債務）。該圖表的結果指出，在不同年代的老年人是越來越有錢，但年輕人卻越來越窮（該曲線為減去1989年 18.5.2 Read and sort data Sorted by arrange() function. p1 &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(year, Category, Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% ungroup() p1 %&gt;% filter(year &lt;= 1992) %&gt;% knitr::kable() year Category Net_Worth 1989 Less than 35 16.17019 1989 35-44 112.47530 1989 45-54 195.11630 1989 55-64 195.25554 1989 65-74 154.34277 1989 75 or older 144.29855 1992 Less than 35 16.60780 1992 35-44 79.91050 1992 45-54 139.97745 1992 55-64 203.44104 1992 65-74 176.44667 1992 75 or older 155.35173 p1 %&gt;% ggplot() + aes(year, Net_Worth, color = Category) + geom_line() + geom_point() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;Less than 35&quot;)) + theme_minimal() + scale_x_continuous(breaks = NULL) + theme(panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;)) p2 &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(year, Category, NW = Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% mutate(increase = (NW-first(NW))/first(NW)) %&gt;% ungroup() p2 %&gt;% filter(year &lt;= 1992) %&gt;% knitr::kable() year Category NW increase 1989 Less than 35 16.17019 0.0000000 1989 35-44 112.47530 0.0000000 1989 45-54 195.11630 0.0000000 1989 55-64 195.25554 0.0000000 1989 65-74 154.34277 0.0000000 1989 75 or older 144.29855 0.0000000 1992 Less than 35 16.60780 0.0270627 1992 35-44 79.91050 -0.2895285 1992 45-54 139.97745 -0.2825948 1992 55-64 203.44104 0.0419220 1992 65-74 176.44667 0.1432131 1992 75 or older 155.35173 0.0765994 美國35歲以下的年輕人的中位淨資產比起年長的美國人來說，一開始平均貧窮得多。從「Less than 35」這條線看來，現在的年輕世代比起2004年的年輕世代所擁有的淨資產低了40%。相比之下，65歲以上的美國人現在的淨資產，相較於2004年增加了9%。隨著時代變化，可想像會有一群人的淨資產越來越多，只是現在從這個圖表看來，年輕人所擁有的淨資產相較於過去是越來越低的，多半流入了成年人和老年人手中。 p2 %&gt;% ggplot() + aes(year, increase, color = Category) + geom_line() + geom_point() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;Less than 35&quot;)) + theme_minimal() + scale_y_continuous(labels=scales::parse_format()) + scale_x_continuous(breaks = NULL) + theme(panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;)) 18.6 等比例座標軸 18.6.1 UNICEF-Optimistic (WGOITH) https://www.nytimes.com/2021/11/17/upshot/global-survey-optimism.html https://changingchildhood.unicef.org/about plot.opt &lt;- read_csv(&quot;data/unicef-changing-childhood-data.csv&quot;) %&gt;% select(country = WP5, age = WP22140, bw = WP22092) %&gt;% mutate(country = ordered(country, levels=c(1, 3, 4, 10, 11, 12, 13, 14, 17, 29, 31, 33, 35, 36, 60, 61, 77, 79, 81, 87, 165), labels=c(&quot;USA&quot;, &quot;Morocco&quot;, &quot;Lebanon&quot;, &quot;Indonesia&quot;, &quot;Bangladesh&quot;, &quot;UK&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;, &quot;Japan&quot;, &quot;India&quot;, &quot;Brazil&quot;, &quot;Nigeria&quot;, &quot;Kenya&quot;, &quot;Ethiopia&quot;, &quot;Mali&quot;, &quot;Ukraine&quot;, &quot;Cameroon&quot;, &quot;Zimbabwe&quot;, &quot;Argentina&quot;, &quot;Peru&quot;))) %&gt;% count(country, age, bw) %&gt;% group_by(country, age) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(bw == 1) %&gt;% select(country, age, perc) %&gt;% spread(age, perc) %&gt;% rename(`15-24y` = `1`, `40+y` = `2`) plot.opt %&gt;% head(10) %&gt;% knitr::kable() country 15-24y 40+y USA 0.6679842 0.4611465 Morocco 0.4365079 0.4735812 Lebanon 0.5467197 0.4435798 Indonesia 0.7920605 0.8027344 Bangladesh 0.4624506 0.4319527 UK 0.5040000 0.4140000 France 0.3900000 0.2640000 Germany 0.5900000 0.3860000 Spain 0.5160000 0.3340000 Japan 0.6367265 0.2586873 plot.opt %&gt;% ggplot() + aes(`40+y`, `15-24y`, label = country) + geom_point(color = &quot;skyblue&quot;, size = 2) + xlim(0, 1) + ylim(0,1) + geom_text(hjust = -0.1, vjust = -0.5) + geom_abline(intercept = 0, slop = 1, color=&quot;lightgrey&quot;, alpha=0.5, linetype=&quot;dashed&quot;) + theme_minimal() + theme(aspect.ratio=1) "],["amount.html", "Chapter 19 AMOUNT 19.1 Bar chart 19.2 Heatmap: Vaccination", " Chapter 19 AMOUNT 19.1 Bar chart 19.2 Heatmap: Vaccination 這個例子參考(Wilke 2019)在視覺化數量（Amount）時的熱圖範例（Heatmap），但改用為視覺化各國每百人完整注射COVID-19疫苗人數歷時資料。 - https://ourworldindata.org/covid-vaccinations - https://github.com/owid/covid-19-data/tree/master/public/data/vaccinations 在R語言中，我們可以使用ggplot2套件來創建熱圖。熱圖通常使用顏色來表示數據的強度或值，通常是從淺色到深色或從冷色到暖色的漸變。ggplot2套件提供了geom_tile()函數來繪製熱圖。熱圖主要有以下幾個作用： 顯示數據的分布情況：熱圖可以將數據的分布情況一目了然地呈現出來，讓觀察者可以快速了解數據的分布情況。 發現數據之間的相關性：熱圖可以將數據之間的相關性直觀地呈現出來，這對於探索數據之間的關係非常有用。 篩選數據：熱圖可以幫助我們快速地篩選出數據中的關鍵部分，從而更好地理解數據。 使用ggplot2繪製熱圖的過程中，我們可以使用scale_fill_gradient()函數設置顏色的漸變方式和範圍，使用coord_equal()函數使x和y軸的尺度相同，從而保持正方形。 19.2.1 The case: Vaccinating coverage by month 本例子的資料前處理難度較高（OS：惡魔級）。困難來自於每個國家登記資料的時間不同，因此會產生大量NA值。但在這樣的狀況下，又要找到以月為時間單位的共同數值，就會更挑戰程式編寫者的資料清理技術。除此之外，如何偵測「每個國家超過每百人有二十人完整注射疫苗的時間點」，更是技巧中的技巧。是個磨練NA值處理和高難度資料前處理的好例子。這個例子同時也是大量在長表格、寬表格間轉換，多次運用spread()/pivot_wider()與gather()/pivot_longer()，搭配group_by()來達到資料整理目的的困難例子。 19.2.2 Data cleaning library(lubridate) raw &lt;- read_csv(&quot;data/vaccinations.csv&quot;) fullvaccinated &lt;- raw %&gt;% select(country = location, date, people_fully_vaccinated_per_hundred) %&gt;% drop_na(people_fully_vaccinated_per_hundred) %&gt;% mutate(m = floor_date(date, unit = &quot;month&quot;)) %&gt;% group_by(country, m) %&gt;% arrange(date) %&gt;% slice(1) %&gt;% ungroup() %&gt;% select(-date) vperc_by_month &lt;- fullvaccinated %&gt;% spread(m, people_fully_vaccinated_per_hundred, fill=NA) %&gt;% gather(month, perc, -country) %&gt;% arrange(country, month) %&gt;% group_by(country) %&gt;% arrange(month) %&gt;% mutate(perc = zoo::na.locf(perc, na.rm = F)) %&gt;% ungroup() %&gt;% arrange(country, month) %&gt;% replace_na(list(perc=0)) 19.2.3 Visualization https://clauswilke.com/dataviz/visualizing-amounts.html 這個案例使用了三個維度的資料，分別為X軸的時間（月）、Y軸的國家、以及用顏色來呈現各國疫苗注射量（每百人）。並使用geom_tile()來製作熱圖。然而，Y軸的排序卻會影響讀圖。例如，在第一個例子中，Y軸的順序是用最後一個時間點的疫苗注射比例來排序。但每個國家政策和疫苗可獲量均不同，故開始注射和覆蓋速度也差很多，最終覆蓋量也會差很多。所以如果以最終覆蓋量來排序的話，反而不易觀察過程的變化，且「顏色」並不容易用來比較最終覆蓋量的大小，因而會產生很多讀圖上的困擾。 另一種繪圖策略是該書上的做法，其Y軸的排序是依照疫苗覆蓋率達到某個數值（例如每百人中有20人完整注射二劑疫苗）的時間早晚來排序。有此作為基準，每個國家在後續時間點的覆蓋速度的比較便比較容易。 另外需要注意到，顏色的取捨、以及相對於尺度的漸層設計也會影響讀圖。 19.2.3.1 Heatmap 01: Sorted by coverage of the last month watched &lt;- c(&quot;United Arab Emirates&quot;, &quot;Japan&quot;, &quot;Singapore&quot;, &quot;South Korea&quot;, &quot;Taiwan&quot;, &quot;Malaysia&quot;, &quot;Hong Kong&quot;, &quot;New Zealand&quot;, &quot;Thailand&quot;, &quot;Netherlands&quot;, &quot;United States&quot;, &quot;Israel&quot;, &quot;United Kingdom&quot;, &quot;Indonesia&quot;, &quot;Thailand&quot;, &quot;Philippines&quot;) vperc_by_month %&gt;% spread(month, perc) %&gt;% filter(country %in% watched) %&gt;% mutate(country = reorder(country, -`2022-05-01`)) %&gt;% gather(month, perc, -country) %&gt;% ggplot() + aes(month, country, fill=perc) + geom_tile() + theme_minimal() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) 19.2.3.2 Heatmap 02: Sorted by the time of specific coverage rate Sort by the time when the vaccine coverage rate exceeds 20% for all countries on the Y-axis. https://clauswilke.com/dataviz/visualizing-amounts.html vperc_by_month %&gt;% filter(country %in% watched) %&gt;% mutate(month = lubridate::as_date(month)) %&gt;% group_by(country) %&gt;% mutate(month1 = min((month[perc &gt; 20]))) %&gt;% ungroup() %&gt;% spread(month, perc) %&gt;% mutate(country = reorder(country, -as.numeric(month1))) %&gt;% select(-month1) %&gt;% gather(month, perc, -country) %&gt;% ggplot() + aes(month, country, fill=perc) + geom_tile() + theme_minimal() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) References "],["distribution-histogram-density.html", "Chapter 20 DISTRIBUTION: Histogram &amp; Density 20.1 Density plot 20.2 Histogram 20.3 Pyramid Plot 20.4 Box plot: Muitiple Distrubution", " Chapter 20 DISTRIBUTION: Histogram &amp; Density 本章節將介紹與資料分布相關的視覺化方法。資料分布是指數據中每個值出現的頻率或概率。在統計學中，了解資料分布是非常重要的，因為它可以幫助我們判斷數據是否為正態分佈，或者是否存在異常值或極端值。本章節將涵蓋常見的資料分布視覺化方法，包括直方圖、密度圖、箱形圖和金字塔圖等。 以下是R語言ggplot2套件中，用於資料分布視覺化的一些常用函式： geom_histogram()：用於創建直方圖。 geom_density()：用於創建密度圖。 geom_boxplot()：用於創建箱形圖。 geom_bar()：用於創建柱狀圖。 geom_freqpoly()：用於創建頻率多邊形圖。 註：本節的設計概念不少是參考 Claus O. Wilke 所著的「Foundations of Data Visualization」一書的章節，同時也參考臺灣和資料新聞的案例進行了改編。 接下來我們將使用Histogram和Density Plot這兩種資料視覺化方法來探索台灣村里長的年齡和性別分布情況。我們所使用的資料來源包括內政部和中選會的投票資料，這些資料能夠提供具有代表性的統計樣本，幫助我們更好地了解村里長的整體特徵。在進行資料視覺化的過程中，我們將會運用R語言中的ggplot2套件，並根據不同的視覺化需求進行相應的設置和調整。 https://www.moi.gov.tw/LocalOfficial.aspx?n=577&amp;TYP=KND0007。 vilmaster &lt;- readr::read_csv(&quot;data/tw_vil2018_elccand.csv&quot;) %&gt;% drop_na(當選註記) 20.1 Density plot 密度圖（Density Plot)是一種展示數據集分佈情況的圖表，它可以幫助我們更好地理解數據集中數值出現的概率。圖表的 X 軸代表數據集的數值範圍，Y 軸則代表每個數值的出現概率。與直方圖不同，密度圖的曲線是光滑的，因為它是通過連續的數值範圍估算出的概率密度函數。通過比較不同數據集的密度圖，我們可以更好地了解它們之間的差異。在ggplot2中，可以用geom_density()函數來創建密度圖。 p1 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_density() + th p2 &lt;- vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_density(alpha=0.5) + th + scale_fill_manual( limits=c(&#39;1&#39;, &#39;2&#39;), # original chart group values=c(&quot;gold&quot;, &quot;skyblue&quot;), # map to color name=&quot;性別&quot;, # legend title breaks=c(1, 2), # original legend group labels labels=c(&quot;Male&quot;,&quot;Female&quot;), # map to new labels na.value = &quot;lightgrey&quot; # color for other groups ) cowplot::plot_grid( p1, p2, labels = c(&quot;(a) Overall&quot;, &quot;(b) Group by gender&quot;), nrow = 1, rel_widths = c(1, 1) ) 20.1.1 Density with different bandwidth 參數bw指的是bnadwidth，為繪製histogram時的bar所涵蓋的資料寬度。以step-plot來說，bw越大，則梯距越寬；以density-plot來說，若bw越大則越是平滑。 library(ggridges) # for geom_density_line() p.b05 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_density_line(fill=&#39;gold&#39;, bw=0.5, kernel=&#39;gaussian&#39;) + th p.b1 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_density_line(fill=&#39;gold&#39;, bw=1, kernel=&#39;gaussian&#39;) + th p.b5 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_density_line(fill=&#39;gold&#39;, bw=5, kernel=&#39;gaussian&#39;) + th p.rect &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_density_line(fill=&#39;gold&#39;, bw=10, kernel=&#39;rectangular&#39;) + th cowplot::plot_grid( p.b05, p.b1, p.b5, p.rect, labels = c(&quot;(a) bw=.5&quot;, &quot;(b) bw=1&quot;, &quot;(c) bw=2&quot;, &quot;(b) rect&quot;), nrow = 2, rel_widths = c(1, 1) ) 20.2 Histogram 直方圖（Histogram）是一種用於展示數據集分佈的圖表。它通過將數據範圍分成若干個區間（稱為 “bins” 或 “buckets”），然後計算落在每個區間內的數據的數量（稱為 “frequency”），來展示數據集的分佈情況。直方圖的 X 軸表示數據範圍，Y 軸表示每個區間中的頻數。直方圖可以幫助我們快速了解數據的分佈情況，特別是數據的中心趨勢、數據的離散程度和是否存在異常值等。 20.2.1 Histogram with different number of bins p10 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_histogram(bins=10, fill=&#39;royalblue&#39;) + th p20 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_histogram(bins=20, fill=&#39;royalblue&#39;) + th p30 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_histogram(bins=30, fill=&#39;royalblue&#39;) + th p40 &lt;- vilmaster %&gt;% ggplot() + aes(年齡) + geom_histogram(bins=40, fill=&#39;royalblue&#39;) + th cowplot::plot_grid( p10, p20, p30, p40, labels = c(&quot;(a) bins=10&quot;, &quot;(b) bins=20&quot;, &quot;(c) bins=30&quot;, &quot;(b) bins=40&quot;), nrow = 2, rel_widths = c(1, 1) ) 20.2.2 Density vs histogram Histogram通常用來顯示數據的分佈情況，它會把數據區間分成若干個等寬的區間，然後計算每個區間內數據的頻率，再將這些頻率表示在y軸上。因此，histogram顯示的是數據的頻率，而不是數據的密度。 Density plot則是用來顯示數據的概率密度函數，它會通過核密度估計（Kernel Density Estimation, KDE）方法，將數據點周圍的密度估計出來，然後將這些估計值表示在y軸上。因此，density plot顯示的是數據的密度，而不是數據的頻率。 pd &lt;- vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_density(alpha=0.5) + th + scale_fill_manual( values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue&quot;), labels=c(&#39;1&#39;=&quot;Male&quot;,&#39;2&#39;=&quot;Female&quot;), name=&#39;Sex&#39; ) ph &lt;- vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_histogram(bins=20, position=&quot;dodge&quot;) + th + scale_fill_manual(values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue &quot;)) + theme(legend.position=&quot;none&quot;) cowplot::plot_grid( pd, ph, labels = c(&quot;(a) geom_density()&quot;, &quot;(b) geom_histogram()&quot;), nrow = 1, rel_widths = c(6, 4) ) 20.2.3 Positions of bar chart p.hist.dodge &lt;- vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_histogram(bins=20, position=&quot;dodge&quot;) + th + scale_fill_manual( values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue &quot;), labels=c(&#39;1&#39;=&quot;Male&quot;,&#39;2&#39;=&quot;Female&quot;), name=&#39;Sex&#39; ) p.hist.stack &lt;- vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_histogram(bins=20, position=&quot;stack&quot;) + th + scale_fill_manual(values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue &quot;)) + theme(legend.position=&quot;none&quot;) cowplot::plot_grid( p.hist.dodge, p.hist.stack, labels = c(&quot;(a) position:dodge&quot;, &quot;(b) position:stack&quot;), nrow = 1, rel_widths = c(6, 4) ) 20.2.4 Display two groups histogram by facet_wrap() geom_histogram(bins=20, position=\"dodge\") 用於繪製直方圖， bins=20表示將數據分成20個區間， position=\"dodge\"表示將不同性別的數據分開顯示。 th 是本範例在最早先所建立的ggplot主題，用於設置圖表的樣式（例如背景顏色、字體等）。 scale_fill_manual() 用於手動設置填充顏色， values=c(\"1\"='gold', '2'=\"skyblue\") 表示性別為1時填充金色，性別為2時填充天藍色。 labels=c('1'=\"Male\",'2'=\"Female\") 表示將性別1標記為Male，性別2標記為Female。 name='Sex' 表示設置顏色圖例的標題為Sex。 facet_wrap(.~性別, nrow=1) 表示將不同性別的數據分開顯示，每直行顯示一個性別。.~性別 表示將數據按性別分組。 vilmaster %&gt;% ggplot() + aes(年齡, fill=factor(性別)) + geom_histogram(bins=20, position=&quot;dodge&quot;) + th + scale_fill_manual( values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue &quot;), labels=c(&#39;1&#39;=&quot;Male&quot;,&#39;2&#39;=&quot;Female&quot;), name=&#39;Sex&#39; ) + facet_wrap(.~性別, nrow=1) 20.3 Pyramid Plot 金字塔圖（Pyramid plot）是一種用於比較兩個群體的統計圖表。它的形狀像一座金字塔，通常用於展示男女或年齡分佈等相關的數據。金字塔圖以垂直線為軸線，其中一側代表一個群體（如男性），另一側代表另一個群體（如女性）。圖表的左右兩側是對稱的，並以一條中心線分開。圖表中的每一行表示一個年齡段，而每一列則表示一個群體的比例或頻數。金字塔圖的高度表示總人數或總比例，並且可以用不同的顏色區分不同的群體。金字塔圖可以直觀地顯示兩個群體之間的差異，特別是在不同年齡段之間。 20.3.1 Modify geom_col() to pyramid plot vilmaster %&gt;% group_by(性別) %&gt;% mutate(age_group = cut(年齡, 0:20*5+.01)) %&gt;% count(age_group) %&gt;% ungroup() %&gt;% ggplot() + aes(x=age_group, y=ifelse(性別==&#39;1&#39;, -1, 1)*n, fill=factor(性別)) + geom_col() + scale_y_continuous(name = &quot;Count&quot;, breaks = 250*(-6:2), labels = c(&quot;1500&quot;, &quot;1250&quot;, &quot;1000&quot;, &quot;750&quot;, &quot;500&quot;, &quot;250&quot;, &quot;0&quot;, &quot;250&quot;, &quot;500&quot;)) + coord_flip() + scale_fill_manual( values=c(&quot;1&quot;=&#39;gold&#39;, &#39;2&#39;=&quot;skyblue &quot;), labels=c(&#39;1&#39;=&quot;Male&quot;,&#39;2&#39;=&quot;Female&quot;), name=&#39;Sex&#39; ) + th + labs(y=&quot;Count&quot;, x=&quot;Age Group&quot;) 20.4 Box plot: Muitiple Distrubution 箱形圖（Box plot）是一種用於展示數據分佈情況的統計圖表。它通常顯示數據的中位數、四分位數、極值和異常值等統計量。箱形圖的中間線表示數據的中位數，箱子的上下邊界則分別表示數據的上四分位數和下四分位數。箱子的高度表示數據的變異程度，而箱子外的線段則表示數據的最大值和最小值。如果數據中存在異常值，則通常使用圓圈或星號等符號來標記。箱形圖可以用來比較不同數據集之間的分佈情況，以及檢查數據是否存在異常值。 20.4.1 TW-Salary (boxplot) Inspired by Six Myths About Choosing a College Major - The New York Times (nytimes.com) and What’s Going On in This Graph? | Jan. 9, 2018 - The New York Times (nytimes.com) library(readxl) raw &lt;- read_excel(&quot;data/tw_salary109.xlsx&quot;, sheet=1, trim_ws = T) raw Category Q1 Median Q3 Mean 男 39.0 53.2 82.3 70.7 女 35.1 46.8 67.6 58.6 未滿25歲 28.1 35.8 45.1 37.7 25-29歲 36.6 47.8 61.7 53.0 30-39歲 39.2 53.3 77.0 64.1 40-49歲 39.9 56.9 91.8 74.8 50-64歲 37.8 53.3 88.4 75.5 65歲以上 30.6 40.9 63.1 62.6 國中及以下 32.7 40.5 52.0 45.4 高中（職） 34.5 44.7 59.8 51.9 大專 38.6 53.7 80.2 67.0 研究所 60.9 96.0 139.3 116.4 礦業及土石採取業 34.2 57.2 91.7 68.5 製造業 38.7 50.4 73.2 64.8 電力及燃氣供應業 73.9 110.7 139.9 113.2 用水供應及污染整治業 31.9 45.7 63.9 54.6 營建工程業 34.1 46.1 64.0 54.7 批發及零售業 36.6 49.5 71.7 62.7 運輸及倉儲業 40.3 58.3 81.4 66.1 住宿及餐飲業 30.1 36.7 49.3 42.0 出版﹑影音製作﹑傳播及 資通訊服務業 53.0 71.5 111.2 88.8 金融及保險業 65.6 96.9 140.1 113.4 不動產業 36.8 52.2 76.6 65.0 專業科學及技術服務業 41.9 61.3 95.0 77.5 支援服務業 33.1 42.1 49.3 45.3 教育業-不含小學以上各級 學校 28.4 33.7 42.7 37.2 醫療保健及社會工作服務業 41.3 60.1 88.1 77.1 藝術娛樂及休閒服務業 28.8 39.2 57.2 48.8 其他服務業 30.6 35.8 49.1 43.6 raw %&gt;% slice(-(1:12)) %&gt;% mutate(Category = reorder(Category, desc(Median))) %&gt;% ggplot() + aes(y = Category, xlower=Q1, xmiddle=Median, xupper=Q3, xmin=0, xmax=150) + geom_boxplot(stat = &quot;identity&quot;, color=&quot;white&quot;, fill=&quot;skyblue&quot;) + geom_point(aes(x = Mean)) + th + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank()) 20.4.2 TW-Income (boxplot) 如果在箱型圖中，平均數高於第三分位數，這代表數據集呈現右偏分佈。也就是說，數據中的大部分觀測值都分佈在第一、二分位數之間，但存在一些較大的極端值，使平均值被往右偏移。 library(gghighlight) toplot &lt;- read_csv(&quot;data/tw_income_107.csv&quot;, ) %&gt;% filter(!`村里` %in% c(&quot;合計&quot;, &quot;其他&quot;, &quot;福住里&quot;)) %&gt;% filter(鄉鎮市區 %in% c(&quot;信義區&quot;)) %&gt;% mutate(村里 = reorder(村里, desc(中位數))) toplot %&gt;% mutate(group = if_else((平均數&gt;第三分位數), &quot;highlight&quot;, &quot;none&quot;)) %&gt;% ggplot() + aes(y = 村里, xlower=第一分位數, xmiddle=中位數, xupper=第三分位數, xmin= min(第一分位數), xmax=max(第三分位數), fill=group) + geom_boxplot(stat = &quot;identity&quot;, color=&quot;white&quot;) + scale_fill_manual(values = c(&quot;highlight&quot;=&quot;orangered&quot;, &quot;none&quot;=&quot;skyblue&quot;)) + guides(fill=FALSE) + geom_point(aes(x = 平均數)) + xlab(&quot;年所得（單位：千元）&quot;) + th + theme(panel.grid.minor = element_blank(), panel.grid.major = element_blank()) "],["proportion.html", "Chapter 21 PROPORTION 21.1 Pie Chart 21.2 Dodged Bar Chart 21.3 Treemap: Nested Proportion", " Chapter 21 PROPORTION 21.1 Pie Chart 21.2 Dodged Bar Chart 21.3 Treemap: Nested Proportion Treemap是一種資料視覺化工具，用於呈現層級式結構的數據。它通常使用矩形或正方形區域來表示不同的數據單元，並將它們分層排列以形成層次樹狀結構。Treemap的特點包括： 易於理解：Treemap以直觀的方式呈現數據，讓使用者能夠輕鬆地了解各個數據單元之間的比例關係。 節省空間：Treemap使用矩形或正方形區域排列數據，能夠更有效地利用空間，呈現更多的數據。 可互動性：Treemap通常支持互動式操作，使用者可以通過縮放、懸停等方式，進一步了解數據。 Treemap適用於以下情況： 層級式數據：Treemap適用於層級式數據，例如組織架構、檔案系統等。 大量數據：Treemap能夠有效地呈現大量數據，並在縮放時保持清晰度。 比例關係：Treemap適用於呈現不同數據單元之間的比例關係，例如市場份額、支出等。 21.3.1 NYT: Carbon by countries 本案例取自紐時所報導之Who Has The Most Historical Responsibility for Climate Change? - The New York Times (nytimes.com)。該新聞報導了聯合國氣候峰會在格拉斯哥舉行期間的一個重要議題：世界上最富裕的國家，即那些對全球暖化負責任的不成比例的國家，應如何賠償因全球氣溫上升所造成的貧困國家的損失。報導指出，現今全球人口中，包括美國、加拿大、日本以及西歐大部分國家在內的富裕國家僅佔12％，但是在過去的170年中，這些國家卻負責了50％的溫室氣體排放。貧困國家要求富裕國家提供更多資金以應對全球暖化所帶來的風險。在峰會上，來自最不發達國家聯盟的Sonam P. Wangdi指出，他的祖國不丹對全球暖化的責任較小，因為該國目前吸收的二氧化碳比汽車和房屋排放的少。然而，不丹仍然面臨著由氣溫上升所帶來的嚴重風險，喜馬拉雅山脈融化的冰川已經導致了洪水和泥石流，摧毀了村莊。報導指出，最不發達國家需要更多的資金和支持，以應對全球暖化所帶來的影響。 本案例的Treemap以面積顯示了各國的碳排放所佔比例，並用顏色視覺化各國的人均GDP。Per Capita是拉丁語，通常用來表示某種統計數據與人口數量之間的關係。它是指將某一特定數量的總量除以人口數目，以得出每個人所擁有的平均數量。例如，國家的人均GDP（Gross Domestic Product，國內生產總值）是指該國的總GDP除以該國的人口數，以反映一個人在該國經濟中所創造的平均貢獻。Per Capita常用於比較不同國家或地區之間的平均水平，以及分析人均收入、人均支出、人均消費等數據。 totreemap &lt;- read_csv(&quot;data/GCB2021v34_MtCO2_flat.csv&quot;) %&gt;% drop_na(`Total`) %&gt;% filter(!Country %in% c(&quot;Global&quot;, &quot;International Transport&quot;)) %&gt;% filter(Year==2020) %&gt;% arrange(desc(`Total`)) %&gt;% mutate(perc = Total/sum(Total)) %&gt;% slice(1:20) library(treemapify) totreemap %&gt;% ggplot() + aes(area = perc, fill=`Per Capita`, label=Country) + geom_treemap() + geom_treemap_text(color=&quot;white&quot;, place=&quot;centre&quot;, grow=TRUE ) 21.3.2 TW: Taiwan Annual Expenditure 上述案例未能突顯出Treemap能夠呈現階層式資料的特色。因此本案例將使用台灣中央預算，階層化地顯示不同機構層級（大類、一級部會）等的預算佔比。例如衛福部、財政部與勞動部的預算均屬於社會福利支出。 這段程式碼中，使用了 zoo 套件中的 na.locf() 函數。此函數用於將 raw 資料框中的 款 欄位的缺失值 (NA) 以最近已知的值 (向前填補) 進行填補。 library(zoo) # raw &lt;- readxl::read_excel(&quot;data/111B歲出政事別預算總表.xls&quot;) raw &lt;- readxl::read_excel(&quot;data/111B歲出政事別預算表.xls&quot;, skip=3, col_names = F) names(raw) &lt;- c(&quot;款&quot;, &quot;科&quot;, &quot;目&quot;, &quot;節&quot;, &quot;機構&quot;, &quot;本年度預算&quot;, &quot;上年度預算&quot;, &quot;上年度決算&quot;, &quot;預算差&quot;) # raw$款 &lt;- na.locf(raw$款) cleand &lt;- raw %&gt;% filter(!is.na(款) | !is.na(科)) %&gt;% slice(-(1:2)) %&gt;% select(-目, -節) %&gt;% mutate(org = purrr::map(機構, function(x){str_split(x, &quot;\\n&quot;)[[1]][2]})) %&gt;% mutate(款 = ifelse(!is.na(款), unlist(org), unlist(款))) %&gt;% mutate(款 = zoo::na.locf(款)) %&gt;% filter(!is.na(科)) %&gt;% select(-科) %&gt;% type_convert() %&gt;% mutate(上年度預算 = as.numeric(上年度預算), 上年度決算 = as.integer(上年度決算), 預算差 = as.numeric(預算差)) %&gt;% replace_na(list(上年度預算 = 0, 上年度決算 = 0)) %&gt;% mutate(預算差 = 本年度預算 - 上年度預算) cleand %&gt;% filter(款 %in% c(&quot;科學支出&quot;)) %&gt;% ggplot() + aes(area = 本年度預算, fill=`本年度預算`, label=org) + geom_treemap() + geom_treemap_text(color=&quot;white&quot;, place=&quot;centre&quot;, grow=TRUE, family = &quot;Heiti TC Light&quot; ) + theme(title = element_text(family = &quot;Heiti TC Light&quot;), text = element_text(family = &quot;Heiti TC Light&quot;)) library(treemapify) cleand %&gt;% # filter(款 %in% c(&quot;科學支出&quot;, &quot;教育支出&quot;, &quot;國防支出&quot;, &quot;司法支出&quot;)) %&gt;% ggplot() + aes(area = 本年度預算, fill=`本年度預算`, label=org, subgroup = 款) + geom_treemap() + geom_treemap_subgroup_border(color=&quot;gold&quot;) + geom_treemap_subgroup_text(place = &quot;centre&quot;, grow = T, alpha = 0.5, colour = &quot;gold&quot;, min.size = 0, family = &quot;Heiti TC Light&quot;) + geom_treemap_text(color=&quot;white&quot;, place=&quot;centre&quot;, grow=F, family = &quot;Heiti TC Light&quot; ) + theme(title = element_text(family = &quot;Heiti TC Light&quot;), text = element_text(family = &quot;Heiti TC Light&quot;), legend.position = &quot;none&quot;) "],["association.html", "Chapter 22 ASSOCIATION 22.1 等比例座標軸", " Chapter 22 ASSOCIATION 22.1 等比例座標軸 22.1.1 UNICEF-Optimistic (WGOITH) https://www.nytimes.com/2021/11/17/upshot/global-survey-optimism.html https://changingchildhood.unicef.org/about plot.opt &lt;- read_csv(&quot;data/unicef-changing-childhood-data.csv&quot;) %&gt;% select(country = WP5, age = WP22140, bw = WP22092) %&gt;% mutate(country = ordered(country, levels=c(1, 3, 4, 10, 11, 12, 13, 14, 17, 29, 31, 33, 35, 36, 60, 61, 77, 79, 81, 87, 165), labels=c(&quot;USA&quot;, &quot;Morocco&quot;, &quot;Lebanon&quot;, &quot;Indonesia&quot;, &quot;Bangladesh&quot;, &quot;UK&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;, &quot;Japan&quot;, &quot;India&quot;, &quot;Brazil&quot;, &quot;Nigeria&quot;, &quot;Kenya&quot;, &quot;Ethiopia&quot;, &quot;Mali&quot;, &quot;Ukraine&quot;, &quot;Cameroon&quot;, &quot;Zimbabwe&quot;, &quot;Argentina&quot;, &quot;Peru&quot;))) %&gt;% count(country, age, bw) %&gt;% group_by(country, age) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(bw == 1) %&gt;% select(country, age, perc) %&gt;% spread(age, perc) %&gt;% rename(`15-24y` = `1`, `40+y` = `2`) plot.opt %&gt;% head(10) %&gt;% knitr::kable() country 15-24y 40+y USA 0.6679842 0.4611465 Morocco 0.4365079 0.4735812 Lebanon 0.5467197 0.4435798 Indonesia 0.7920605 0.8027344 Bangladesh 0.4624506 0.4319527 UK 0.5040000 0.4140000 France 0.3900000 0.2640000 Germany 0.5900000 0.3860000 Spain 0.5160000 0.3340000 Japan 0.6367265 0.2586873 plot.opt %&gt;% ggplot() + aes(`40+y`, `15-24y`, label = country) + geom_point(color = &quot;skyblue&quot;, size = 2) + xlim(0, 1) + ylim(0,1) + geom_text(hjust = -0.1, vjust = -0.5) + geom_abline(intercept = 0, slop = 1, color=&quot;lightgrey&quot;, alpha=0.5, linetype=&quot;dashed&quot;) + theme_minimal() + theme(aspect.ratio=1) "],["time-trends.html", "Chapter 23 TIME &amp; TRENDS 23.1 Highlighting: Unemployed Population 23.2 Smoothing: Unemployed", " Chapter 23 TIME &amp; TRENDS 23.1 Highlighting: Unemployed Population This example is referenced from Datacamp’s Introduction to data visualization with ggplot2。 23.1.1 The econimics data 這是一個包含美國經濟時間序列資料的資料集，資料來源為https://fred.stlouisfed.org/。economics是以「寬」表格方式儲存，而economics_long 資料框則以「長」表格方式儲存。每一列之date為資料收集的月份。 pce：個人消費支出，以十億美元為單位，資料來源為 https://fred.stlouisfed.org/series/PCE pop：總人口數，以千人為單位，資料來源為 https://fred.stlouisfed.org/series/POP psavert：個人儲蓄率，資料來源為 https://fred.stlouisfed.org/series/PSAVERT/ uempmed：失業中位數持續時間，以週為單位，資料來源為 https://fred.stlouisfed.org/series/UEMPMED unemploy：失業人數，以千人為單位，資料來源為 https://fred.stlouisfed.org/series/UNEMPLOY economics %&gt;% head() ## # A tibble: 6 × 6 ## date pce pop psavert uempmed unemploy ## &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1967-07-01 507. 198712 12.6 4.5 2944 ## 2 1967-08-01 510. 198911 12.6 4.7 2945 ## 3 1967-09-01 516. 199113 11.9 4.6 2958 ## 4 1967-10-01 512. 199311 12.9 4.9 3143 ## 5 1967-11-01 517. 199498 12.8 4.7 3066 ## 6 1967-12-01 525. 199657 11.8 4.8 3018 23.1.2 Setting marking area recess &lt;- data.frame( begin = c(&quot;1969-12-01&quot;,&quot;1973-11-01&quot;,&quot;1980-01-01&quot;,&quot;1981-07-01&quot;,&quot;1990-07-01&quot;,&quot;2001-03-01&quot;, &quot;2007-12-01&quot;), end = c(&quot;1970-11-01&quot;,&quot;1975-03-01&quot;,&quot;1980-07-01&quot;,&quot;1982-11-01&quot;,&quot;1991-03-01&quot;,&quot;2001-11-01&quot;, &quot;2009-07-30&quot;), event = c(&quot;Fiscal &amp; Monetary\\ntightening&quot;, &quot;1973 Oil crisis&quot;, &quot;Double dip I&quot;,&quot;Double dip II&quot;, &quot;Oil price shock&quot;, &quot;Dot-com bubble&quot;, &quot;Sub-prime\\nmortgage crisis&quot;), y = c(.01415981, 0.02067402, 0.02951190, 0.03419201, 0.02767339, 0.02159662, 0.02520715) ) library(lubridate) recess &lt;- recess %&gt;% mutate(begin = ymd(begin), end = ymd(end)) economics %&gt;% ggplot() + aes(x = date, y = unemploy/pop) + ggtitle(c(&quot;The percentage of unemployed Americans \\n increases sharply during recessions&quot;)) + geom_line() + geom_rect(data = recess, aes(xmin = begin, xmax = end, ymin = -Inf, ymax = +Inf, fill = &quot;Recession&quot;), inherit.aes = FALSE, alpha = 0.2) + geom_label(data = recess, aes(x = end, y = y, label=event), size = 3) + scale_fill_manual(name = &quot;&quot;, values=&quot;red&quot;, label=&quot;Recessions&quot;) 23.2 Smoothing: Unemployed Smooth by bin smoothing fit &lt;- with(economics, ksmooth(date, unemploy, kernel = &quot;box&quot;, bandwidth=210)) economics %&gt;% mutate(smooth = fit$y) %&gt;% ggplot() + aes(date, unemploy) + geom_point(alpha = 5, color = &quot;skyblue&quot;) + geom_line(aes(date, smooth), color=&quot;red&quot;) + theme_minimal() 23.2.1 Polls_2008 Second Example comes from Rafael’s online book library(dslabs) span &lt;- 7 polls_2008 ## # A tibble: 131 × 2 ## day margin ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -155 0.0200 ## 2 -153 0.0300 ## 3 -152 0.065 ## 4 -151 0.06 ## 5 -150 0.07 ## 6 -149 0.05 ## 7 -147 0.035 ## 8 -146 0.06 ## 9 -145 0.0267 ## 10 -144 0.0300 ## # … with 121 more rows fit &lt;- with(polls_2008, ksmooth(day, margin, kernel = &quot;box&quot;, bandwidth = span)) polls_2008 %&gt;% mutate(smooth = fit$y) %&gt;% ggplot(aes(day, margin)) + geom_point(size = 3, alpha = .5, color = &quot;grey&quot;) + geom_line(aes(day, smooth), color=&quot;red&quot;) + theme_minimal() "],["network-vis.html", "Chapter 24 NETWORK VIS 24.1 Generating networks 24.2 Retrieve Top3 Components 24.3 Motif visualization and analysis", " Chapter 24 NETWORK VIS 網絡視覺化其實已經有非常好的簡介和指南。但在此補充一些常用的網絡視覺化參數 library(igraph) 24.1 Generating networks 24.1.1 Random network g &lt;- barabasi.game(500, directed = T) message(&quot;\\n(V, E, Reciprocity, nComponent)\\n&quot;, length(V(g)), &quot;\\t&quot;, length(E(g)), &quot;\\t&quot;, sprintf(&quot;%.3f\\t&quot;, reciprocity(g)), count_components(g, mode = &quot;weak&quot;) ) l &lt;- layout.fruchterman.reingold(g) # l &lt;- layout_with_kk(g) # l &lt;- layout_in_circle(g) par(mar = c(0,0,0,0) + 0.1) plot(g, layout = l, vertex.color = rgb(1, 1, 0, 0.2), # vertex.color = factor(V(g)$blocked), vertex.size = 3, # vertex.size = sqrt(V(g)$degree)*3, vertex.frame.color= rgb(0, 0, 0, 0.5), # vertex.label = V(g)$display, # vertex.label = str_sub(V(g)$name, 1, 10), vertex.label.cex = 0.6, vertex.label.color = rgb(0, 0, 0, 0.7), vertex.label.family = &#39;Heiti TC Light&#39;, edge.curved = 0.1, edge.arrow.size = 0.1, # edge.width = sqrt(E(g)$weight), # edge.color = E(g)$year, # edge.color = E(g)$weight, edge.color = &quot;#4169E1&quot;, # edge.color = E(g)$color, # edge.label = E(g)$weight, # edge.label = E(g)$year, edge.label.cex = 0.4, edge.label.color = rgb(1, 0, 0) ) 24.1.2 Random network rg &lt;- sample_gnm(length(V(g)), length(E(g)), directed=T) message(&quot;\\n(V, E, Reciprocity, nComponent)\\n&quot;, length(V(rg)), &quot;\\t&quot;, length(E(rg)), &quot;\\t&quot;, sprintf(&quot;%.3f\\t&quot;, reciprocity(rg)), count_components(rg, mode = &quot;weak&quot;) ) l &lt;- layout.fruchterman.reingold(rg) par(mar = c(0,0,0,0) + 0.1) plot(rg, layout = l, vertex.color = rgb(1, 1, 0, 0.2), vertex.size = 3, vertex.frame.color= rgb(0, 0, 0, 0.5), vertex.label.cex = 0.6, vertex.label.color = rgb(0, 0, 0, 0.7), vertex.label.family = &#39;Heiti TC Light&#39;, edge.curved = 0.1, edge.arrow.size = 0.1, edge.color = &quot;#4169E1&quot;, edge.label.cex = 0.4, edge.label.color = rgb(1, 0, 0) ) 24.2 Retrieve Top3 Components components &lt;- igraph::clusters(rg, mode=&quot;weak&quot;) biggest_cluster_id &lt;- which.max(components$csize) # which.max(components$csize) # components$csize # biggest_cluster_id top3_break &lt;- sort(unique(components$csize), decreasing = T)[3] biggest_cluster_id &lt;- which(components$csize &gt;= top3_break) vert_ids &lt;- V(rg)[components$membership %in% biggest_cluster_id] rg &lt;- igraph::induced_subgraph(rg, vert_ids) message(&quot;\\n(V, E, Reciprocity, nComponent)\\n&quot;, length(V(rg)), &quot;\\t&quot;, length(E(rg)), &quot;\\t&quot;, sprintf(&quot;%.3f&quot;, reciprocity(rg)) ) 24.2.1 Visualize again l &lt;- layout.fruchterman.reingold(rg) par(mar = c(0,0,0,0) + 0.1) plot(rg, layout = l, vertex.color = rgb(1, 1, 0, 0.2), vertex.size = 3, vertex.frame.color= rgb(0, 0, 0, 0.5), vertex.label.cex = 0.6, vertex.label.color = rgb(0, 0, 0, 0.7), vertex.label.family = &#39;Heiti TC Light&#39;, edge.curved = 0.1, edge.arrow.size = 0.1, edge.color = &quot;#4169E1&quot;, edge.label.cex = 0.4, edge.label.color = rgb(1, 0, 0) ) 24.3 Motif visualization and analysis 24.3.1 Motif type library(igraph) par(mfrow=c(4,4), mai= rep(0.2, 4)) for(i in 0:15){ g1 &lt;- graph_from_isomorphism_class(3, i) plot(g1, vertex.color = &quot;gold&quot;, vertex.size = 20, # vertex.size = (V(g)$nTweets)^(1/3)+1, vertex.frame.color= &quot;black&quot;, vertex.label = NA, edge.color = &quot;black&quot;, edge.arrow.size = 0.5) title(i, line=-3, adj=0.4 ,col.main=&quot;royalblue&quot;) } 24.3.2 Motif analysis 24.3.2.1 Generate network res &lt;- motifs(g, 3) res ## [1] NA NA 2241 NA 466 0 0 0 0 0 0 0 0 0 0 ## [16] 0 writeLines(as.character(res), sep = &quot;\\t&quot;) ## NA NA 2241 NA 466 0 0 0 0 0 0 0 0 0 0 0 24.3.3 Generate motives barabas_motif &lt;- function(e){ g &lt;- barabasi.game(e, directed = T) vec &lt;- motifs(g, 3) %&gt;% replace_na(0) for(i in 1:99){ g &lt;- barabasi.game(e, directed = T) tmp &lt;- motifs(g, 3) %&gt;% replace_na(0) vec &lt;- vec + tmp } vec &lt;- vec / 100 writeLines(as.character(vec), sep = &quot;\\t&quot;) } random_net_motif &lt;- function(v, e){ g &lt;- sample_gnm(v, e, directed=T) vec &lt;- motifs(g, 3) %&gt;% replace_na(0) for(i in 1:99){ g &lt;- sample_gnm(v, e, directed=T) tmp &lt;- motifs(g, 3) %&gt;% replace_na(0) vec &lt;- vec + tmp } vec &lt;- vec / 100 writeLines(as.character(vec), sep = &quot;\\t&quot;) } random_net_motif(length(V(g)), length(E(g))) ## 0 0 247.61 0 494.5 1.06 247.1 0.94 0 1.04 0 0.39 0 0 0 0 barabas_motif(length(E(g))) ## 0 0 2550.99 0 460.27 0 0 0 0 0 0 0 0 0 0 0 "],["geospatial.html", "Chapter 25 GEOSPATIAL", " Chapter 25 GEOSPATIAL "],["interactivity.html", "Chapter 26 Interactivity 26.1 ggplotly 26.2 產製圖表動畫", " Chapter 26 Interactivity 26.1 ggplotly Scatter plots with ggplot2 (plotly.com) 26.1.1 LINE CHART Line plots with R (plotly.com) NW &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(Category, year, Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% ungroup() 如果希望滑鼠在移到折線上時就會有浮出的資訊（tips）顯示該資料點的屬性特徵，可以採用plotly()這個套件。這個套件原本就是做線上互動圖表的，但他開發了R client讓R的使用者可以很輕易地把ggplot2的結果轉為互動圖表。但這所謂的互動也僅限於滑鼠移過去所浮出的資訊罷了，不過已經能夠達到吸引部分讀者目光、提供訊息的效果。 而plotly的設計非常簡單，就是把ggplot的結果指給一個變數後，然後用ggplotly(NW.plot)將其轉為plotly即可。但要注意的是，並不是每一個圖都可以順利轉換。例如本節最後一個例子Treemap便無法成功轉換。 設定：原本plotly會帶一個操控列，可以在ggplotly()指令後加入config()便可將其隱藏。 NW.plot &lt;- NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category) + geom_line() + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) + th library(plotly) ggplotly(NW.plot) %&gt;% config(displayModeBar = FALSE) 可以在aes()設定要帶入圖的變數時，新增一個text變數，手動設定要呈現的動態呈現方塊。但要注意的是，要多加入一個group=1才能夠作用（WHY？）。但前例浮出視窗的原始內容所顯示的是原本的變數名稱和值，往往不易觀察。比較好的方式是在下ggplot() + aes()指令時，在aes()中指定text來作為後續浮出視窗內容。指定方法如下。要注意的是，該浮出視窗的語法是HTML，所以如果要改寫浮出視窗內容，要用paste0()將變數和HTML的標籤給銜接起來。以下例子中的&lt;b&gt;代表粗體的意思，&lt;br&gt;則是換行符號。 NW.plot &lt;- NW %&gt;% ggplot() + aes(year, Net_Worth, color=Category, text = paste0(&quot;&lt;b&gt;年(X): &lt;/b&gt;&quot;, year, &quot;&lt;br&gt;&quot;, &quot;&lt;b&gt;淨資產(Y): &lt;/b&gt;&quot;, Net_Worth,&quot;&lt;br&gt;&quot;, &quot;&lt;b&gt;年齡組: &lt;/b&gt;&quot;, Category), group=1) + geom_line() + theme_minimal() + labs(title = &quot;Net Worth by year grouped by age groups&quot;, x = &quot;Year&quot;, y = &quot;Net Worth&quot;) + th ggplotly(NW.plot, tooltip = &quot;text&quot;) %&gt;% config(displayModeBar = FALSE) 其他例子中使用ggplotly()都是直接照前面的方法套用即可。唯獨在Treemap中無法用這樣的方法來做互動的視覺化。想想這也正常，畢竟Treemap是用非ggplot的第三方套件（library(treemapify)）。 除此之外，可以把R Markdown中Code Cell的的設定加入include=FALSE，這樣可以讓RMD在編製為HTML檔時，不要顯示程式碼，而直接顯示互動的視覺化介面。 26.1.2 SCATTER bw &lt;- read_csv(&quot;data/unicef-changing-childhood-data.csv&quot;) %&gt;% select(country = WP5, age = WP22140, bw = WP22092) %&gt;% mutate(country = ordered(country, levels=c(1, 3, 4, 10, 11, 12, 13, 14, 17, 29, 31, 33, 35, 36, 60, 61, 77, 79, 81, 87, 165), labels=c(&quot;USA&quot;, &quot;Morocco&quot;, &quot;Lebanon&quot;, &quot;Indonesia&quot;,&quot;Bangladesh&quot;, &quot;UK&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;, &quot;Japan&quot;, &quot;India&quot;, &quot;Brazil&quot;, &quot;Nigeria&quot;, &quot;Kenya&quot;, &quot;Ethiopia&quot;, &quot;Mali&quot;, &quot;Ukraine&quot;, &quot;Cameroon&quot;, &quot;Zimbabwe&quot;,&quot;Argentina&quot;, &quot;Peru&quot;))) %&gt;% count(country, age, bw) %&gt;% group_by(country, age) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(bw == 1) %&gt;% select(country, age, perc) %&gt;% spread(age, perc) %&gt;% rename(`15-24y` = `1`, `40+y` = `2`) bw.p &lt;- bw %&gt;% ggplot() + aes(`40+y`, `15-24y`, label = country) + geom_point(color = &quot;skyblue&quot;, size = 2) + xlim(0.2, 0.85) + ylim(0.2, 0.85) + geom_text(hjust = -0.1, vjust = -0.5) + geom_abline(intercept = 0, slop = 1, color=&quot;lightgrey&quot;, alpha=0.5, linetype=&quot;dashed&quot;) + th + theme(aspect.ratio=1) bw.p %&gt;% ggplotly() 26.1.3 Barplot Bar charts with R (plotly.com) county &lt;- read_csv(&quot;data/tw_population_opendata110N010.csv&quot;) %&gt;% slice(-1, -(370:375)) %&gt;% type_convert() %&gt;% mutate(county = str_sub(site_id, 1, 3)) %&gt;% group_by(county) %&gt;% summarize( area = sum(area), people_total = sum(people_total) ) %&gt;% ungroup() population.p &lt;- county %&gt;% mutate(county = reorder(county, people_total)) %&gt;% ggplot() + aes(county, people_total) %&gt;% geom_col(fill=&quot;skyblue&quot;) + coord_flip() + th population.p %&gt;% ggplotly() 26.1.4 Boxplot Box plots with ggplot2 (plotly.com) aqi.toplot &lt;- read_rds(&quot;https://github.com/p4css/R4CSS/raw/master/data/AQI_Chaozhou.rds&quot;) %&gt;% arrange(日期)%&gt;% filter(測項==&quot;PM2.5&quot;) %&gt;% gather(&quot;hour&quot;, &quot;PM25&quot;, 4:28) %&gt;% mutate(PM25 = as.numeric(PM25)) %&gt;% drop_na() %&gt;% mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %&gt;% filter(month %in% c(11, 12, 1, 2, 3)) aqi.plot &lt;- aqi.toplot %&gt;% mutate(year = as.character(year)) %&gt;% ggplot() + aes(x=year, y=PM25) + geom_boxplot(fill=&quot;skyblue&quot;, alpha=0.2) + ylim(0, 200) + coord_flip() + theme_minimal() aqi.plot %&gt;% ggplotly 26.1.5 Treemap (Global Carbon) 其他例子中使用ggplotly()都是直接照前面的方法套用即可。唯獨在Treemap中無法用這樣的方法來做互動的視覺化。想想這也正常，畢竟Treemap是用非ggplot的第三方套件（library(treemapify)）。 totreemap &lt;- read_csv(&quot;data/GCB2021v34_MtCO2_flat.csv&quot;) %&gt;% drop_na(`Total`) %&gt;% filter(!Country %in% c(&quot;Global&quot;, &quot;International Transport&quot;)) %&gt;% filter(Year==2020) %&gt;% arrange(desc(`Total`)) %&gt;% mutate(perc = Total/sum(Total)) %&gt;% slice(1:20) library(treemapify) carbon.p &lt;- totreemap %&gt;% ggplot() + aes(area = perc, fill=`Per Capita`, label=Country) + geom_treemap() + geom_treemap_text(color=&quot;white&quot;, place=&quot;centre&quot;, grow=TRUE ) # carbon.p %&gt;% ggplotly 26.2 產製圖表動畫 https://gist.github.com/rafapereirabr/0d68f7ccfc3af1680c4c8353cf9ab345 R也有套工具可以產製圖表動畫，概念上就是沿著一條資料維度，把多張圖給疊在一起變成一個gif動畫。本例子即是把產假之薪的範例沿著時間軸做動畫。每個時間點都是當年各國產假支薪給付程度的地圖，但由於有19年的資料，所以可以把年代當成動畫的時間軸。 以下是清理資料的步驟，會彙整出國名、國家代碼（ISO3）、年、和給付等級四個變項。預期利用國名、國家代碼和給付等級就可以畫出每年的圖。然後將年作為動畫的時間軸，便可產生地圖動畫。 pml &lt;- read_excel(&quot;data/WORLD-MACHE_Gender_6.8.15.xls&quot;, &quot;Sheet1&quot;, col_names=T) %&gt;% select(country, iso3, contains(&quot;matleave&quot;), -contains(&quot;wrr&quot;)) %&gt;% gather(&quot;year&quot;, &quot;degree&quot;, 3:21) %&gt;% replace_na(list(degree=0)) %&gt;% mutate(year2=as.POSIXct(strptime(year, &quot;matleave_%y&quot;))) %&gt;% mutate(year3 = strftime(year2, &quot;%Y&quot;)) %&gt;% select(country, ISO3=iso3, year=year3, degree) 26.2.1 地圖下載與轉換投影方法 此為下載地圖並處理地圖成為可以用geom_polygom()繪圖的多邊形資料點。 library(rworldmap) wmap &lt;- getMap(resolution=&quot;low&quot;) wmap &lt;- spTransform(wmap, CRS(&quot;+proj=robin&quot;)) # reproject wmap &lt;- fortify(wmap) wmap %&gt;% filter(!duplicated(id)) %&gt;% head(10) ## long lat order hole piece id ## 1 -6558139.1 1331766 1 FALSE 1 Aruba ## 2 6607120.5 3981588 1 FALSE 1 Afghanistan ## 3 1338236.2 -628452 1 FALSE 1 Angola ## 4 -5863722.7 1948852 1 FALSE 1 Anguilla ## 5 1723246.7 4546404 1 FALSE 1 Albania ## 6 1503172.1 6370384 1 FALSE 1 Aland ## 7 146562.7 4541753 1 FALSE 1 Andorra ## 8 5157180.1 2742768 1 FALSE 1 United Arab Emirates ## 9 -6080937.4 -2363597 1 FALSE 1 Argentina ## 10 3901101.2 4403251 1 FALSE 1 Armenia ## group ## 1 Aruba.1 ## 2 Afghanistan.1 ## 3 Angola.1 ## 4 Anguilla.1 ## 5 Albania.1 ## 6 Aland.1 ## 7 Andorra.1 ## 8 United Arab Emirates.1 ## 9 Argentina.1 ## 10 Armenia.1 pml_map &lt;- wmap %&gt;% left_join(pml, by=c(&quot;id&quot;=&quot;country&quot;)) %&gt;% filter(!is.na(ISO3)) %&gt;% mutate(year = as.integer(year)) # devtools::install_github(&quot;thomasp85/transformr&quot;) pml_map %&gt;% select(id) %&gt;% filter(!duplicated(.)) %&gt;% head(10) ## id ## 1 Afghanistan ## 2 Angola ## 3 Albania ## 4 Andorra ## 5 United Arab Emirates ## 6 Argentina ## 7 Armenia ## 8 Antigua and Barbuda ## 9 Australia ## 10 Austria 26.2.2 靜態繪圖測試 pml_map %&gt;% filter(year==1995) %&gt;% ggplot() + aes(x = long, y = lat, group=group, fill=factor(degree)) + geom_polygon(color=&quot;grey&quot;) + theme_void() + scale_fill_manual(values=c(&quot;1&quot;=&quot;red&quot;, &quot;2&quot;=&quot;LightCyan&quot;, &quot;3&quot;=&quot;lightskyblue&quot;, &quot;4&quot;=&quot;DodgerBlue&quot;, &quot;5&quot;=&quot;MediumBlue&quot;)) + coord_cartesian(xlim = c(-11807982, 14807978)) 在採用gganimate繪圖時，僅需要多加一個動畫繪圖函式+ transition_time(year)即可，其他繪圖部分並無修改。最後才用animate()函式把這整個繪圖指令轉製為動畫，包含指定fps（frame per second）和長寬等參數。 library(gganimate) pml.ani &lt;- pml_map %&gt;% ggplot() + aes(x = long, y = lat, group=group, fill=factor(degree)) + geom_polygon(color=&quot;grey&quot;) + theme_void() + scale_fill_manual(values=c(&quot;1&quot;=&quot;red&quot;, &quot;2&quot;=&quot;LightCyan&quot;, &quot;3&quot;=&quot;lightskyblue&quot;, &quot;4&quot;=&quot;DodgerBlue&quot;, &quot;5&quot;=&quot;MediumBlue&quot;)) + coord_cartesian(xlim = c(-11807982, 14807978)) + transition_time(year) # + # ease_aes(&quot;linear&quot;) + # enter_fade() + # exit_fade() animate(pml.ani, fps = 10, end_pause = 30, width = 750, height = 450, renderer = gifski_renderer()) anim_save(&quot;jour5014/pml2.gif&quot;, animation = last_animation()) knitr::include_graphics(&quot;jour5014/pml2.gif&quot;) "],["wgoitg.html", "Chapter 27 WGOITG of NyTimes", " Chapter 27 WGOITG of NyTimes 紐約時報提供的what’s going on in the graph 系列教學旨在幫助讀者更好地理解和解讀圖表，特別是在時事和政治等敏感領域中的圖表。這些教學以實際的新聞圖表為例，介紹了如何分析和評估圖表的質量、有效性和可靠性，並提供了一些技巧和策略，幫助讀者從圖表中獲取準確和全面的資訊。 具體來說，what’s going on in the graph系列教學的目的包括以下幾點： 提高讀者對圖表的識讀能力和分析能力，讓讀者能夠更加自信和準確地理解和評估圖表。 幫助讀者識別和處理常見的資訊偏差和誤導，如選擇性展示數據、扭曲比例、誤導標籤等。 強調圖表應該為讀者服務，而不是為了強調某個立場或觀點而有意歪曲事實。 提供了一些有效的技巧和策略，如注意圖表的標題、軸標籤和單位、比較數據的趨勢和範圍、理解圖表的背景和上下文等。 "],["inequality-net-worth-by-age-group.html", "Chapter 28 Inequality: Net Worth by Age Group", " Chapter 28 Inequality: Net Worth by Age Group LEARNING NOTES 座標軸從數值到增加值 這個教學案例來自紐約時報的「What’s going on in this gragh」系列資料視覺化教學之Teach About Inequality With These 28 New York Times Graphs - The New York Times (nytimes.com) 。該圖表呈現在不同年代、不同年齡層的人所擁有的淨資產（包含土地、存款、投資等減去債務）。該圖表的結果指出，在不同年代的老年人是越來越有錢，但年輕人卻越來越窮（該曲線為減去1989年 淨資產（Net worth）是一個財務術語，指的是一個人或機構的總資產減去總負債後剩餘的價值。換言之，Net worth是一個人或機構在財務上的價值或實力。如果一個人或機構的總資產超過了總負債，那麼其net worth為正值，反之則為負值。在個人財務上，Net worth通常用來評估一個人的財務健康狀況。一個人的Net worth越高，通常代表其擁有更多的財富和投資，並能夠更好地應對突發事件和生活變數。因此，許多投資者和財務顧問都會建議人們注重提高自己的net worth。 Sorted by arrange() function. p1 &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(year, Category, Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% ungroup() p1 %&gt;% filter(year &lt;= 1992) %&gt;% knitr::kable() year Category Net_Worth 1989 Less than 35 16.17019 1989 35-44 112.47530 1989 45-54 195.11630 1989 55-64 195.25554 1989 65-74 154.34277 1989 75 or older 144.29855 1992 Less than 35 16.60780 1992 35-44 79.91050 1992 45-54 139.97745 1992 55-64 203.44104 1992 65-74 176.44667 1992 75 or older 155.35173 library(gghighlight) p1 %&gt;% ggplot() + aes(year, Net_Worth, color = Category) + geom_line(linetype=&quot;dotted&quot;) + geom_point() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;35-44&quot;)) + theme_minimal() + scale_x_continuous(breaks = NULL) + theme(panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;)) p2 &lt;- read_csv(&quot;data/interactive_bulletin_charts_agecl_median.csv&quot;) %&gt;% select(year, Category, NW = Net_Worth) %&gt;% group_by(Category) %&gt;% arrange(year) %&gt;% mutate(increase = (NW-first(NW))/first(NW)) %&gt;% ungroup() p2 %&gt;% filter(year &lt;= 1992) %&gt;% knitr::kable() year Category NW increase 1989 Less than 35 16.17019 0.0000000 1989 35-44 112.47530 0.0000000 1989 45-54 195.11630 0.0000000 1989 55-64 195.25554 0.0000000 1989 65-74 154.34277 0.0000000 1989 75 or older 144.29855 0.0000000 1992 Less than 35 16.60780 0.0270627 1992 35-44 79.91050 -0.2895285 1992 45-54 139.97745 -0.2825948 1992 55-64 203.44104 0.0419220 1992 65-74 176.44667 0.1432131 1992 75 or older 155.35173 0.0765994 p2 %&gt;% ggplot() + aes(year, increase, color = Category) + geom_line(linetype=&quot;dotted&quot;) + geom_point() + gghighlight(Category %in% c(&quot;65-74&quot;, &quot;35-44&quot;)) + theme_minimal() + scale_y_continuous(labels=scales::parse_format()) + scale_x_continuous(breaks = NULL) + theme(panel.background = element_rect(fill = &quot;white&quot;, colour = &quot;white&quot;, size = 0.5, linetype = &quot;solid&quot;)) "],["optimism-survey-by-countries.html", "Chapter 29 Optimism Survey by Countries", " Chapter 29 Optimism Survey by Countries 這個練習為紐約時報的一則報導「Where Are Young People Most Optimistic? In Poorer Nations. - The New York Times (nytimes.com)」。該報導乃根據一項涵蓋 21 個國家的大型調查，這項調查比較了不同國家和年齡層（年輕人對成年人）對於下一代的生活是否會比現在更好的看法。該調查還比較了不同國家（富裕與貧窮）和年齡層（年輕人對成年人）對於當今兒童在基本方面的狀況，以及對於社會和環境問題的看法。此外，調查還比較了不同國家和年齡層對於現代科技對年輕人生活的影響看法，以及對於焦慮和壓力等方面的看法。 聯合國兒童基金會與 Gallup 共同進行了這項調查，該調查共有 21,000 名受訪者，分為兩個年齡組別——15 至 24 歲和 40 歲以上，並包括來自世界各地的代表性樣本。年輕組表示，當今兒童在教育、醫療保健和身體安全等基本方面都比他們的父母更好。在中位數國家中，有 57％ 的年輕人表示，隨著每一代的到來，世界正在變得越來越美好，而這一比例在老年人中僅有 39％。然而，在富裕國家，56％ 的年輕人和 64％ 的老年人表示，當今兒童在經濟方面將比他們的父母更加困難——這種觀點與近年來許多人的經濟現實相符。 視覺化的重點是等比例之座標軸的運用 plot.opt &lt;- read_csv(&quot;data/unicef-changing-childhood-data.csv&quot;) %&gt;% select(country = WP5, age = WP22140, bw = WP22092) %&gt;% mutate(country = ordered(country, levels=c(1, 3, 4, 10, 11, 12, 13, 14, 17, 29, 31, 33, 35, 36, 60, 61, 77, 79, 81, 87, 165), labels=c(&quot;USA&quot;, &quot;Morocco&quot;, &quot;Lebanon&quot;, &quot;Indonesia&quot;, &quot;Bangladesh&quot;, &quot;UK&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Spain&quot;, &quot;Japan&quot;, &quot;India&quot;, &quot;Brazil&quot;, &quot;Nigeria&quot;, &quot;Kenya&quot;, &quot;Ethiopia&quot;, &quot;Mali&quot;, &quot;Ukraine&quot;, &quot;Cameroon&quot;, &quot;Zimbabwe&quot;, &quot;Argentina&quot;, &quot;Peru&quot;))) %&gt;% count(country, age, bw) %&gt;% group_by(country, age) %&gt;% mutate(perc = n/sum(n)) %&gt;% ungroup() %&gt;% filter(bw == 1) %&gt;% select(country, age, perc) %&gt;% spread(age, perc) %&gt;% rename(`15-24y` = `1`, `40+y` = `2`) plot.opt %&gt;% head(10) %&gt;% knitr::kable() country 15-24y 40+y USA 0.6679842 0.4611465 Morocco 0.4365079 0.4735812 Lebanon 0.5467197 0.4435798 Indonesia 0.7920605 0.8027344 Bangladesh 0.4624506 0.4319527 UK 0.5040000 0.4140000 France 0.3900000 0.2640000 Germany 0.5900000 0.3860000 Spain 0.5160000 0.3340000 Japan 0.6367265 0.2586873 plot.opt %&gt;% ggplot() + aes(`40+y`, `15-24y`, label = country) + geom_point(color = &quot;skyblue&quot;, size = 2) + xlim(0, 1) + ylim(0,1) + geom_text(hjust = -0.1, vjust = -0.5) + geom_abline(intercept = 0, slop = 1, color=&quot;lightgrey&quot;, alpha=0.5, linetype=&quot;dashed&quot;) + theme_minimal() + theme(aspect.ratio=1) "],["taiwan.html", "Chapter 30 Case Studies (Taiwan) 30.1 TW AQI Visual Studies", " Chapter 30 Case Studies (Taiwan) 30.1 TW AQI Visual Studies library(tidyverse) ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── ## ✔ dplyr 1.1.0 ✔ readr 2.1.4 ## ✔ forcats 1.0.0 ✔ stringr 1.5.0 ## ✔ ggplot2 3.4.2 ✔ tibble 3.1.8 ## ✔ lubridate 1.9.2 ✔ tidyr 1.3.0 ## ✔ purrr 1.0.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors library(readxl) # options(stringsAsFactors = F) 30.1.1 eda-load-data-from-github # aqi_data &lt;- read_rds(&quot;https://github.com/p4css/R4CSS/raw/master/data/AQI_Chaozhou.rds&quot;) aqi_data &lt;- read_rds(&quot;data/AQI_Chaozhou.rds&quot;) 30.1.2 Trending: Central tendency toplot &lt;- aqi_data %&gt;% arrange(日期)%&gt;% filter(測項==&quot;PM2.5&quot;) %&gt;% gather(&quot;hour&quot;, &quot;PM25&quot;, 4:28) %&gt;% mutate(PM25 = as.numeric(PM25)) %&gt;% drop_na() %&gt;% group_by(日期) %&gt;% summarize(avg = mean(PM25)) %&gt;% ungroup() %&gt;% mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %&gt;% group_by(year, month) %&gt;% summarize(avg = mean(avg)) %&gt;% ungroup() ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `PM25 = as.numeric(PM25)`. ## Caused by warning: ## ! NAs introduced by coercion ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. Counting data by month and plotting to ensure the degree of data loss. aqi_data %&gt;% filter(測項==&quot;PM2.5&quot;) %&gt;% arrange(日期)%&gt;% gather(&quot;hour&quot;, &quot;PM25&quot;, 4:28) %&gt;% mutate(PM25 = as.numeric(PM25)) %&gt;% drop_na() %&gt;% group_by(日期) %&gt;% summarize(avg = mean(PM25)) %&gt;% ungroup() %&gt;% arrange(日期) %&gt;% mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %&gt;% count(year, month) %&gt;% mutate(rn = row_number()) %&gt;% ggplot() + aes(rn, n) + geom_line() + theme_minimal() ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `PM25 = as.numeric(PM25)`. ## Caused by warning: ## ! NAs introduced by coercion 科普小學堂-空氣中的懸浮粒子 台灣PM2.5三大面向：空汙現況多嚴重？要怪中國還是怪自己？ - 第 1 頁 - The News Lens 關鍵評論網 library(gghighlight) toplot %&gt;% mutate(month = as.character(month)) %&gt;% group_by(month) %&gt;% arrange(year) %&gt;% # mutate(diff = avg -first(avg), # month = as.character(month)) %&gt;% # ungroup() %&gt;% ggplot() + aes(year, avg, color = month) + geom_line() + # geom_point() + gghighlight(month %in% c(&quot;11&quot;, &quot;12&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) + theme_minimal() ## Warning: Tried to calculate with group_by(), but the calculation failed. ## Falling back to ungrouped filter operation... ## label_key: month 30.1.3 Trending: Extreme value toplot2 &lt;- aqi_data %&gt;% arrange(日期)%&gt;% filter(測項==&quot;PM2.5&quot;) %&gt;% gather(&quot;hour&quot;, &quot;PM25&quot;, 4:28) %&gt;% mutate(PM25 = as.numeric(PM25)) %&gt;% drop_na() %&gt;% group_by(日期) %&gt;% summarize(avg = sum(PM25)/24) %&gt;% ungroup() %&gt;% mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %&gt;% group_by(year, month) %&gt;% summarize(purple = sum(avg&gt;150), red = sum(avg&gt;54), orange = sum(avg&gt;35)) %&gt;% ungroup() ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `PM25 = as.numeric(PM25)`. ## Caused by warning: ## ! NAs introduced by coercion ## `summarise()` has grouped output by &#39;year&#39;. You can override using the ## `.groups` argument. toplot2 %&gt;% mutate(month = as.character(month)) %&gt;% group_by(month) %&gt;% arrange(year) %&gt;% ggplot() + aes(year, orange, color = month) + geom_line() + # geom_point() + gghighlight(month %in% c(&quot;11&quot;, &quot;12&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) + ylab(&quot;Days (PM25 &gt; 35) in one month&quot;) + theme_minimal() ## Warning: Tried to calculate with group_by(), but the calculation failed. ## Falling back to ungrouped filter operation... ## label_key: month toplot3 &lt;- aqi_data %&gt;% arrange(日期)%&gt;% filter(測項==&quot;PM2.5&quot;) %&gt;% gather(&quot;hour&quot;, &quot;PM25&quot;, 4:28) %&gt;% mutate(PM25 = as.numeric(PM25)) %&gt;% drop_na() %&gt;% mutate(year = lubridate::year(日期), month = lubridate::month(日期)) %&gt;% filter(month %in% c(11, 12, 1, 2, 3)) ## Warning: There was 1 warning in `mutate()`. ## ℹ In argument: `PM25 = as.numeric(PM25)`. ## Caused by warning: ## ! NAs introduced by coercion toplot3 %&gt;% mutate(year = as.character(year)) %&gt;% ggplot() + aes(y=year, x=PM25) + geom_boxplot(fill=&quot;skyblue&quot;, alpha=0.2) + xlim(0, 200) + theme_minimal() "],["appendix.html", "Chapter 31 Appendix 31.1 Dataset", " Chapter 31 Appendix 31.1 Dataset 111B歲出政事別預算表.xls - 111B歲出政事別預算總表.xls 臺北市住宅竊盜點位資訊-UTF8-BOM-1.csv opendata107Y020.csv opendata110Y060.csv tptheft.csv tw_income_107.csv tw_population_opendata110N010.csv tw_salary109.xlsx villmast_excel.xls WORLD-MACHE_Gender_6.8.15.xls "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
